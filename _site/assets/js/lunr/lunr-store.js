var store = [{
        "title": "개발 블로그 플랫폼 비교 분석 및 선택 과정 (Github vs Velog vs Tistiry vs ...)",
        "excerpt":"개발 블로그 개설 이유      다들 개발을 하다 보면 나도 기술 블로그, 개발 블로그를 만들어볼까? 하는 생각이 한번쯤 들었을 것이다.   아무래도 여러 개발 블로그들을 접하게 되면서도 있었고, 나는 스타트업에서 일하게 되며 동일한 오류를 보게 되는 경우가 잦아지며 버그 리포팅의 필요성도 다시 느껴 기록의 필요성을 느꼈다.   나는 강의 필기를 꽤나 열심히 하는 편이고 친구들에게 필기 좀 팔아봐라는 얘기를 정말 많이 들었기에, 팔기는 좀 그렇고 공유하고 싶어 블로그를 하자고 다짐 했다.   하지만.. 미루기를 한 세월,, 결국 눈 앞에 닥쳐오고 더 이상 미룰 수 없어서 개설이라도 해보려고 ,, !   개발 블로그 플랫폼 종류     Github Blog (+ jekyll)   Velog   tistory   Notion   Naver Blog   주로 위의 5가지를 개발 블로그로 많이 사용하더라, 그래서 이 중에서 결정하려고 했고, 나에게 맞는 걸 찾기 위해 비교해보았다!      지극히 개인적인 장단점 주의    기능별 비교                          Github Blog       Velog       tistory       Notion       Naver Blog                       작성 방법       Markdown       Markdown       에디터       Markdown + 에디터       에디터                 이미지 첨부 방식       markdown 형식       markdown 형식,  첨부 …       Drag &amp; Drop,  붙여넣기,  첨부 …       Drag &amp; Drop,  붙여넣기,  첨부 …       Drag &amp; Drop,  붙여넣기,  첨부 …                 이미지 사이즈 조절 여부       가능       일부 가능       가능       가능       가능                 Code Syntax Highlighting       가능       가능       다소 불편       가능       가능                 카테고리       카테고리, Tag       Tag only       카테고리, Tag       계층 구조,  Database 의 tag 로 정리 가능       카테고리, Tag                 디자인 커스텀       완전 자유로움       불가능       일부 가능       매우 일부 가능       일부 가능                 진입 장벽       많이… 걸림       쉬움       쉬움       쉬움       쉬움                 기타       글 수정, 블로그 디자인 수정 시마다 커밋해야함                       개인적인 필기나 메모들과 분리가 어려움  퍼블리싱 다소 귀찮       기존에 일상블로그로 이미 사용중           하나하나 얘기해보면       작성 방법  대부분 markdown 형태로 작성 할 수 있었다. 하지만 나는 markdown 형식에 그렇게 익숙한 편은 아니기에 이 부분이 좀 걸렸다. 그래서 티스토리를 사용할까? 라는 생각이 꽤나 들었다.   요즘은 markdown 형식으로 글 작성 할 수 있게 해주는 에디터도 많다 보니 일단 크게 생각하지는 않았다   이미지 첨부 방식  사실 나에게 꽤 큰 비중을 차지하는 문제이다   나는 이미지를 첨부할 때 노트북에서 캡쳐한 다음 클립보드에 있는 것을 그대로 붙여넣기해서 첨부하는 방식을 굉장히 선호한다. 또한 Drag &amp; Drop 방식도 굉장히 선호하는 편이다  근데 Github 이나 Velog 와 같이 마크다운 으로 작성하는 에디터의 경우 마크다운 형식으로 이미지를 첨부해야한다는 사실이 굉장히 귀찮게 느껴졌다  아무래도 해당 방식들은 이미지를 어딘가에 업로드하고 그 링크를 가져와야하다보니 그 불편함이 더 더욱 크게 느껴지는 것 같다. 그래도 velog 정도면 첨부를 지원해서 양반인데 github은…. 그래서 굉장히 길게 고민했다   이미지 사이즈 조절 여부  이거도 중요한 점 중 하나.. 사실 이 전 항목과 결과가 비슷하다   Code Syntax Highlighting  개발 블로그다 보니 필수적으로 생각해야하는 요인!  아무래도 글에 코드를 입력해야하는 일이 굉장히 많을 것으로 예상되는데, 코드 가독성이 안 좋으면 글 쓰는 사람도, 보는 사람도 불편하다. ㅜㅜ  대부분이 다 가능한데 tistory 은 별도 플러그인을 지정해야해서 다소 불편하다는 정도?   카테고리  굉장히 굉장히 중요한 부분 .. !! 아무리 글이 예쁘고 디자인이 예쁘다고 하더라고, 정리를 못 하면 글들이 다 너저분하게 흩틀어져 있는 것 처럼보이고, 방문자도 원하는 글을 찾기 힘들다  이 점에서 velog 가 탈락했다.. UI/UX 가 굉장히 깔끔하고 많은 사람들이 사용 중이라는 큰 장점이 있긴 한데, Tag 로 밖에 정리를 못 하기에 개인적으로 넘 불편했다. (그리고 나중에 나올 디자인 커스텀 못 하는 점도)  이 부분에서 Notion 도 좀 걸렸는데 계층적으로 분리할 수 있고, Database 표나 다른 것을 통해 정리할 수는 있지만 전체적인 틀은 못 보는 것이 불편하달까?   디자인 커스텀  굉장히 굉장히 중요한 부분22 무조건 난 블로그가 예뻐야한다,, 막 헐 ? 디자인 장난아니다? 할 정도는 아니어도 되지만, 내 마음에 들어야한다  그래야 애정이 가고 블로그를 계속 가꾸어나갈 마음이 들기 떄문이다. 이 점에서 커스텀이 어려운 velog 는 탈락   진입 장벽  사실 이건 github 빼고는 다 동일하다. github은 jekyll 설정을 하고, 본인에게 맞게 디자인을 커스텀 하는 시간이 오래 걸리기에 저렇게 표시 해 두었다   기타  내 개인적인 의견들?  나는 노션을 매우 잘 사용 중이다. 수업 필기나, 미팅 일지라던가, 개인적인 여행 계획이나 등등 메모해야할 일이 있으면 거의 노션을 사용 중이다.  그렇기에 개인적인 글들과 공개하고 싶은 내용들을 분리해서 작성해야했는데 이 과정이 좀 귀찮았다  마찬가지의 이유로 네이버 블로그도 탈락.. 네이버 블로그는 이미 맛집 리뷰나 여행 리뷰로 사용 중이기에 나중 SEO 작업 등을 생각하면 적합하지 않았다.   결론  위의 내용에서 우선 순위가 큰 디자인 커스텀, 카테고리, 이미지 등을 고려했을 때, 결국 글 쓰는 것이 다소 불편 할 수는 있어도, 내가 원하는 대로 커스텀이 가능한 github blog 를 사용하기로 하였다.  그리고 노션으로 작성한 글을 markdown 형식으로 추출할 수도 있기에, 기존에 작성한 글을 쉽게 옮길 수 있다는 점도 큰 장점 !  ","categories": ["Github Blog"],
        "tags": ["Github","Blog"],
        "url": "/categories/develop/Github_Blog/intro",
        "teaser": null
      },{
        "title": "[OS] Ch1. Introduction",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    Operating System  - Computer System Sturcture의 component             HW : 기본 computing resource 제공   ex) CPU, Memory, I/O Device   Operating Systme : 여러 application과 user 간의 HW 사용을 제어하고 조정   Application Program : System resource 가 user computin probelm 을 해결하는데 사용되는 방식 정의    ex) word processes, web browser   User   ex) people, machines, other computer   - OS 란?      computer의 user와 computer 의 HW 간 intermediary (중개자) 역할을 함            HW control &amp; manage       basic application 제공           Goal of OS → 결국 성능을 어떻게 더 좋게 할 것인가 . .            user program 실행하고, user problem 을 쉽게 해결할 수 있도록 제어 서비스 향상       computer system 을 사용하기 쉽게 user 에게 편리한 환경 제공하지       computer HW 를 효율적으로 사용하게 system 성능 향상           - Definition of OS? OS 역할!      OS는 Resource allocator            모든 리소스 관리하고 할당하는 역할       효과적이고 공평한 리소스 사용을 위해 상충되는 요청들 (여러 application 이 동일 resouce 에 접근하는 경우) 사이에서 결정내려줌           OS 는 Program controler            application과 I/O device를 제어감       program 실행을 제어해서 computer 사용의 error 와 improper 방지              사실 보편적인 정의는 없음 . . → OS 명령 시 오는 모든 것 정도로 생각하면 ㅇㅇ   Kernel : computer 에서 항상 실행 중인 한 program 으로 OS 의 core part 임 → 그 외는 system program (OS 와 함께 제공) 이거나 application program 임   system program (system utllities)            OS 와 associated 이지만 kernel 의 일부는 아님       program 개발과 실행하는데 편한 환경 제공    ex) editer, compiler, debugger, shell …               Computer System Architecture   - Single Processor System      single general-purpose processor 사용   special-purpose processor 사용하는 경우도 있긴 함!            graphics controller 나 disk controller       여기선 user process 실행하지 않음           - Multi-Processor Systme      paraller system 이나 tightly-coupled system 이라고도 알려져 있음   장점            throughtput 증가       multi single processor system 보다 경제적임       신뢰성 증가 → 서로의 영역에 접근을 안해서, , ?           Type            Asymmetric Multiprocessor (AMP) : 각 process에는 특정 task 가 할당되어 그 task 만 수행함! 그리고 master / slave procesor 로 나뉘어 master 가 slave 들 scheduling 하거나 관리       Sysmmetric Multiprocessor (SMP) : 모든 process 는 동일하며 모든 task 수행 가능! → 일반적으로는 보통 이 type                   -&gt; CPU 간은 BUS 나 Switch 로 연결되어 있고, 각 CPU 는 identical                   - Multi-core Processor System      single chip 에 multi computing core 가 존재 → CPU 의 한 Chip 에 여러 core 가 존재   N-core 가 있는 multi-core processor 는 N standard processor 로 OS 가 인식함   Type            Uniform Memory Access (UMA) : 모든 core 는 모든 memory 모듈에 대해 동일한 access time 을 가짐       Non-uniform Memory Access (NUMA) : core 마다 각 memory 모듈의 access time 이 다를 수 있음                       UMA 는 물리적 거리가 같기에 접근 시간이 동일한데       NUMA 는 물리적 거리가 다르기에 접근 시간이 다름           - 용어 정리?      Processor : logical 실행 단위 or 물리적 chip을 설명하기 위해 사용 → CPU 자체를 의미하기도 함! 근데 multi-core 에서는 좀 애매해짐   Core : L1 cache 및 funtional unit 을 포함하는 logical 실행 단위 → Processor 에 포함된 작업 단위   Chip : computer 에 있는 물리적 intergrated circuit (IC)   Soket : computer matherboard (메인모드) 에 있는 물리적인 connector 로 signle phtsical ship 을 수용 → soket 여러개인 메인보드는 multi-core chip 을 수용할 수 있음   - Operating System Structure      효율성을 위해 Multiprogramming이 필요함!            why?     → single programe은 CPU 및 I/O 장치를 항상 사용할 수 없는데 (독점 못하니까 ㅜㅜ) user는 여러 program을 실행해야함       Multiporgramming은 작업(code &amp; data)를 organize하여 CPU가 항상 하나만 실행 할 수 있도록 해줌     → 여러 process 들이 CPU 사용할 수 있게       system의 전체 작업 중 일부는 memory에 보관됨       Job Scheduling을 통해 실행할 하나의 작업이 선택됨       대기해야 할 때 (I/O Burst) OS는 다른 작업으로 전환됨           Timesharing (Multitasking)은 CPU가 작업을 너무 자주 전환해서 사용자 작업이 실행되는 동안 해당 작업과 상호작용 할 수 있는 interactive Computing (대화형 컴퓨팅)을 만들어내는 logical extension            respones time (요청 보내고 응답 받는데 걸리는 시간) 이 1초보다 짧아야함       각 사용자는 momory에서 실행되는 적어도 하나의 프로그램을 가지고 있음 → process       여러 작업이 동시에 실행될 준비가 된 경우 → CPU Scheduling을 통해 나눠주는       만약 process가 memory에 맞지 않으면 swapping을 통해 momory 밖으로 옮겨 실행할 수 있도록 함       가상 momory는 완전히 memory 에 있지 않은 process의 실행을 허용함 → Ch9 에서 좀 더 자세히           +) 사실 명확하게는 multitasking이랑은 다름 ! Timesharing 은 CPU 시간을 작은 단위로 분할하여 여러 사용자가 동시에 접근 할 수 있게하는 것           Computer System Operation   - Computer System Operation      I/O device 와 CPU는 동시에 실행될 수 있음 → 그래서 I/O burst 와 CPU Burst 가 따로인겨 !   각 device controller는 특정 device type을 담당하고 local buffer를 가지고 있음   CPU는 Main Memory ↔ local buffe 양 방향으로 data를 이동시킴   Device controller는 Interrupt를 발생시켜 CPU에게 operation이 끝났다는 것을 알림   - Computer System Operation들           Interrupt : 중요 event를 알리기 위해 processor에게 전달되는 signal       ex) 마우스 클릭 이벤드              HW와 SW는 interrupt를 유발할 수 있음                intterupt는 interrupt vector를 통해 보통 interrupt service routine으로 control을 전달하며, 이 interrupt vector에는 모든 service rouine의 address가 포함되어 있음           → 어디부터 실행하면 되는지 알려줘서 control 전달                   +) interrupt service routine : Computer System에서 발생하는 interrupt를 처리하기 위해 미리 정의된 code block → 즉 발생했을 때 어떻게 처리할 것인지       HW-generated interrupt 는 OS   SW-generated interrupt 에는 Trap과 Exception가 있음                     Trap : OS service를 위한 software request → 개발자가 의도를 가지고 design한           ex) file open.. 과 같은 system call                        Exception : software error → trap과 달리 bug..           ex) division by zero                   [Interrupt 과정]      현재 실행 중인 instruction 완료 (중단)   user program의 state를 reg나 stack에 저장   고정된 위치 (서비스 루틴의 address) 곳으로 실행 이동   interrupt service routine 실행   저장된 user program의 state로 restore   1에서 중단된 user program 실행 재개      OS와 user는 computer system의 HW/SW resource를 공유함 → 여기서 OS의 user 신뢰 문제 발생…            user program이 다른 program 이나 system 을 kill 해서는 안됨       그래서 Dual-mode를 사용함 !!           - Dual-mode      OS가 자신과 다른 sysptem component들을 보호하도록 하기 위해 사용하는   User mode / kernel mode 로 나뉨   User mode : 제한된 operation만 수행 가능 → application은 기본이 이 mode   Kernel mode (supervisor, system, privileged) : 모든 operation 수행 가능 → kernel은 이 mode   Mode bit (HW 에서 제공)            system이 User(mode bit = 1) / Kernel code(mode bit = 0) 중 뭐를 실행하고 있는지 구별 할 수 있도록       특권으로 설정된 어떤 instruction (다른 user나 system에게 영향을 줄 수 있는)은 kenel에서만 실행 가능함 (only kernel mode)       system call은 mode를 kernel mode로 변경하고 실행한 다음 return 되면 user mode로 다시 변경함 → kenel 에서 실행되는 동작이라서                 system call이 될 경우 trap을 발생시키고, mode bit를 0으로 바꿈   그리고 system call 처리후에 bit를 다시 1로 돌린 다음에  return       Management   - Timer      무한 루프나 process가 과하게 resource를 차지하는 것을 막기 위한 방법 → OS 는 효율적이게 동작하기 위해 관리하는 manager니까   특정 주기 이후에 interrupt 설정되게끔 → 주기마다 작업이 실행            OS는 counter를 설정하고 매 clock tick 마다 counter를 감소 시킴       counter 가 0이 되면 interrupt 설정                control을 되찾거나 할당된 시간을 초과한 program을 종료시키기 위하여 process scheduling 전에 설정       → scheduling 전에 timer 확인! 그래야 지난 애 있으면 대기나 다른 상태로 바꿔야 schduling 때 처리되니까       - GHz      CPU 에서 GHz는 clock frequency이며, clock rate, clock speed라고 하기도 함   일반적으로 clock speed가 빠를수록 CPU가 빠름        clock speed는 CPU 가 초당 실행하는 cycle 수로 측정하며 그 단위가 GHz       ex) A CPU with a clock speed of 3.2 GHz executes 3.2 billion cycles per second.       - Process Management      process는 실행 중인 program이며, system내 작업 단위임   Program은 Passive(패시브 ㅇㅇ) entity이고, Process는 Active(실행 중인) entity → 즉 program 중 실행 중인 것이 process   Process는 작업을 수행하기 위해 resources 가 필요함            CPU, Memory, I/O, File       Initializaion data → Input 받거나 . .           process 종료시 재사용 가능한 resources 를 되돌려 받아야함 → 다시 반납하쇼   Single-threaded process는 하나의 program counter (PC)를 가지고 있다            program counter (PC) : 실행할 다음 instruction 의 위치 지정       process는 완료 될 때 까지 한번에 하나씩 순차적으로 inst을 실행함           Multi-thredaded process는 thread당 하나의 program counter를 가지고 있다   일반적으로 system은 하나 또는 그 이상의 CPU들에서 동시에 실행 중인 많은 process들(some user, some OS)을 가지고 있다.            process / thred 간 CPU multiplexing를 통한 concurrency (동시성)           Process Management Activities            CPU에서 process 및 thread scheduling       user &amp; system processes 생성 및 삭제       process 일시 정지 및 재개       process synchronization 를 위한 매커니즘 제공                    process synchronization : 여러 process가 공유 중인 resouce에 접근하려고 할 때 실행 순서를 제어하여 서로의 작업에 영향을 주지 않도록 하는 기술                       process communication 을 위한 매커니즘 제공                    process communication : 서로 다른 process 간 data나 masseage를 주고 받는 기술                           - Memory Management      processing 전 후의 모든 Data은 main memory 에 있음!   실행을 위해 memory 에 있는 모든 instruction   Momory management는 memory 에 저장될 내용과, 그 시기를 결정함            user를 위해 CPU utilization 와 computer response 최적화           Main Memory Management Acticities            현재 실행 중인 memory part와 누구에 의해 사용 중인지 추적       memory 안팎으로 이동할 process (또는 그 일부) 및 data 결정       필요에 따라 memory 공간 할당 및 할당 해제           보조 기억장치도 관리해요 !   - Storage Management      OS는 information storage 에 대해 균일하고 논리적인 view를 제공            물리적 속성을 논리적 storage 단위인 file로 abstract → file 의 기본 컨셉       각 media 은 device (disk srive, tape drive)에 의해 control 됨                    access speed, capacity, data-transfer rate, access method (sequential or random) 이 속성에 포함되어 있음                           File-System Management            일반적으로 file은 directory들로 organiz됨       누가, 무엇에 access할 수 있는지 셜정하기 위해 대부분의 system에 대한 acces control       OS Activities                    file &amp; directory 생성 및 삭제           file &amp; directory 조작을 위한 primiotives           보조 storage에 file mapping           안정적인 (non-volatile) storage media에 file backup                   +) 어떻게 power 없이 안정적으로 file을 storage할 것인지가 OS에서는 중요한 도전과제                  ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch1",
        "teaser": null
      },{
        "title": "[OS] Ch2. Operating-System Structure",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    OS Services              OS Services    - Operating System Service      OS 별로 차이가 있긴 하나 보통 다음 4가지의 service로 구성            Booting Service : Couputer HW를 관리하고 Program을 실행 할 수 있도록 부팅함       User Service : 프로그래머가 programming 작업을 쉽게 할 수 있도록 함       System Service : System 이 효율적으로 동작하도록 보장       System Call : Program과 OS 간의 interface 를 제공하여 System 기능을 사용 할 수 있도록           -  User Service           User Interface :  대부분의 OS는 user unterface (UI)를 가지고 있음       ex) Comman-Line(CLI), Graphics User Interface(GUI) 등..            Program Execution : system은 program을 memory에 로드, 해당 program을 실행하고 정상 또는 비정싱 시 실행을 종료 할 수 있어야 함       ex) 메모리 할당, 해제, 프로세서 스케줄링       I/O Operation : 실행 중인 program에는 I/O가 필요할 수 있음! OS 는 I/O 동작 방법을 제공   File-System Manipulation : program은  file과 directory를 읽고 쓰고, 생성하고, 삭제하고, 검색하고 나열하고 권한을 관리해야함   Communications(통신) : proces는 같은 computer 내  process들이나, 네트워크로 연결된 다른 computer의  process들과 information을 교환할 수 있음            공유 memory 나 message 전달을 통해 통신이 이루어질 수 있음           Error Detection : OS 는  가능한 모든 HW/SW 수준에서의  error을 탐지하고 system을 모니터링하여 조정함으로 HW 문제를 예방해야함            user program, CPU, memory hardware, I/O device 등에서의 error 탐지       각 error에 대해 OS는 적절한 조치를  취해야함!       Debugging facilites가 도움이 될 수 있음           - System Service      Resource Allocation : 다수의 user나 job이 동시에 실행 될 경우 각각에 res를 할당해주어야함            다른 scheduling 방식을 가진 여러 종류의 resource 존재           Accounmtin / Logging : 어떤 user가 어떤 종류의 resource를 얼마나 많이 사용하고 있는지 정보를 저장하고 추천            user service를 개선하고 system을 재구성하는 연구, 통계 자료로도 사용           Protection and Security : computer system에 저장된 정보의 소유자의 사용을 제한할 수 있음. 그리고 서로 관련이 없는 여러 perocess이 동시에 실행 될 때는 다른 process나 OS를 방해하지 못하도록 보호해야함            Protection : resource에 대한 모든 액세스를 제어       Security : 외부 I/O를 방어하고 외부 user에 대해 인증을 요구               System Calls   - System Calls      OS에서 제공하는 service에 대한 programming interface → 실행 중인 prgram과 OS 간의 interface   일반적으로 high-level language인 C/C++ 로 작성됨   직접적인  system call 사용이라 아니라 주로 high-level  Application Program Interface (API)을 통해 system call 에 엑세스            potrability (이식)이 편함 system call은 더 자세하고 작업하기 어렵기 때문에!           일반적인 3가지 API            Window를 위한 Windows API       POSIX-based system(모든 버전의 UNIX, Linux, Mac OS X 포함)을 위한 POSIX API                    휴대용 OS Interface (POSIX) : OS 간의 호환성을 위해 IEEE가 정한 표준 제품군                       Java Virtual Machine (JVM)을 위한 JAVA API                ex)                 한 file의 내용을 다른 file로 복사하는 system call                           standard api         - System Call Implementation      System call interface는 API에서 function call을 가로채 OS Kernel에서 의도한 system call을 호출하고, system call의 state, 및 returen value를 반환함   일반적으로 각 system call에는 번호가 할당됨            system call interface는 이러한 번호에 따라 indexing된 table 을 유지, 관리함           caller는 system call이 어떻게 구현되어있는지 알 필요가 없음.            그냥 API를 따르고 호출 결과로 OS 가 수행할 작업만 이해하면 됨 → 걍 쓸거니까,,       API에 의해 OS Interface의 자세한 부분은 programer에게 숨겨짐              API - System Call - OS 관계도           User Application이 open()이라는 system call을 호출한 경우            Application이 open()이라는 system call 호출       system call interface는 open()의 system call number를 확인하고, 이를 실행하기 위해 kernel mode로 변경       kernel mode 에서 open()에 필요한 parameter들을 검사       file system 에서 file의 meta data를 읽어와 File Descriptor에게 할당하고, file table에 등록       File Descriptor는  open() 의 반환 값으로 user application에게 반환됨       반환된 File Descriptor를 이용하여 user application은 file을 읽거나 쓸 수 있음           - Standard C Library Example          Standard C Library 는 Linux와 UNIX 에게 일부 system call interface를 제공함   C program에서 printf()를 호출하면, system call인 write()를 호출함       OS Design and Implementation (OSDI)   - OS Design and Implementation      OS 의 Design과 Implementaion은 해결하지 못 하는 문제이지만, 일부 approache들은 성공적으로 증명되었다 → 나중에 나와요   다양한 OS 내부 구조들은 크게 달라질 수 있음   Goal과 Specification을 먼저 정의해서 OS 설계를 시작해야함!   System design은 HW 선택과 system type에 의해 영향을 받음            Batch, time shared, single user, multiuser, …           User goals &amp; System goal            User goal : OS는 사용하기 편하고, 배우기 쉬우며, 신뢰성이 있고, 안정하고 빠르게 동작해야함       System goal : OS 는 설계, 구현, 유지 보수가 용이해야하고, 유연하,며 신뢰성이 있으며, 오류가 없고, 효율적이어야함           OS의 requirement를 정의가 (정의하는 솔루션이) 유일한 것은 아님!!            다양하기에 OS 가 다양한 것           -  Seperate Mechanism &amp; Policy      Mechanism와 Policy를 분리하는 것이 OS 설계 및 구현에서의 중요한 principle            Mechanism : 어떻게 할 건가?       Policy : 무엇을 할 건가?           ex) CPU 보호를 보장해야함!!       →  Mechanism : Timer 구조를 사용하자, Policy :  특정 user에 대해서 timer를 얼마나 길게 설정하지?            Mechanism와 Policy를 분리는 policy 결정이 나중에 변경되는 경우에 대처할 수 있는 유연성을 제공함       ex) CPU-intensive 한 program보다 I/O-intensive한 program에 우선순위를 부여하는 policy           OS Structure   - Simple Structure (Monolithic, 단일구조)      OS 기능을 kernel 과 동일한 memory 공간에 두고 system call 만으로 사용함   Not Well-definde인 구조   작고 단순하며 제한된 system으로 시작하여 성장!   module로 나누지 않음   [MS-DOS]         초기에는 memory 공간이 제한적이었기에, 최대한 적은 공간을 차지하면서 최대한 많은 기능을 제공하기 위해 초기에 작성됨   처음에는 간단한 OS 였지만, 시간에 따라 컴퓨터 기술이 발전하면서 새로운 기능이 계속해서 추가됨 → 초기에 계획된 제한적 범위를 넘어섬   초기에는 I/O Interface와 level이 분리되어 있지 않아 application이 직접 I/O Device에 접근할 수 있음            오작동과 악성 프로그램의 위험성이 높았음 ㅠㅠ           그 당시 HW 도 제한적이었기에 Dual Mode를 지원하지 않았음            그렇기에 이러한 HW에서도 잘 동작되도록 개발           [Traditional UNIX (Monolithic)]         매우 광범위한 기능이 Kernel에 집약되어있음                     Kernel 아래 System call interface 이하의 모든 기능이 kernel에 통합됨 (단일층 . .)           → kenel은 OS 에서 거의 모든 일을 처리함                   매우 적은 Layering (계층구조)을 가지고 있으며, 두꺼운 monolthic layer로 구성되어 있다.            적은 만큼 각 계층간 interface가 충분하지 않기에, 구현과 유지보수가 어려움           즉. Tranditional UNIX는 기능이 통합된 kernel과 layering이 얇은 구조로 인해 확장성이 제한적이며, 구현과 유지 보수가 어려움   [Monolithic Structure]                 OS는 system Call Interface 아래 하나의 장소에 모두 포함   Application은 system call interface를 사용하여 kernel과 상호작용   ex) Unix, Window XP, Linux과 같은 상용 system에서 일반적으로 사용   장점            성능 우수 → 직접 통신이라       kernel 개발자가 쉽게 개발 할 수 있음           단점            kernel component 간 보호 없음 → 다 통합된 공간에 있으니..       쉽게 확장되지 않음 → 다 kernel 에 넣어야해서       전체 구조가 복잡해짐       하나에 문제가 발생하는 순간 어디에 문제가 발생한 것인지 몰라 복구 어려움           - Layerd Approach                  OS 는 하위 layer위에 구축된 여러 layer (level)로 나뉨            The bottom layer (level 0) : HW       The highest Layer (level N) : User Interface           Moularity를 통해 각 layer는 하위 level layer의 functions(operations) 및 service만을 사용하도록 선택            자신보다 하위인 layer에서 제공하는 functions(operations) 및 service를 이용해 본인 layer를 구축함           장점            각 layer가 서로 분리되어있기에 보안이 강화       각 layer의 문제가 전체 system에 영향을 미치는 것을 방지할 수 있고 독립적으로 디버깅 및 교체 가능                    low-level routines의 구현 세부사항을 숨김                       유연하고 확장성이 높은 OS를 만드는데 유용함           단점            여러 layer를 적절하게 정의하는 것에 어려움이 있을 수 있음       효율성 → layer가 많을 수록 function간 더 많은 Indirection (간접 참조)가 필요하고 이로 인해 function overhead가 커짐           - Microkernels System Structure      Microkernel은 필수적인 OS 기능만을 포함시킨 축소된 OS core   기존 OS에서 kernel에 있던 기능을 user space로 옮겨, kernel에는 기본적인 기능만 남겨둠 → 필수만 남긴다!   Kernel에 남긴 기능            기본적인 Memory 관리       I/O와 iterrup 관리       Process간 통신       기본 Scheduling           전통 OS에 포함되는 많은 service들이 User Process로 동작            Device driver       File system       Virual Memory 관리       Security sercvice       etc..           example: QNIX, Tru64, UNIS, Mach        User modules간 통신은 message passing을 통해 이루어짐       ex) 디스플레이를 필요로 하는 클라이언트 프로그램은 마이크로커널과 메시지 교환을 통해 간접적으로 디스플레이 서비스와 통신                   장점            확장성 : 새로운 서비스를 Kernel이 아닌 user space에 추가하므로, microkenel 기반 OS를 확장하는 것이 더 쉬움       호환성 : Microkernel만 변경하고 그 외의 service는 변경하지 않아도 되기에 다른 CPU로 port하는 것이 쉬움.       신뢰성 &amp; 보안성 : 많은 코드가 kenel mode에서 실행되지 않기에 User space service의 error가 kernel space에 영향을 주지 않아 안전함           단점            Performance overhead : User space와 kernel space 사이에 통신이 많기에 이에 따라 overhead가 발생 할 수 있음       Communication from User space to Kernel space : 사용자 공간의 서비스가 커널 공간과 통신할 때 보안 문제가 발생 가능성                Layer VS Mocrokernel                   - Modules      많은 최신 OS는 kernel module을 구현함   Object-oriented approach와 유사함            각 core component는 분리되어 있음       각 component은 알려진 interface를 통해 다른 component와 통신함       필요한 경우 kernel 내에서 load 가능함           전반적으로 layer 구조와 비슷하지만 더 flexibility함            어떤 module도 다른 module을 호출 가능함!           Modules은 microkernel 방식과도 유사하지만, Modules은 kernel 내부에 있으며 통신을 위한 message passing이 필요하지 않음   [ex. Solaris Modular Approach]          Core Kernel 을 중심으로 7가지 type의 module로 구성한 소프트웨어 모듈화 접급 방식            scheduling classes       file systems       loadable system calls       executable formats       STREAMS modules       miscellaneous       device and bus drivers          ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch2",
        "teaser": null
      },{
        "title": "[OS] Ch3. Processes",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    Process Concept   - Process Concept                    Process : 실행 중인 progeam → 실행되었으니 memory 에 적제되었고, 자신만의 memory 영역이 있는 것 !   Process 실행은 무조건 순차적으로 실행되어야 함   Process에 포함 된 것            Text Section (loaded Progeam)       Program Counter       Stack (Temporay data) : 함수 parameter나, reture address, local variable을 저장하는 일시적인 memory 영역       Head : 동적으로 할당된 memory → Stack 이랑 비슷하지만 동적으로 할당된다는 점이 다름! 더 static하고 global함       Data Section (Global Variables) : Global variable등 초기화된 data를 저장           - Process State      Process가 실행되는 동안 process의 state는 계속해서 변경됨            new : Process가 생성되는 중       running :  Instriction이 실행되고 있는 상태       waiting : Process가 어떤 event가 발생하기를 기다리는 중       ready : Process가 processor에 할당되기를 기다리는 중       terminated : process가 실행을 완료함               - Process Lift Cycle          New → Ready : 새로 생성되는 New에서 실행 가능한 상태인 Ready 로 전환   Ready → Running : Kernel이 scheduling 할 때 process는 ready 상태에서 running으로 전환   Running → Waiting : 만약, Process가 blocked되어 event가 발생하기를 기다린다면 waiting으로 전환 ex) I/O   Waiting → Ready : Event가 완료되면 다시 Ready 상대로 전환   Running → Ready : Interrupt가 발생하면 실행 되다가 다시 실행 가능 상태인 ready로 전환   Running → Terminated : exit()가 호출되면 실행 완료한 것이므로 종료하기 위해 terminated로 전환   - Process Control Block (PCB)         Particular process를 관리하기 위해 필요한 정보가 포함된 OS의 데이터 구조   각 Process와 관련된 정보들 → OS에서 process를 표현하는 .. !            Process State       Program Counter       CPU registers       CPU Scheduling information       Memory-management information       Accountin information       I/O status information           Process Scheduling   - Context Switch          P1가 CPU 사용중인 상황인데, P2가 CPU를 사용해야하는 일이 발생   Kernel의 Interttupt Handler가 P1을 중지하고 PCB0에 P1에 대한 정보(reg 정보, process state 등)를 저장함   다음에 실행할 P2에 대한 정보를 PCB1에서 가져옴   Interrupt Handler는 다시 CPU를 P2에 할당하고, P2에서 PCB1에서 받아온 reg 정보, process state를 읽어와 CPU가 실행하도록 함   P2 실행            CPU Switch from Process to Procee       CPU가 다른 process로 전환된다면 system은 무조건 이전 process의 state를 save하고, 새로운 process의 state를 load 해야함       Process의 Context는 PCB로 표현됨       Context Switch 과정은 사실 유용한 작업을 수행하는 것은 아니고 단지 전환이기에 순전한 overhead 임 ㅜㅜ       switch되는 속도는 memory 속도나, 복사해야하는 reg 수 등등에 따라 달라짐                 보통은 마이크로 초 단위           - Process Scheduling Queues           Job Queue : System의 모든 실행 가능한 process들의 set   Ready Queue : Main memory에 상주하며, 실행될 준비가 되었거나(ready) 기다리는 (waiting) 상태의 process들의 set   Device Queue (I/O wait Queue) : I/O Device를 기다리는 procee들의 set            process는 다양한 Queue들 사이에서 이동함       Queue는 보통 linked list로 구현       Process schduling하는 과정 Queueing-Diagram으로 표현                            Process는 I/O request를 발생 시킨 후 I/O Wait Queue에 추가될 수 있음       process는 새로운 child process를 생성한 다음, child의 종료를 기다리는 동안 ready Queue에 추가될 수 있음       Process가 interrupt 또는 time slice expired에 의해 강제로 core 에서 제거 되었다면 Ready Queue에 추가될 수 있음           - Schedulers      Long-term Scheduler (Job Scheduler) : Ready Queue로 추가할 process 선택하는 것이 목적            매우 드물게 호출 : (second, miniutes) → 느려도 괜찮앙       Degree of multiprogramming를 제어           Short-term Scheduler (CPU Scheduler) : 다음에 실행되고 CPU에 할당할 process 선택하는 것이 목적            매우 자주 호출 : (milliseceons) → 빨라야함!!           Process는 둘 중 하나로 설명 가능            CPU-bound-process : 계산에 더 많은 시간을 소비하고, 적고 긴 CPU Burssts → Long-term                    그래서 Long-term Scheduler는 결정을 신중해야해야함..                       I/O-bound-process : 계산보다 I/O 를 수행하는데 더 많은 시간을 소비하고. 많고 짧은 CPU Bursts →Short-term       CPU Bursts : Process가 CPU를 사용하는 시간               +) Medium-term Scheduler :   Time-sharing system 에서 Degree of multiprogramming (동시에 실행 중인 program 수?)를 줄이기 위해 process를 memory에서 temporarily(일시적)으로 제거함  → 나중에 process 재시작함!!   → Swapping       Operation on Processes   - Process Creation (프로세스 생성)          Creating precess를 Parent Process라고 하고 이때 생성되는 새 process를 Child Process라고 함 → Parent가 Child Process 생성   생성된 Child Process가 또 다른 Process를 생성하면서 Process tree를 만듦   일반적으로 Process는 식별자(PID) 를 통해 식별되고 관리됨   Resource Sharing            부모와 자식은 모든 리소스를 공유 → 둘 다 동일한 리소스에 접근 가능       자식은 부모의 일부 리소스를 공유 → 자식은 부모의 일부 리소스에만 접근할 수 있음       부모와 자식은 리소스를 공유하지 않음 →  서로 독립적           Execution            부모와 자식이 동시에 실행       부모는 자식이 terminate될 떄 까지 wait           Address Space            자식은 부모의 duplicate       자식은 새로운 program을 load           - Process Creation in UNIX      UNIX에서 process를 생성하는 system call들           fork() : 새로운 process를 생성함! → 부모 process의 모든 것을 그대로 복제시켜 자식 process 생성   exec() : Process의 memory space를 fork로 생성된 새 process로 대체하기 위해 fork 다음으로 실행되는 system call            fork할 때 부모를 그대로 복제하면서 메모리 공간도 그대로 복제시켜버림..       복제된 process가 같은 program이 아니라 다른 program을 실행시켜야 하므로 새 memory space로 덮어씌움           → 즉 그대로 복제 한 다음에 실행할 program 으로 덮어씌우는 형태로 보통 fork-exec  같이 사용함       wait() : 부모에 의해 호출됨! 자식 process가 종료 될 떄 까지 부모 process를 일시적으로 중단하고 대기시킴   exit() : 호출한 prcoess를 종료   - Process Termination      process는 마지막 statement를 실행하고 OS에게 삭제를 요청하여 종료함 (exit)            Process는 부모에게 state value를 return할 수도 있음 → wait를 통해!       Process의 리소스는 OS에 의해 해제됨           부모는 자식 process의 실행을 종료 시킬 수도 있음 (abort)            자식이 할당된 리소스를 초과하는 경우       자식에게 할당된 작업이 더 이상 필요하지 않은 경우       부모가 종료된 경우                    일부 OS는 부모가 종료되면 자식의 계속 실행을 허용하지 않는 것도 있음 → 그럼 이제 모든 자식이 연쇄적으로 다 종료되는..                           Interprocess Communication   - Cooperating Processes (협력 프로세스)      Cooperating Process는 독립적인 proces와 달리 다른 process의 실행에 영향을 줄 수도, 받을 수도 있음!!            +) 독립적인 Process는 다른 process의 실행에 영향을 줄 수도, 받을 수도 없음       서로 상호작용하면서 특정 기능을 수행           장점 (Process Cooperation 환경을 제공하는 이유)            정보 공유 : 같은 데이터에 여러 user가 관심을 가질 수 있음 (ex. shared files) 그러면 제한된 리소스 사용 효율성 증가       연산 속도 향상 : task를 subtask로 나눠서 병렬로 실행할 수 있음       모듈성 : 모듈 방식으로 system을 디자인하면서 system function을 separeate process로 나눌 수 있음       편리성 : 동시에 개별 사용자가 많은 task를 를 수행 할 수도 있게 됨           단점            병행 process간의 synchronization 되어야한다는 문제와 이때의 reace condition           - Interprocess Communication (IPC)      Process간 통신하고 synchronize하는 매커니즘!        IPC에는 2가지 모델(방법)이 있고 둘다 OS에서 일반적으로 사용             왼) Message Passing         오) Shard Memory                        Shard Memory : 동일한 주소 공간과 공유 변수 사용 → 즉 공유되는 memory 공간이 있다는 뜻                    어디에 메모 남기고 가면 다른 사람이 보고 확인하는 방식이랑 비슷 ㅋㅋ           system call은 공유 memory 영역을 설정하는데만 필요함           모든 access는 routine memory access로 처리됨                       Message Passing : 공유 변수에 의존하지 않고 process가 각각 통신함                    카톡 보내는거랑 비슷합니다요           작은 양의 data(simple data)를 교환하는데 유용함           충돌 없이 구현하기게 쉬움                           - Shard Memory      통신하는 Process간 공유되는 memory 공간이 있음   통신은 OS가 아닌 User process의 제어 아래에 있음 → User process에 따라서 통신   User process가 공유 메모리에 접근 할 때 동기화 하는 방법을 제공하는 것이 가장 큰 문제! → Producer - Consumer 문제   동기화에 대해서는 나중에 . . .   - Producer - Consumer Problem (in shard memory)           Cooperatin process의 패러다임, 생산자 프로세스는 소비자 프로세스가 소비하는 정보를 생산함       → 정보가 없는데 소비자가 소비하려하거나, 정보가 가득 찼는데 정보를 생성하려는 문제가 발생하지 않도록       공유 memory는  Buffer를 사용하여 Buffer의 item이 Producer에 의해 채워지고, Consumer에 의해 비워지는 방식 사용            동시에 접근하는 문제를 해결하기 위한 방법임!           Unbounded-Buffer            Buffer의 크기에 실질적인 제한을 두지 않아 producer는 항상 생산하도록       Consumer는 buffer가 empty라면 기다려야함           Bounded-Buffer → Circular Buffer            Buffer의 크기가 고정되어있다고 가정하여 Producer는 buffer가 가득 찼다면 기다려야함       Consumer는 마찬가지로 buffer가 empty라면 기다려야함           [Bounded-Buffer]   #define BUFFER_SIZE 10  typedef struct { \t... } item;  item buffer[BUFFER_SIZE];  int in = 0;          // point to next free position (Producer가 생성해서 넣을 위치) int out = 0;         // point to first full position (Consumer가 받을 위치)*          If in == out : Buffer is Empty → 넣을 곳과 가져올 곳이 동일하니   If ((in+1) % BUFFER_SIZE) == out : Buffer is Full → 넣을 곳 다음이 바로 가져올 곳이니 한바퀴 돌았다는 뜻            왜? in+1 == out  이면 가득찼다는 것인데 overflow 방지를 위해 순환식으로 사용하다보니까 모듈값이 out이 되어야함                이 해결 방법이 제대로 작동하긴 하지만 BUFFER_SIZE-1 개의 element만 사용할 수 있다는 단점이 있음       → Full 일 때 in과 out 이 차이가 나야 Full 과 Empty 구별가능하니까 하나 비워두기       // Producer while (true) { \t/* Produce an item */ \twhile ((**(in + 1) % BUFFER_SIZE)**  == out);    /* free buffer가 없는 동안에는 (full 상태) 아무것도 안함 */   \t/* full 이 아니면 */ \tbuffer[in] = item; \tin = **(in + 1) % BUFFER SIZE**;                 /* overflow 방지하기 위해 순환방식을 사용하고자 modular */ }  // Consumer while (true) { \twhile (in == out);                           /*  buffer 안에 아무것도 없는 동안 (empty 상태) 아무것도 안함 */  \t// remove an item from the buffer \titem = buffer[out];  \tout = **(out + 1) % BUFFER SIZE**;               /* overflow 방지하기 위해 순환방식을 사용하고자 modular */ }*   - Message Passing      Process간 서로 통신하고 행동을 동기화하는 매커니즘 → 동기화한다는 점에서 공유 메모리랑 다르죠            shard memory 는 mem 을 동기화, 얘는 행동을 동기화           동일한 주소 공간을 쓰지 않고, Process간 직접 통신하고 동기화할 수 있도록 허용   Direct / Indirect 2가지 통신이 있음            Direct는 누구한테 보내고 받는 지를 명시 → 직배송       Indirect는 mail box같은 것을 통해서 전달함 → 배대지 사용하는 느낌?           2가지 Operation (직접 통신 버전) 제공            Send(receiverID, message) → message size는 구현에 따라 고정일 수도 있고, 변수일 수도 있음                Receive(senderID, message)           *  Indirect였다면 ID 가 아니라 mailbox 위치가 파라미터로 사용                   두 Process간 통신 할 때 다음 과정이 필요            그들간 communication link 설정 → 통신망 느낌       send/receive 를 통해 message 교환                    Soket programming처럼 soket만들고 연결 link 만들고 soket 보내는 방식과 유사                           구현 문제..            link 어케 설정해?       모든 통신 process 쌍 간에 몇개의 link가 있을 수 있을까?       link의 capacity는?       message 크기는 고정이야 가변이야?       link는 단방향이야 양방향이야?           - Synchronization (in message passing)      message passing 에는 block / non-block 방식이 있음   Blocking → rendezvous (랑데뷰) 방식            Synchronize로 간주됨 (응답 올 때 까지 대기! 암거도 못해!)       Block-send : Sender가 msg 보낸 후, Reciver가 받을 때 까지 Send를 block (sender 아님!!! send method를 블락한다는거)       Block-receive : Msg를 사용할 수 있을 때 까지 Receive를 block (reveiver 아님!!! receive method를 블락한다는거)           Non-blocking            Asynchonize로 간주됨 (응답 오던 말던 다 함 ㅋ)       Nonblock-send  **:** Sender가 msg보낸 후에도 계속 send 할 수 있도록 허용       Nonblock-receive : vaild message나 null을 retrieve할 수 있도록 허용 (받는 담에 vaild일 떄만 ㄹㅇ 받아융)           non-block 방식이 더 유용함!   message next_produced;   while (true) { \t/* produce an item in next produced */ \tsend(next_produced);  // 계속 보냄 }  message next_consumed;   while (true) { \treceive(next_consumed); // -&gt; 일단 받고 ㅋㅋ \t/* consume the item in next consumed */  }*   - Buffering      Indirect 방식에서 사용 . . ? Message 수용하는..   Link에 message Queue를 연결하는 방식으로 다음 3가지 중 보통 하나는 사용            Zero capacity : 0 message 가능                 Queue의 수용 공간이 0이라 msg 보관이 안됨       그렇기에 sender는 receiver가 받을 때까지 기다려야함 (block) → rendezvous (랑데뷰) 방식                    Bounded capacity : 유한한 N 개의 message 가능                       N 길이의 Queue를 가짐       Link가 Full이라면 sender는 기다려야함 (block)                    Unbounded capacity : 무한한 message . . 가능                       Sender가 기다릴 일이 없어용 ~  !          ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch3",
        "teaser": null
      },{
        "title": "[OS] Ch4. Thread",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    Overview   - Threads      Instructions Sequence를 실행하는 CPU utilization의 기본 단위 → 실행 단위 !            OS scheduler가 독립적으로 관리하는 가장 작은 sequence       자체 Thread ID, Program Counter(PC), Register set, Stack 를 가지고 있음           Process는 하나 이상의 Thread를 가질 수 있고, 하나 이상의 task를 동시에 실행할 수 있음            process의 다른 thread과 reaource (code, data section, heap…) 를 공유하기에 lightweight       프로세스와 비슷한 lifecycle을 가짐 → ready, waiting, running           Single processor에서 multithreading은 일반적으로 multiplexing에 의함            single processor 라서 multiplexing 하려면 한 processor 내에서 thread간 전환이 굉장히 빠르고 자주 발생 해야함.. → context switch 로 인한 overhead           Multiprocess (including multi-cores)에서 thread는 실제로 동시로 실행 될 수 있으며, 각 core는 특정 thread를 실행         - 왜 Threads 방식을 사용했을까?      경우에 따라서 하나의 application이 동시에 여러 task를 실행해야하는 경우가 있음. 근데 이때 모든 task마다 새로운 process를 생성하기에는 시간이랑 리소스가 너무 많이 소모됨 ㅜㅜ   그래서 하나의 process에 task를 실행할 수 있는 thread를 여러개 두는 방식을 사용!   장점            빠름!       생성, 전환에 드는 ovehead가 적음       동일한 주소 공간을 공유할 수 있음           - Multithreaded server           하나의 process에서 여러 비슷한 task를 수행하는 경우의 예시 ex) 웹서버                   웹 서버는 클라이언트 요청을 받는데, 이 클라이언트가 동시에 굉장히 많을 수 있음        기존의 단일 threas process로 실행된다면, 한번에 하나의 클라이언트에게만 받은 요청에 대한 서비스를 제공 할 수 있어서 다른 클라리언트들은 굉장히 기다려야했음 ㅜㅜ       → 이걸 요청을 처리하는 별도의 thread를 만들어 해결! 즉, 요청 처리하는 thread 따로 있도 다른 사용자 상호작용이나 그런 작업하는 thread 따로 있는       client가 server에 요청을 보내면, 새로운 thread를 만들어 요청에 대한 서비스를 하도록하고, server는 계속 클라이언트들에게 요청을 받음   장점            Responsiveness :                    일부 part가 block되거나 긴 작업을 수행하는 동안에도 application은 계속 실행될 수 있음 → 사용자에 대한 응답성 향상           그니까 버튼을 눌렀는데 시간이 겁나 오래 걸리는 동작일 경우.. 이 시간에도 다른 요청을 받을 수 있게 됨                       Resource Sharing :                    Process는 원래 공유 메모리나 메세지 전달과 같은 기술을 통해서만 리소스를 공유할 수 있음           근데 Thread는 기본적으로 자신이 속한 process의 memory와 resource를 공유함           그렇기에 application이 동일한 주소 공간 내에서 여러 실행 중인 thread를 가질 수 있음                       Economy :                    process 생성을 위해 매 process 마다 memory와 resource 할당하는 데는 비용이 많이 듬.. ㅜㅜ           근데 thread는 그냥 자기가 속한 process의 memory와  resourc를 공유하므로 따로 할당안해줘두 됨 ! 그래서 차라리 thread만들고 전환하는게 더 경제적                       Scalability :                    다중 CPU system에서 multithreading사용하면 병렬 처리가 더 증가됨           즉, multithreading의 장점은 서로 다른 processing core에서 병렬적으로 thread가 실행 중인 multiprocess 구조에서 더 커짐           단일 thread process는 짜피 한 process니까?                           - Multicore Programming      Multicore or Multiprocessro system은 다음과 같은 이유로 프로그래머에게 압박감을 줌 ㅠㅠ            Dividing activities, Balance, Data splitting, Data dependency, Testing and debugging           Concurrency(동시성)는 하나 이상의 작업 진행을 할 수 있음을 의미   Parallelism(병렬성)은 System이 하나 이상의 작업을 동시에 수행 할 수 있음을 의미        즉, Concurrency는 동시에 실행되는 것 처럼 보이게 하는 것으로 single-core, multi-core 둘 다 가능하며, Parallelism은 실제로 동시에 수행되는 것으로 multi-core에서만 가능한 개념                          Concurrency은 동시에 실행되는 것 처럼 Thread를 왔다갔다 거리며 실행하지만, Parallelism은 여러 core로 실제로 동시에 실행시킴. (1,2) (3,4) 이렇게           Type of Parallelism            Data prarallelism - 동일한 데이터의 subset을 여러 core에 분산, 각 thread는 동일한 operation 을  각각 수행       Task parallelism - core 에 thread를 분산, 각 thread는 고유한 operation 수행               Multithreading Models   - Multithreading models      Kernel Threads : Kernel에서 지원 받음            ex) Windows, Solaris, Linux, Mac OS X 등을 포함한 거의 모든 일반적인 OS           User Threads : user-level therad library에 의해 수행되는 management            3가지 중요한 thread library                    POSIX Pthreads           Win32 threads           Java threads                           - Kernel Threads      Kernel (OS) 가 직접 관리하는 thread로, Kernel은 System call에 의한 생성되고 파괴되는 thread를 모두 알고 있음   그렇기에 thread가 차단되면, 전체 thread 를 차단하지 않고 다른 thread를 예약할 수 있음   Thread 기반으로 Fine-grain 수행            Fine-grain : 하나의 작업을 작은 단위로 나눈 뒤, 다수의 호출을 통해 작업 결과를 생성하는 방식       Kernel은 thread를 관리하기 위해 process scheduling algorithms을 사용함           kernel mode 권한 관련에 의해 thread 전환이 무거움   - User Threads      Kernel은 user-level thread의 존재를 알지 못하고(인식하지 못함), thread가 포함된 process만 알고 있음 → 즉 process 단위로 인식   Thread management는 user-level therad library에 의해 수행됨            개발자는 thread 라이브러리를 사용해서 thread를 관리 (생성, 삭제, 예약 전환 등..) 함           Thread가 차단되면, processd의 다른 모든 thread를 포함한 전체 process가 종료됨            Thread block → process block → process 내 다른 thread도 block           Kernel은 thread가 아니라 process를 scheduling 함 → thread는 user-level에서 관리하니까   kernel mode 권한이 필요하지 않아서 thread 전환이 가벼움   - 다양한 Multi-threading Models      궁극적으로 user thread와 kernel thread 사이에 관계가 무조건 존재해야함   그 관계의 종류            Many-to-One       One-to-One       Many-to-Many           → user가 하나고, 여러개의 kernel 가 있을 순 없으니 . .       - Many-to-One Model (user-level thread)      여러개의 user-thread가 단일 kernel-thread에 매핑됨 → kernel 이 process 단위로 관리   지금 이 모델 사용하는 경우는 거의 없음!   장점            Thread management가 user space에서 이루어짐 →즉, scheduling 이 user-threas library 에서 이뤄져서 효율적임!           단점            Thread가 block되면, 전체 process도 block 된다는 문제점 ㅜㅜ → kernel 이 process 단위로 인식하다 보니까       process단위로 kernel 이 관리하다보디 process 단위로 할당해서 Thread의 병렬 실행이 없음 ㅜㅜ 그래서 multiple CPU를 이용 할 수 없다 !           ex) Solaris Green Threads, GNU Portable Threads       - One-to-One Model (kernel-level thread)      각 user-threaed가 kernel-thread에 매핑됨 → kernel 이 process 내 thread 단위로 관리   장점            Thread를 block해도 다른 thread가 block 되지 않음       parallelism이 증가해 multiprocessor 성능이 향상됨           단점            User-thread를 생성하려면, kernel-thread도 생성해야함 → 그렇기에 overhead가 증가하고 thread 수에 제한이 생김           ex) Windows NT/XP/2000, Linux, Solaris 9랑 그 이후 모델들       - Many-to-Many Model      여러 user-thread가 여러 kernel-thread에 매핑 할 수 있도록 허용   OS가 충분한 수의 kernel-thread를 생성할 수 있도록 허용   장점            parallelism이 증가해 multiprocessor 성능이 향상됨           단점            일반적으로 구현하기에 복잡함 ㅜㅜ           ex) Solaris prior to version 9, Windows NT/2000 with the Thread Fiver package       - Two-level Model      Many-to-Many랑 비슷하지만, 얘는 user-thread와 kernel-thread간의 bound를 허용한다는 점이 다름            Bounded threads : User thread 가 지정된 단일 kernel thread (전용.. 인 느낌)에 영구적으로 매핑       Unbounded threads : User thread 가 set내의 kernel thread 간 움직일 수 있음           ex) IRIX, HP-UX, Tru63 UNIX, Solaris 8와 그 earlier       - User-Level Thread vs Kernel-level Threads  정리   User-Level      Application(User) 에 의해 관리   Kernel은 Thread를 모름! 인식하지 못함   Context switching이 쌈 → kernel mode 권한이 필요 없으니   원하는 만큼 많이 생성할 수 있음   주의 깊게 사용해야함 . . → 서로 보호되어 있지 않아서   Kernel-Level      Kernel에 의해 관리   Kernel resources를 사용함   Context switching이 비쌈   생성하는데 한계가 있음 → Kernel Resource를 사용하다보니   사용하기 비교적 간편함 ㅎㅅㅎ       Thread Libraries   - Thread Libraries      Thread library는 thread를 생성하과 관리하기 위한 API를 개발자에게 제공함   구현의 2가지 기본 방법            Kernel의 도움 없이 User space에 완전히 있는 Library                    Library에 있는 함수를 호출하면, system call이 아니라 User space에 있는 local function이 호출                       Kernel (OS)의 도움을 받는 Kernel-level library                    Library에 있는 함수를 호출하면, kernel로의 system call                           3가지 main library            Pthreads       Win32       Java           - Pthreads (POSIX Thread)      User-level 또는 Kernel-level 로 제공될 수 있음   Thread 생성 및 syncronization에 필요한 POSIX 표준 (IEEE 1003. 1c) API   API는 thread library의 동작을 지정하고, 구현은 library 개발에 달려있음 → 이게 무슨 말이고 . .   UNIX OS(Solaris, Linux, Mac OS X)에서 공통적임   기본 Pthread APU            pthread_create() : 새로운 thread 생성                    thread 변수, thread 속성, start routinc 함수와 선택적 argument 허용                       pthread_join() : thread의 termination을 기다림                    메인 thread가 종료되기 전에 thread가 작업을 수행할 수 있는지 확인하는 데 사용                       pthread_exit() : 호출한 thread를 termination           #include &lt;pthread.h&gt; #include &lt;stdio.h&gt;  #include &lt;stdlib.h&gt;  int sum;                                /* this data is shared by the thread(s) */ void *runner(void *param);              /* threads call this function */  int main(int argc, char *argv[]) { \t\tpthread t tid;                      /* the thread identifier */ \t\tpthread attr t attr;                /* set of thread attributes */  \t\t/* set the default attributes of the thread */  \t\tpthread attr init(&amp;attr); \t \t\t/* create the thread */ \t\tpthread create(&amp;tid, &amp;attr, runner, argv[1]); /* runner에 의해 child thread 생성하고 실행됨 */ \t \t\t/* wait for the thread to exit */  \t\tpthread join(tid,NULL); \t \t\tprintf(\"sum = %d∖n\",sum); /* child에서 수행한 값이 나옴! 만약 param이 2였다면 sum은 1+2 = 3 */ }  /* The thread will execute in this function */  void *runner(void *param) { \t\tint i, upper = atoi(param);         /* thread 내에서 정의한 local var이기에 각 thread의 local stack에 저장됨 */ \t\tsum = 0;                            /* gloval var이기에 data section에 저장죔 */  \t\tfor (i = 1; i &lt;= upper; i++) \t\t\tsum += i; \t\t \t\tpthread exit(0);  }       Threading Issues   - fork() &amp; exec() system call      multithreaded program에선 fork()와 exec() system call의 의미가 달라질 수 있음 → 원래  fork() 는 process 생성하는 놈   multithreaded program에서 한 program의 thread가 fork()를 호출한 경우            새로운 process는 부모의 모든 thread를 복제해야하는가       새로운 process는 fork()를 호출한 thread만 복제해야하는가                    일부 UNIX system은 위의 두가지 버전의 fork()를 모두 구현하기도 함                           exec()를 호출한 경우            모든 thread를 포함한 전체 process가 대체됨           fork()를 부르자마자 다시 exec()을 부른다면 exec()에서 지정한 프로그램이 곧 모든 것을 다시 대체할 것이기 때문에 모든 스레드를 복제해서 만들어주는 것은 불필요!   fork() 후 exec()를 하지 않는다면 새 프로세스는 모든 스레드들을 복제 해야 함   - Signal Handling      signal은 UNIX system에서 특정 event가 발생했다고 process에게 알리기 위해 사용함            ex) CTRL+C에 의해 process가 종료된 경우           signal를 process하기 위해 signal handeler 사용            특정 event에 의해 signal 생성       process로 signal 전달       signal handled (처리)                  multithread program에서 signal 전달하기 위한 option (signal 생성 종류에 따라 결정됨)            signal이 적용되는 thread에 전달       process의 모든 thread에 전달       process의 특정 thread에 전달       process에 대한 모든 signal을 받을 특정 thread 지정           - Thread Cancellation      Thread가 완료되기 전에 terminating            ex) 웹 페이지가 렌더링 되는 동안 중지 버튼 누르는 경우           2가지 일반적인 approaches            Asynchronous cancellation : 타겟 thread를 즉시 종료                Deferred cancellation : 타겟 thread가 자신이 취소되는지 취소 여부를 주기적으로 확인하면서 순서대로 종료할 수 있는 기회 제공           → 더 통제되고 안전함! 자신이 취소되어도 안전하다고 판단하고 취소 여부 확인하면 되니까                   - Thread Pool      요청마다 새로운 thread를 생성하는 거는 새로운 process를 생성하는 방식보다는 overhead가 적긴하지만 그래도 thread에도 약간의 overhead가 존재            thread생성하는데 걸리는 시간이라던가 . .           무제한 thread는 system resource (CPU, Memory) 를 고갈할 수 있음 ㅜㅜ   이러한 문제를 해결하기 위해 thread pool 사용 !            process를 시작할 떄 미리 일정한 수의 thread를 만들어 task를 기다리는 곳인 pool에 넣어둠       대기하고 있다가 server가 요청을 받으면 새 thread를 생성하는 것 대신 pool에서 깨워서 할당           장점            일반적으로 기존 thread로 요청을 처리하는 방식보다 빠름!       일정한 한 순간에 존재하는 thread 수를 제한하여 리소스 고갈 방지           Pool의 thread 수는 CPU 수, Memory, 예상하는 동시 요청 수 등을 기준으로 설정할 수 있음  ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch4",
        "teaser": null
      },{
        "title": "[OS] Ch5. CPU Scheduling",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    Basic Concepts  - Basic Concept      Multiprogramming : 일부 process가 항상 실행되도록 하여 CPU utilization (사용율)을 최대화 함 → 즉 최대한 CPU가 놀지 않도록 하는 것            한 번에 여러 process들이 메모리에 유지시킴       block 될 때 까지 process 실행 시키고, 만약 block 된다면 다른 process를 실행           Process scheduling이랑 Thread Scheduling은 종종 같은 의미로 사용되기도 함 ~~   - CPU Burst와 I/O Burst의 Alternating Sequence          CPU-I/O Burst Cycle : CPU 실행 cycle과 I/O Wait로 구성된 Process            이때 CPU 실행이 연속되는 기간을 CPU Burst라고 하고       I/O를 연속해서 기다리는 기간을 I/O Burst라고 함                  CPU-bound Process : CPU-Burst가 길고, I/O-Burst가 드물게 있는 Process                     왼쪽 그래프에서 왼쪽 동그라미           ex) 데이터 마이닝, 이미지 프로세싱..                   I/O-bound Process : CPU-Burst가 짧고, I/O-Burst가 자주 있는 Process                     왼쪽 그래프에서 오른쪽 동그라미           ex) 유저의 입력이 계속있는 게임                   - CPU Scheduler      Short-term Scheduler → 빠르게 자주 바뀌는 .. !            memory에서 실행할 준비가 되어있는 process를 고르고, 그들 중 하나에게 CPU를 할당!                Process가 다음과 같은 경우 CPU Scheduling가 실행 될 수 있음                                   Admitted 된 상태                        Running state → Waiting state 로 전환된 경우                          ex) I/O Request                  Running state → Ready state 로 전환된 경우                  ex) Interrupt 발생                  Waiting state → Ready state 로 전환된 경우                  ex) I/O 작업 완료                  Terminates           1,4 는 non-preemtive, 나머지는 preemitive   1와 4번의 경우, 실행 중이던 것이 멈추거나, 종료된 상황이므로 선택의 여지가 없이 Ready Queue에서 새로운 Process를 골라야함   다른 경우, 어떻게 스케줄링을 할지 선택권이 있을 수 있다   - Preemtive (선점형) vs Non-preempitve (비선점형)      Preemitive            CPU가 Process에 할당되어도, 다른 Process가 CPU를 강제로 빼았을 수 있음 → 우선순위에 따라 CPU가 할당 되는 경우       ex) Time-slicing           Non-preempitve            CPU가 Process에 할당 되면, Block 되거나 terminate될 때 까지 실행됨 → 중간에 빼았을 수 없음       위에서 1번과 4번의 경우           - Dispatcher      Dispatcher module은 Short-term Scheduler (이하 STS)가 선택한 Process에 CPU 제어권을 넘겨줌! → CPU 할당 !   CPU Scheduler 내부에 포함되어 있는 것으로 STS가 선택한 Process에 실질적으로 CPU 를 할당하는 역할   Dispatch Latency : Dispatcher가 한 process를 stop하고 다른 하나를 running 시키는데 걸리는 시작   CPU 제어권 넘기는 과정에는 다음 것들 포함            Switching context (Process의 Reg 전환)       Switching to User mode       Program을 재시작하기 위해 User program이 적절한 location을 찾을 수 있도록하고, jump함           → 즉 다시 Running 하기 위해 할당해주는 과정                                  Scheduling Criteria   - Scheduling Criteria (스케줄링 기준)      최대화 할수록 최적화됨            CPU utilization : 가능한 CPU를 바쁘게 일 시켜야함       Throughput : 시간 단위당 실행 완료하는 process 수           최소화 할수록 최적화됨            Turnaround time : 특정 작업을 실행 시키는데 걸리는 시간                    Completion time - Submission Time                       Waiting time : Ready Queue에서 실행되기를 기다리는 시간                    Fairness : 각 Process에 대해 동일한 시간을 배정하거나, 우선순위에 따라 적절한 시간을 배정해주어야함                       Response time : output이 아닌 request가 요청된 순간부터 첫번째 response가 생성될 때 까지 걸린 시간                    특히 interactice system environment에서 유용 ex) 폰,,                               Scheduling Algorithms   - Scheduling Algorithms      Ready Queue에 있는 Process 중 어떤 Process에게 CPU를 할당할 것인지 결정   최대한 Performance criteria를 최적화하는 방향으로 결정함   종종 일부보다는 평균값을 최적화하는 방향을 선택하기도 함   Interactive System에서는 Response Time을 최소화는 것이 가장 중요한 기준인 경우도 있음   - First-Come, First-Served (FCFS, 선착순) Scheduling      말 그대로 먼저 도착한 Process 순서대로 CPU를 배정함        ex) 위와 같은  P1, P2, P3가 있을 때                                  Process           Burst Time (ms)                                           P1           24                             P2           3                             P3           3                                   P1, P2, P3 순서대로 도착했을 때, FCFS Scheduling에 의해 정해진 Gantt Chart는                                  P1           P2           P3                                           0 ———————————————24           24 —————— 27           27—————— 30                                  Waiting Time : P1 = 0;  P2 = 24;  P3 = 27;       Average Waiting Time : (0 + 24 + 27) / 3 = 17                        P2, P3, P1 순서대로 도착했을 때, FCFS Scheduling에 의해 정해진 Gantt Chart는                                  P2           P3           P1                                           0 —————— 3           3—————— 6           5 ———————————————30                                  Waiting Time : P1 = 6;  P2 = 0;  P3 = 3;       Average Waiting Time : (6 + 0 + 3) / 3 = 3           → 1의 경우에 비해 굉장히 최적화됨!!!              Ready Queue로 FIFO 사용   Average Waiting Time은 일반적으로 최소가 아니며, variance가 큼 → 순서에 따라 많은 영향을 받아서   단점            Convoy effect : CPU bound process (CPU 사용 시간이 굉장히 긴 Process) 로 인해 다른 모든 사람이 Ready 상태임에도 불구하고 한참 기다려야함 ㅜㅜ       Non-preemptive Schediling algorithms.. 이면 timesharing system에서 큰 골칫거리,,           - Shortest-Jop-First (SJF) Scheduling      다음 CPU Burst의 길이와 각 Process를 연결하여 이 길이가 가장 짧은 Process 순서대로 CPU를 할당하여 scheduling            길이가 동일하다면 FCFS (선착순)           Average Waiting Time이 최소화 되기에 SJF 방식이 최적이긴하나, 다음 CPU Request 시간을 알기 어렵다는 큰 문제점이 있음 ㅜㅜ            Why 어려움? → I/O Request 가 나와야 I/O Burst로 전환되어 CPU Burst 길이를 측정 할 수 있어서 ㅜㅜ                ex) 다음과 같은  P1, P2, P3가 있을 때                                  Process           Burst Time (ms)           Shortest Order                                           P1           6           2                             P2           8           4                             P3           7           3                             P4           3           1                           SJF Scheduling에 의해 정해진 Gantt Chart는                                  P4           P1           P3           P2                                           0 —————— 3           3 ———————————— 9           9 ————————————— 16           16 —————————————24                                  Waiting Time : P1 = 3;  P2 = 16;  P3 = 9; P4  = 0       Average Waiting Time : (3 + 16 + 9 + 0) / 4 = 7       FCFS 사용 했을 경우 Average Waiting Time : (0 + 6 + 14 + 21) / 4 = 10.25           [SJF Scheduling의 2가지 방식]                  Process       Arrival Time (ms)       Burst Time (ms)                       P1       0       8                 P2       1       4                 P3       2       9                 P4       3       5                   Nonpreemptive SJF : 일단 CPU가 Process에게 주어지면, CPU burst가 끝날 때까지 CPU를 선점하고 있음                                  P1           P2           P4           P3                                           0———————— 8           8 ———— 12           12 ————— 17           17 —————————26                                  Average Waiting Time : (0 + (8-1) + (17-1) + (12-3) / 4 = 7.75                Preemiptive SJF : 새로 도착한 Process의 CPU burst길이가 지금 실행 중인 procee의 남은 CPU burst시간보다 짧다면 선점 (뻇음)       → Shortest-remaining-time-first scheduling이라고도 알려져 있음                                  P1           P2           P4           P1           P3                                           0 —1           1 ———— 5           5 ————— 10           10 ———————18           18 ————————- 27                                  Average Waiting Time : ((10-1)+(1-1)+(17-2)+(5-3)) / 4 = 6.5           - Next CPU Burst 길이 결정      실제 길이를 알 수 없기에 추측만 가능함 ㅜㅜ   이전 CPU Burst 길이들의 exponential average를 이용하여 추측            $t_n$  = Actual Lenght of $n^{th}$ CPU Burst       $\\tau _{n+1}$  = Predicted Value for the next CPU Burst       $\\alpha, 0 \\leq \\alpha \\leq1$       Define :  $\\tau _{n+1} = at_n\\space + \\space (1-\\alpha )\\tau_n$           - Priority Scheduling      각 process에게 정수 priority number가 주어짐   CPU는 우선순위가 가장 높은 process에게 할당되고, 만약 우선순위가 동일한 경우에는 FCFS 순서를 사용함   SJF는 다음 CPU Burst 시간을 기반으로 한 우선순위 스케줄링이라면, 이거는 일반적으로 지정된 고정된 값을 우선순위로 이용   우선순위는 internally(내부적), externally(외부적) 으로 정의될 수 있음            Internally : 측정가능한 quantity나 qulity를 사용! ex) 시간 제한이나 시간 사용량, 리소스 사용량, CPU burst에 대한 I       external : 컴퓨터 시스켐 외의 기준에 의해 설정 ex) 컴퓨터 사용에 지불하는 금액           2가지 방식            현재 실행 중인 프로레스보다 우선위가 높은 새로운 프로레스가 ready queue에 도착한 경우                    Preemptive : CPU를 선점하고 새로운 프로세스 실행           Non-preempitve : 그런거 없음 지금 CPU 사용하고 있는 process 그대로 유지                           문제점 : Stavation → 우선 순위가 낮은 process의 경우 계속 밀리니 결국 절대 실행 못 할 수도 있음 ㅜㅜ        해결법 : Aging → 시간이 지날수록 점진적으로 기존의 process의 우선수위를 높여서 오래된 process가 실행되도록       ex) 우선순위 범위를 0-127로 두고 15분 마다 대기 중인 프로세스의 우선순위를 1씩 높임!       → 그렇게 되면 우선순위 127이었던 애는 32분 이상 지나면 0이 되어서 처리하게 됨       Round Robin (RR)      Time-sharing system 을 위해 특별히 설계된 방식으로 Preemptive 방식 임   각 process는 10-100 밀리초인 작은 CPU 단위 시간 (Time Quantum)의 일정 시간을 얻음   그리고 이 Time Quantum이 지나면 다음 process가 선점되어서 ready Queue의 마지막에 추가됨            FCFS랑 비슷하지만 Process 간 switch를 위한 선점을 추가함           Ready Queue는 circular queue이고 FIFO를 사용해서 구현함   고려해야할 2개의 경우            Process가 1 Time Quantum보다 작거나 같은 CPU Burst를 가지는 경우 → 남는 time quantum 동안 어떻게? 그냥 바로 scheduling       Process가 1 Time Quantum보다 큰 CPU Burst를 가지는 경우 → time quantum 끝날 때 마다 계속 처리를 어떻게?           ex) example, Time Quantum = 4                  Process       Burst Time (ms)                       P1       24                 P2       3                 P3       3                          P1       P2       P3       P1       P1       P1       P1       P1                       0—— 4       4 —- 7       7— 10       10 ——14       14——18       18——22       22——26       26——30              Average waiting time : ((10-4)+4+7)/3 = 5.66   RR의 경우 굉장히 긴 시간을 기다려야하는 경우도 있음        일반적으로 평균 turnarund 시간이 SJF보다 길지만 응답속도은 더 좋음 → interactive 한       Ready Queue 에 n개의 process가 있고 time quantum이 q인 경우, 각 process는 한번에 최대 q 시간 단위의 chunk로 CPU시간의 1/n 을 얻음   (n-1)q 이상 다음 quantum을 기다리는 process는 없음 → 각자가 최대로 q 만큼 기다려야 (n-1)q 만큼 기다린거니까   성능은 time quantum 사이즈 q에 따라 달려있음            q 가 매우 큰 경우 → FCFS 랑 동일해짐.. 사실 q 보다 burst 시간이 긴게 없을테니까       q 가 매우 큰 경우 → 각 n 개의 process는 실제보다 1/n 속도의 실행되는 process가 될거임. . 그리고 context switch가 굉장히 자주 일어나서 overhead가 커짐 ㅜㅜ                    평균 Turnaround 시간은 q가 증가한다고 해서 무조건 나아지는게 아님      Multilevel Queue      Ready Queue를 2개로 분할한 다음에 어떤 process냐에 따라 어떤 queue에 넣을지 결정 → 즉 프로세스간 여러 레벨로 분류하는            foreground (interactive) queue → 상호작용이 많고 burst 시간이 빠른       background (batch) queue → batch 처럼 긴 시간동안 동작하고 상대적으로 덜 중요한           각 process는 하나의 ready queue에 영구적으로 할당됨   각 queue는 각자의 scheduling 알고리즘을 가짐            foreground (interactive) : RR → 아무래도 빠르게 동작되어야하니까 …       background (batch) : FCFS           ready queue 사이에도 scheduling이 이루어져해야함            Fixed priority scheduling                    즉 무조건 foreground에서 모두 사용한 다음에 background로 넘어감 → Stavation 문제 발생할 수도                       Time slice : 각 queue는 프로세스 사이에서 schedule을 잡을 수 있는 일정량의 CPU 시간을 얻음! 이 시간 지나면 얻어야해                    foreground queue는 processRR 에서 80%, background in FCFS 에서 20%                                각 ready queue는 우선순위가 낮은 queue보다 절대적인 우선 순위를 가짐                          interactive 프로세스를 실행하려면 system process queue이 비어있어야함       system process가 도착하면 interactive process가 선점됨       즉 앞에 있는 queue가 다 실행되어야 다음 queue에 들어있는 프로세스들이 실행된다는 것           Multilevel Feedback Queue      process가 ready queue간에 이동할 수 있는 경우 !   다른 policy와 quantum size를 가진 Multiple Queue 간에서 process는 migrate 할 수 있음   CPU burst times에 따라 process를 분리할 수 있음            process가 CPU 시간을 너무 많이 사용하는 경우 → 낮은 우선순위를 가진 queue로 이동                만약 process가 너무 오래 wait 하고 있는 경우 → 높은 우선순위를 가진 queue로 이동           : starvation 을 방지하기 위한 aging 방법               I/O 중심인 process랑 foreground(interactive)한 process 은 높은 우선순위에 배치함       processeor 중심의 process는 낮은 우선순위에 배치함           [Example in Multilevel Feedback Queue]      3 개의 Queue            Q0 : Time Quantum 이 8 ms 인 RR       Q1 : Time Quantum 이 16 ms 인 RR       Q2 : FCFS           Scheduling            새로운 job이 Q0 에 들어가고, CPU를 얻으면 8 ms 동안 가지고 있음       8 ms 동안 완료되지 않으면 jop은 Q1 으로 이동함       Q1 에서 job 은 16 ms 동안 추가적으로 CPU 가짐 ! 그리고 이 시간동안 완료되지 않으면 다시 Q2로 이동       Q2 에서 job 은 FCFS 방식으로 작동! 대신 Q1, Q2 가 이때 비어있을 때만                  Multilvel-feedback-Queue Sceduler은 다음 parameter에 대해 정의됨            number of Queues       각 Queue에 대한 scheduling algorithms       process 를 더 높은 우선순위의 queue로 upgrade 하는 것을 결정하는 method       process 를 더 낮은 우선순위의 queue로 demote 하는 것을 결정하는 method       process가 service를 원할 때 process 가 들어갈 ready queue를 결정하는 method       process가 service를 받는 시기를 결정하는 method → PPT 에는 없음!               Multiple-Processor Scheduling   - Multiple-Processor Schduling      multiple CPUs (Multiple-Processor) 가 가능한 경우 CPU Scheduling은 더 복잡해짐 ㅜㅜ → Processor 마다 독자적인 Queue랑 독자적인 Scheduling 방식을 가지고 있으니까 !            Asymmetric Multiprocessing (AMP)                 단 하나의 process (master)만 system data structure에 접근함 그리고 얘가 다른 모든 processor들의 scheduling을 지정함       다른 process (slave)들은 user code만 실행                    Symmetric Multiprocessing (SMP)                       각 processor는 자체적으로, 즉 스스로 scheduling함       각 Processor는 공통의 ready Queue에 있는 process 들 중에 실행할 process를 선택함! 아니면 Procesor가 각자의 private queue를 가지는 경우도?           - Symmetric Multiprocessing (SMP)      Common Ready Queue (Global)            Process가 idle이 되면 (유휴 상태가 되면), CPU schduler는 즉시 common queue에서 해당 process를 추출함           A private Queue for Each Processor            모든 process 간의 load balancing이 필요함       process간 migration으로 종료되면                    push migratioin           pull migration (work stealing)           Linux: Push-load-balancing every 200 ms, pull-load-balancing whenever local task queue is empty                           - Processor Affinity (프로세서 선호도)      Cache Affinity            cache에는 최근에 CPU에 의해 접근한 data의 copy본이 포함되어 있음 그래서 이를 선호       process가 최근에 할당된 CPU말고 다른 CPU에 할당된 경우                    새로운 접근에 의해 이전 캐시들은 무효화됨 → 관련 없는 캐시니까           새 CPU에서 시작하니까 cache miss가 엄청나게 많이 발생           많은 bus traffic과 굉장히 느린 main memory 접근..                       그러니까! 최대한 다른 CPU로의 migration은 피해야함!! 되도록이면 무조건 기존의 CPU에 할당되도록!!! → 그래서 processor에 대한 선호도를           Process는 현재 있는 Processor에 대한 선호도가 있음            Hard Affinity : 다른 CPU로의 migration 금지 (forbidden)       Soft Affinity : Mitgration 가능하긴 한데 undesirable (바람직하지 않다)                NUMA (Non-Uniform Memory Accesss) Affinity : CPU Scheduler와 memory 배치 알고리즘이 함께 작동해서 프로세스에 대한 메모리 페이지가 상주하는 특정 processor(soket)에 process를 할당 할 수 있음                   Work-Conserving or Not      Work-conserving            누군가 CPU 를 원할 때 리소스를 idel 상태로 두지 마라!       실행 가능한 process가 없을 때만 CPU가 idel 상태가 되도록           Non work-conserving            실행 가능한 process가 있어도 CPU가 idel 상태 일 수 있음       안정성은 높을지도?          ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch5",
        "teaser": null
      },{
        "title": "[OS] Ch6. Process Synchronization",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    Background   - Cooperating Processes → ch3 에서 함      Independent process는 다른 process의 실행에 영향을 주거나, 받을 수 없음   Cooperating process는 다른 프로세스의 실헹에 영향을 주고, 받을 수 있음   - Synchronization Problem      여러 process에서 공유 데이터에 동시에 접근하면 데이터가 일치하지 않는 문제가 발생할 수 있음        그렇기에 Race Condition을 잘 설정해서, 여러 process가 동일한 data에 접근하고자 할 때 접근하고 실행하는 순서를 정해 질서있게 실행이 보장되도록 해야함       → 그 방법이 바로 Process Synchronizaion 과 Coordination       ex) P1 : x++;   P2: x--; 연산이 있다고 하고 x는 공유 메모리 인 경우      연산 과정은 1. read x →  2. compute new value of x → 3. write to x 순서로!   초기에 x=0 이었다면 두 프로세스가 실행 되고 난 다음에 x 값은?   기대하는 값은 0이지만 사실 -1, 0, +1 다 나오는 경우가 있음 ㅜㅜ → 무조건 0만 나오게 하려면? 1,2,3이 나눠지지 않고 한번에 실행되게 해야함   - Producer-Consumer Problem → Ch3 에서 한..      count 변수 사용한 버전   하지만 이것도 여전히 producer과 consumer가 공유 메모리인 count에 접근하고 조작하기 때문에 여전히 sync 문제가 발생함   // Producer: while (true) { \t/*  produce an item and put in nextProduced **/ \twhile (count == BUFFER_SIZE); // do nothing \t \tbuffer [in] = nextProduced; \tin = (in + 1) % BUFFER_SIZE; \tcount++; }*    *// Consumer: while (true)  { \twhile (count == 0) ; // do nothing  \t \tnextConsumed =  buffer[out];  \tout = (out + 1) % BUFFER_SIZE;  \tcount--;  \t/**  consume the item in nextConsumed */ }   Race Condition      Race Condition: 2개 이상의 process가 공유 자원을 병행적으로 읽거나 쓰는 상황   count를 증감/감소하는 instrunction 이 있다고 가정하면 그 과정은   /* count ++ */ 1. reg1 = count       // read, load 2. reg1 = reg1 + 1   // compute 3. count = reg1      // write, store   /* count -- */ 1. reg1 = count       // read, load 1. reg1 = reg1 - 1   // compute 2. count = reg1      // write, store   Syncronization이 없는 경우 (count = 5 상태로 시작 ㅇㅇ)                  Inst       Producer       Consumer       count       Producer’s r1       Consumer’s r1                       t1       r1 ← count               5 (init)       5                         t2       r1 ← r1 + 1               5       6                         t3               r1 ← count       5       6       6                 t4               r1 ← r1 -1       5       6       4                 t5       count ← r1               6       6       4                 t6               count ← r1       4       6       4              reg는 local이라 상관 노노   마지막이 5여야하는데 4네 . . ㅜㅜ   t2/t3, t4/t5, t5/t6 사이에 context switch 발생      이런 문제가 발생한 이유?          hole block으로 실행되어야하는데 broken되어 나눠 실행되었기 때문     각자가 독립적이지 않도록, 종속적이게 한번에 실행되어야함      (위랑 똑같은거 다시 써보면 ㅇㅇ..)   S0: producer execute reg1 = count {reg1 = 5}   S1: producer execute reg1 = reg1 + 1   {reg1 = 6}   /* Context Switch */   S2: consumer execute reg2 = count   {reg2 = 5} → 사실 reg1 이어도 local이라 동일   S3: consumer execute reg2 = reg2 - 1   {reg2 = 4}   /* Context Switch */   S4: producer execute count = reg1 {count = 6 }   /* Context Switch */   S5: consumer execute count = reg2   {count = 4} → 5여야 하는데 ㅜㅜ   The Critical-Section Problem   - Critical Section (임계 구역)      공유 자원 접근 순서에 따라 실행 결과가 달라지는(공통 변수를 변경하거나 table을 update하는)  process의 코드 영역 (segment of code) → 즉 여기서 race condition이 발생            위의 예시에서는 counter가 critical section에 속함       하나의 process가 critical section에서 실행 중이면 다른 어떤 process도 이 critical section에 접근 허용을 하면 안됨 (한번에 하나씩)       critical section problem은 process가 cooperate할 수 있는 protocol을 설계하는 것 !           기본적인 구조   do { \tEnter critical section C \t\t\tcritical section C: operation on shared data  \tExit critical section C \t\t\tremainder section  } while(TRUE);   - Solution to Critical-Section Data      다음 3가지 조건을 만족해야 critical section 문제를 해결할 수 있음            Mutual Exclusion (상호배제) : Process  $P_i$ 가 Critical Section $C$ 에서 실행 중인 경우, 다른 process들은 ciritical section에서 실행될 수 없음           →  $C$ 에선 race condition이 없음! 그냥 무조건 한번에 하나만 실행               Progress (진행 융통성) : 현재 critical section에서 실행 중인 process가 없고 critical section에 진입하려는 process가 있는 경우, critical section에 들어갈 process를 고르는 선택을 무한정 연기할 수 없음       → 즉, process가 자신의 차례이지만 critical section 을 안 쓰고 있다고 해서 다른 process가 자원을 쓰고싶은데 계속 기다려라고 할 수 없음. 지금 안 쓰고 있다면 최대한 활용            Bounded Waiting (한정 대기) : process가 critical section에 진입을 요청한 이후부터 요청이 승인되기 전까지 다른 process들이 critical section에 진입하는 횟수가 제한되어야함       → 즉 mutual exclusion 때문에 기다리는 process가 무한정 대기하고 있으면 안됨       →  $C$ 진입에 대한 fairness를 위한 기능       Peterson’s Solution   - Peterson’s Solution      SW-only solution 으로 HW 의 도움을 받지 않음        발표 했을 당시 원래 두개의 process (p0, p1)에서만 적용 가능 했던 방법       → 지금은 일반화되어 여러개애서도 가능하다고 함 → 그치만 교수님께선 일단 2개보다 많은 경우 지원 안된다고 말씀하시긴 함       LOAD와 STORE이 atomically하게 실행된다고 가정 → 즉 interrupted 되지 않음   두 process는 2개의 변수를 공유함            int turn;    // 누가 critical section에 들어갈 차래인지 나타냄       Boolean flag[2];     // process가 critical section에 들어갈 준비가 되어있는지 나타냄, p[i] == TRUE이면 Pi 준비된거           // Algorithm for Pi (j = 1-i) -&gt; Pi의 context에서 실행되는 // symmetric이라 Pj 에 대해서도 동일함 do { \t\tflag[i] = TRUE; // critical section에 들어가고 싶으니 준비되었다고 알림 \t\tturn = j; // 들어가고 싶다고 선언 후에 Pj한테 차례를 돌려 다른 애들 중에 critical section에 들어가고 싶은 애가 있는지 확인 \t\twhile(flag[j] &amp;&amp; turn == j); // Pj가 쓸 동안 기다리기...  \t\t/* critical section */ // 이제 내 차례 !  \t\tflag[i] = FALSE; // critical section 다 썼으면 다 썼다고 알림 \t\t \t\t/* remainder section */ // 이제 남은 영역  } while(TRUE);   - Peterson’s Solutuin의 correctness  증명하기           correctness : 알고리즘이 요구사항을 얼마나 만족하는가, 모든 input에 대해 올바른 output을 내는가            correctness를 증명하기 위해 Critical-Section Solution 의 3가지 조건에 대해서 볼거에요             Property 1 : Mutual Exclusion                 $P_i$ 는 flag[i] = TRUE || turn == i 일 때만 critical section 에 들어갈 수 있음       $P_i$ 랑 $P_j$ 둘 다 critical section에서 실행된다고 가정하자!       그럼  flag[i] = flag[j] = TRUE 이어야하고, 이때 turn 은 i 일수도, j 일수도 있음       만약 turn == j 라고 하면, $P_i$ 는 계속 while 문에 갇혀있고, 이는 $P_j$가 critical section에서 실행을 마치고 flag[j] == FALSE 가 될 때까지 갇혀있음       실행을 마치고 flag[j] == FALSE 가 되어 while 문에서 나와 criticival section에 들어간다고 하면, 이는 처음 가정인 flag[i] = flag[j] = TRUE 를 만족하지 못 하고 $P_j$가 critical section에 나오게 되므로  Mutual Exclusion 만족 !!                    Property 2 &amp; 3 : Progress &amp; Bounded Waiting                       $P_i$ 는 critical section 에 들어가고 싶을 때 (flag[i] == TURE)       $P_i$ 가 while 문에 갇히게 될지 판단! 갇힌다면 (flag[j] = TRUE &amp;&amp; turn == j) critical section에 들어가지 못 함                    $P_j$ 는 들어갈 생각이 없음                             flag[j] == FALSE 라서,  $P_i$ 는 갇히지 않고 critical section 에 들어갈 수 있음       2. $P_j$ 도 critical section 에 들어가고 싶음                        flag[j] == TRUE 니까 $P_j$ 도 while 문에 갇히는디 판단하는 상황일거임               1) turn == i → $P_i$  가 critical section에 들어감               2) turn == j → $P_j$ 가 critical section 에 들어감                       $P_j$ 가 critical section 에서 나오게 된다면 flag[j] == FALSE 가 됨           이 상황에서 바로 $P_j$ 가 다시 들어가고 싶다고 요청해도 TURE 로 바꾼 다음에 turn 을 i 에게 넘겨주니 $P_i$ 가 critical section에 들어감                       사용 후에 flag 를 FLASE로 바꿔주어 다른 process가 critical section 에 진입할 수 있게 해주므로 Progress 만족       진입 후에 다시 들어가고 싶다고 요청할 때 다른 process에게 turn 을 넘겨주므로 Bounded Waiting 만족           - Petson’s solution 단점 (개인적으로 정리한 내용)      busy waiting 이라 resurce 많이 소모   SW 방식이라 속도가 느림 ㅜ ㅜ   process 2개일 때만 사용 가능 → 현대에는 적용하기 힘들다   Synchronization Hardware (using Lock)   - Synchronization hardware      HW 를 사용하여 rece conditoin을 방지하는 방법        일반적으로 HW를 사용한 critical-section solution에는 lock이라는 도구를 사용함       → critical section 을 lock 으로 보호하여 Race condition을 방지              많은 system 들을 critical section code를 보호하기 위한 HW 를 제공하고 있고, 최신 HW들은 그 방식으로 특별한 atomic hardware instrunction 을 제공함            Atomic hardware instrunction == Uninterruptiable operation       즉, 인터럽트 발생을 허용하지 않고 한번에 다 실행되는 !       system이 성공적으로 바뀌거나 아무것도 변경되지 않거나           이렇게 해서 명령의 순서가 순서대로 잘 실행되는 것을 보장할 수 있고, 다른 inst 가 실행되지 못하므로 critical section에 예상하지 못한 변경이 발생하지 않음   Atomic hardware instrunction 종류            Test memory word and set value (TestAndSet) → read/write 에 대해       Swap Contents of Two Memory Words (Swap) → 두 memory 읽고 swap                    만약 TestAndSet 이랑 Swap 이 다른 CPU 에서 동시에 실행된다면 임의의 순서로 순차적으로 실행됨 !                           bouned wait 조건을 만족 못 한다는 문제가 있음   - TestAndSet Instruction   // Definition of TestAndSet bool TestAndSet (boolean *target) { \t\tbool rv = *target;  \t\t*target = TRUE;  \t\treturn rv;          // return the old value }      Executed Atomically   target 값 바꾼 다음에 원래 기존의 값(old value) 을 return   If target == FALSE : target 은 TURE 가 되고, FALSE return   If target == TURE : target 은 TURE 유지하고, TURE return   [Solutution using TestAndSet]   // Solution using TestAndSet do { \t\twhile (TestAndSet(&amp;lock));   // LOCK 상태에선 아무것도 안하고 계속 TURE로 바꾸며 LOCK 유지   \t\t/* critical section */       // 다른 process에 의해 LOCK 풀리면 critical section 진입 \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t // 이때 while 문에서 검사하기 위해 TestAndSet(&amp;lock) 실행되면 다시 LOCK 라고 뜨니까 한 process만 들어올 수 있음 \t\tlock = FALSE;                // 다 사용하고 나면 UNLOCK으로 변경  \t\t/* remainder section */ } while (TRUE);                                      lock == FALSE : UNLOCK           lock == TURE : LOCK                           boolean 변수인 lock 을 공유하고, 처음에 false (UNLOCK) 으로 초기화   lock 을 획득한 process만 critical section에 진입하기에 Mutual Exclusion 만족, 다 사용하고 나면 다시 FALSE 로 바꾸기에 Progress 만족   But Bounded wait 는 불만족 . . 요청 순서와 무관하게 지정되기에   - Swap Instruction (CAS)   // Definition of Swap int compare_and_swap(int *value, int expected, int new_value) { \t\tint temp = *value; \t\tif (*value == expected)    // value 가 기대한 값과 같을 때만 \t\t\t\t*value = new_value;    // new_value 로 변경 \t\treturn temp;               // return the old value }      Exectued Atomically   (*value == ecpected) 일 때만 value 는 new_value로 변경!   항상 value 의 원본값을 return   [Solution Using Swap]   do { \t\twhile (compare_and_swap(&amp;lock, 0, 1) != 0) ; // &amp;lock가 0 이 아닐 때, 즉 LOCK 일 때는 아무것도 안함!   \t\t/* critical section */                       // 다른 process에 의해 lock이 0이 되면 다시 1로 바꾸고 while 탈출!  \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t // 그리고 critical section 진입 \t\tlock = 0;                                    // 다 쓰고 나면 UNLOCK 으로 변경  \t\t/* remainder section */ } while (true);                                      lock == 0 : UNLOCK           lock == 1 : LOCK                           boolean value 인 lock 을 공유하고, 처음엔 0 (UNLOCK) 으로 초기화   처음 process 가 실행되면 초기값이 0이므로 compare_and_swap() 에서 lock 값을 1로 바꾸고 Critical section 에 진입   마찬가지로 lock 을 획득한 process만 critical section에 진입하기에 Mutual Exclusion 만족, 다 사용하고 나면 다시 FALSE 로 바꾸기에 Progress 만족   But Bounded wait 는 불만족 . . 요청 순서와 무관하게 지정되기에   Semaphores   - Semaphores (with busy waiting)   typedef struct{  \t\tint value;             // 사용 가능한 resource 수 \t\tstruct process *list;  // ready queue } semaphore;      synchronization tool 중 하나로 Dijkstra 가 고안한 방법   Busy waiting 문제를 해결함 → 나중에 해결한 방법 나옴   Semaphore S 라는 integer 변수인 Class를 사용함                                                            0 : LOCK               1 : UNLOCK                                                   // Semaphore Definition /* P(S) */ wait(S) {  \t\t// 아래 두 statement 는 atomic 하게 실행되어야함 \t\twhile S &lt;= 0 ; // 여기선 근데 매번 검사하기에 busy waiting 이긴 해 \t\tS--;   }   /* V(S) */ signal(S) { \t\tS++;  }      S 를 변경하는 2개의 standard Atomic Operation 을 가지고 있음            wait() : 원래 P() 라고 부름! 검사한다는 의미       signal() : 원래 V() 라고 부름! 증가한다는 의미           - Semaphore as General Synchronization Tool      Counting semaphore            S 값이 무제한!       resource가 여러개므로 critical section에 여러개의 process가 진입할 수 있음           Binary semaphore            S 값이 0 과 1 만 가능 ! → 즉 하나의 resource 를 두고 경쟁       구현이 더 간단       Mutex lock 이라고 부르기도함       S 가 1으로 초기화되면 →  wait() 먼저 실행되어야함       S 가 0으로 초기화되면 →  signal() 먼저 실행되어야함            // Mutual Exclusion using Binary Semaphore  Semaphore mutex;    //  initialized to 1   do {  \t\twait (mutex);  \t\t// Critical Section        \t\tsignal (mutex);  \t\t// remainder section  } while (TRUE);           - Counting Semaphore      유한한 수의 resource에 접근하는 것을 컨트롤 할 때 사용   S 는 가능한 resource 의 개수로 초기화   Resource 사용 할 때 : wait(S) operation 사용 → count 감소.. 0 되면 사용 가능한 resource 없다는 소리   Resource release 할 때 : signal(S) operation 사용 → count 증가   ex) 도서관에 비유하면            프론트는 semaphore 를 의미하고, 스터디룸(좌석)은 resource, 그리고 스터디룸 이용하는 학생들은 process       학생들은 프론트에서 스터디룸 있는지 확인하고 예약해서 스터디룸 사용함           - Synchronization Problem에서 semaphore 사용하기      동시에 실행되는 두개의 process가 있다 하자   이때 P1은 statement S1, P2는 statement S2 를 가지고 있음   S2가 S1 이 실행 완료된 이후에만 실행해야한다면 아래처럼 사용하면 됩니당   // in P1 S1 statement; signal(sync);      // sync 사용 완료했어여   // in P2 wait(sync);     // sync 기다리는 중.. S2 statement;   - Semaphore Implementation      위에서 보인 Semaphore 는 Busy waiting 방식이라 (spinlock) 비효율적  → wait() 에서 계속 조건 확인하니까            spinlock : lock 상태일 동안 계속 반복문 돌면서(spin) 기다린다는       busy waitting 은 CPU cycle 을 낭비하는 방식이라 비효율적임..       뭐 대부분의 multiprocessor 구조에선 괜찮기도 하고 critical section 이 짧거나 거의 안 쓰면 상관 없지만 그래도..           그래서 우리는 wait() 와 signal()을 수정해서 block - awake 방식으로 바꿀거임! 그리고 이를 위해서 semaphore 구조에 있는 list 를 waitingQueue로 사용할거에요            block() : invoke를 기다리는 process를 waiting queue에 배치하여 wait state로 바꿔버림! 이렇게 해서 busy wait 대신 그냥 process 자체를 스스로 block 해보림       wakeup() : waiting queue 에서 하나를 제거하고 이를 ready queue 에 재배치 하여 ready state로 바꿔버림           두 process가 동시에 동일한 semaphore에서 wait() 와 signal() 을 호출해서는 안됨 ! → semaphore 구현도 critical problem 으로 귀결..            이 문제는 단일/멀티 processor 에 따라 나눠서 해결                    Uniprocessor : Disable Interrupt                             wait 와 signal 연산 중에는 Interrupt 를 비활성화시켜 다른 processor의 명령어 실행이 끼어들지 않도록!           Interrupt가 다시 활성화되고 schedul 되기 전까진 현재 실행 중인 하나의 prcocess만 실행됨       2. Multiprocessor :           여기선 Interrupts 를 금지 시킬 수 없음 ! 모든 process에 금지시키기엔 성능 저하 문제가.. 그래서 다른 process의 명령어가 임의로 끼어들 수 있음 ㅜㅜ           그래서 SMP 에서는 lock 기술이 필요함  ㅜㅜ                           - Semaphore without Busy waiting   // New Definition wait(semaphore *S) { \t\t/* Start Atomic */ \t\tS-&gt;value--;  \t\tif (S-&gt;value &lt; 0) { \t\t\t\tadd this process to S-&gt;list;  \t\t\t\tblock(); \t\t} \t\t/* End Atomic */ }    signal(semaphore *S) { \t\t/* Start Atomic */ \t\tS-&gt;value++;  \t\tif (S-&gt;value &lt;= 0) { \t\t\t\tremove a process P from S-&gt;list;  \t\t\t\twakeup(P); \t\t} \t\t/* End Atomic */ }      Start,, 부터 End 까지는 Atomically 하게 실행 됨 !   이 버전에서는 semaphore 값이 음수가 될 수 있음! 그리고 이때 절대값은 semaphore 에서 기다리고 있는 process 수가 됩니다요   - Semaphroe 단점      Deadlock &amp; Starvation   Priority Inversion   - Deadlock &amp; Starvation (교착상태와 기아)           Deadlock : 둘 이상의 process가 기다리는 중인데, 이는 둘 중 하나에 의해 발생하는 event를 기다리는.. → 즉 서로에 의해 충족할 수 있는 event를 무한히 기다리는       ex) 1로 초기화된 2개의 semaphores S, Q 가 있을 때                                  t           P0           P1           비고                                           t0           wait(S)                       s—; return                             t1                       wait(Q)           q—; return                             t2                       wait(S)           P1 block!                             t3           wait(Q)                       P0 block!                             …           ————————           ——BLOCK——           ————————                             tn           signal(S)           signal(Q)                                         tn+1           signal(Q)           signal(S)                                              이렇게 서로 상대방 것을 기다리다 영원히 갇혀버리는,,,       Deadlock 발생 조건 → 수업시간 때 안함 그냥 나중에 나올 거 미리..                    다음 4가지 조건을 모두 만족하면 Deadlock 발생!           즉, 발생안하고 싶으면 4가지 중 하나라도 불만족시키게 하면                            Mutual Exclusion               No Preemption               Hold and Wait               Circular Wair                                                        Starvation : 무기한 Blcok,,, process가 semaphore의 queue에서 벗어나지 못 하고 갇혀있는       - Prioirty Inversion      말 그대로 우선순위는 더 높은데 뒤에 실행되어서 우선순위가 역전되는 현상   ex) Process들 L(ow), M(iddle), H(igh) 가 있고 이들의 우선 순위는 L &lt; M &lt; H 라고 하자            L 이 resource R (ex: lock) 를 얻고 실행함       M이 실행되면 우선순위가 높으므로 L 에게서 CPU 선점하고 실행됨       H가 실행되면 우선순위가 높으므로 M 에게서 CPU 선점하고 실행됨       그러다 H 가 L 이 가지고 있는 resource인 R 을 필요로하게 되어서 요청함       근데 지금 R은 L 이 가지고 있으니 H 는 Block 됨       그럼 다시 CPU 는 M 에게로 돌아가게 되고 . . H 는 R 이 unblock 되기만을 기다림       그러려면 M 이 종료되고 L 이 다시 실행되고 signal() 을 실행해야하는거니까 H 는 M을 기다리는 우선순위 역전이 발생한다           Solution            Priority Inheritance (우선순위 계승)                    L 이 R 에서 작업하는 종안 H 의 우선순위를 계승받음           R 에서의 L 의 작업이 끝나면 원래 우선순위대로 돌아오고 H 가 그 다음으로 실행됨                           Clasic Problems of Synchronization   - Classical Problems of Synchronization      Bounded-Buffer Problem   Readers and Writers Problem   Dining-Philosophers Problem   - Bounded-Buffer Problem      producer-consumer 문제를 동기화에 적용한??????   N buffer가 있고, 각각은 하나의 item 을 가질 수 있음   다음 3가지 semaphore 를 만들어서 관리하여 해결 ! → 이 방법 말고도 있을 수 있음            Semaphore Mutex 를  1 로 초기화 → buffer pool 로 부터 보호! 즉, mutual exclusion 조건 만족시키기 위해       Semaphore Full 를 0 로 초기화 → filled item 의 수를 count 하는 역할       Semaphore Empty 를 N 로 초기화 → free item 의 수를 count 하는 역할           // The structure of the producer process do  { \t\t// Produce가 nextp에 item 생성   \t\twait(empty); // Buffer 에 넣을거니 free item 감소시키기 \t\twait(mutex); // mutual exclusion 위해  \t\t/* Critical Session */  \t\t// Buffer에 생성한 item 추가  \t\tsignal(mutex); // mutual exclusion 위해 \t\t/* Remain Session */ \t\tsignal(full);  // Buffer 에 넣었으니 filled item 증가시키기 } while (TRUE);   // The structure of the consumer process do { \t\twait (full);  // Buffer 에서 뺄꺼니 filled item 감소시키기 \t\twait (mutex); // mutual exclusion 위해  \t\t/* Critical Session */  \t\t// buffer에서 nextc 부터 item 제거  \t\tsignal (mutex);  // mutual exclusion 위해 \t\t/* Remain Session */ \t\tsignal (empty); // Buffer 에서 뺐으니 free item 증가시키기  \t\t// Consumer가 nextc에 있는 item 사용 } while (TRUE);   - Readers-Writers Problem      Data set이 여러 concurrent process (Reader과 Writer) 들에 의해 공유 되고 있음!            Reader : Only Data Read! 그 외 업데이트나 다른 어떤 것도 할 수 없음       Writer : Read / Write 둘 다 가능 ~       보통 (# Reader) » (# Writer) 임! 물론 application 종류에 따라 나뉘지만           이런 상황에서 여러 reader 들이 동시에 접근하는 것은 전혀 문제가 없지만, 오직 Writer 의 경우 동시에 딱 하나의 Writer 만 접근 할 수 있음            즉 한 writer가 critical section에 있을 때 다른 writer 들이 접근하지 못 하도록 막아야하는 것이 문제!                2가지의 버전이 존재                     First Readers-Writer Problem : 어떤 Reader도 다른 Reader가 끝날 때까지 가디라지 않는다! Writer가 기다리고 있으니까 (reader의 priority 가 더 높음)           → Writer 가 starve 에 빠질 수 있음                        Second Readers-Writer Problem : Writer가 접근하기 위해 대기 중이라면, 다른 어떤 새로운 reader도 read 를 시작할 수 없음 (writer의 priority 가 더 높음)           → Reader 가 starve 에 빠질 수 있음                          우리는 첫번째 버전에 대해서 볼 거에욤           Problem : multiple reader 또는 single writer 가 공유 데이터(Shared Data)에 같은 시간에 접근 할 수 있도록 허용 → 첫번째 버전으로 함 보시죵   Shared Data 에는 뭐가 포함?            Data Set       Integer readcount : 0 으로 초기화되고 현재 얼마나 많은 process 들이 obj 를 read 하고 있는지를 의미       Semaphore mutex : 1로 초기화 되고 readcount 를 보호하는 역할                Semaphore wrt :           1로 초기화 되고, writer를 위한 semaphore → writer 가 data set을 수정하기 위해 critical session 에 진입하는 것에 대해           첫번째와 마지막 reader도 사용  → writer 가 접근 못하게 막고 풀이 위해                   // Writer Process do { \t\twait(wrt); // 다른 writer 막기  \t\t/* Critical Session, \t\t\t writing is performed */  \t\tsignal(wrt); } while (TRUE);   // Reader Process do { \t\t/* reader 잠시 막아두기  \t\t\t read count 변경해야하니까! \t\t\t 그리고 첫번째면 다른 작업 할건데 그 사이에 안 들어오게 */ \t\twait(mutex);   \t\treadcount++;  // read 하고 있는 (critical session 에 있는) process 수 증가  \t\tif(readcount == 1) // 첫번째 reader 면 writer 가 접근 못 하게 막기 \t\t\t\twait(wrt);  \t\tsignal(mutex); // 이제 다른 reader 들어올 수 있게 허용  \t\t/* reading is performed */  \t\t/* reader 잠시 막아두기  \t\t\t read count 변경해야하니까! */ \t\twait (mutex);  \t\treadcount--; // read 하고 있는 (critical session 에 있는) process 수 감소  \t\tif (readcount == 0) // 마지막 reader 면 writer 가 접근 풀어주기 \t\t\t\tsignal (wrt);  \t\tsignal (mutex) ; } while (TRUE);   - Digning-Philosophers Problem      대규모 concirrency-control 문제의 기본적 예제   [Digning-Philosophers Problem]      철학자 5명이 원형 테이블에서 식사를 하고 있다   테이블 중앙에는 음식이 있고, 5개의 젓가락(한쌍 아니고 한개) 이 철학자 사이에 있다   철학자는 생각을 할 때는 밥을 먹지 않는다.   그러다 철학자가 배가 고파 밥을 먹으려고 할 때, 자신의 왼쪽 또는 오른쪽 젓가락을 잡으려 시도하고 두개의 젓가락을 모두 잡아야 먹을 수 있다   밥을 먹고 나서 철학자는 젓가락을 내려놓고다시 생각에 빠진다       do { \t\twait(chopstick[i]);  \t\twait(chopStick[(i+1) % 5]); \t\t//  eat ( ˘༥˘ )\t\t \t\tsignal(chopstick[i]);  \t\tsignal(chopstick[(i+1) % 5]); \t\t//  think } while (TRUE);      Shared Data            음식 (Data Set)       chopStick(Semaphore로 표현) 배열 (chopStick[5], 다 1로 초기화)           Deadlock 발생 하는 경우            모든 철학자가 다 자신의 왼쪽 (또는 다 오른쪽) 젓가락을 잡으려고 하면           [Deadlock 해결한 solution]      최대 4명만 테이블에 앉게하기   양쪽 젓가락을 다 잡는 것이 가능한 상태에만 젓가락 잡게 하기   홀수번째 철학자는 왼쪽 잡고 오른쪽, 짝수번째 철학자는 오른쪽 잡고 왼쪽 잡게 하기   … 더 생각해보기!            근데 이를 만족하는 해결법도 한 철학자를 starve 상태로 만들 수 있다는 것을 알아두쉐여!!          ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch6",
        "teaser": null
      },{
        "title": "[OS] Ch8. Deadlock",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    The Deadlock Problem   - Bridge Crossing Example          Traffic 은 일방통행으로만 전달   bridge의 각 section → resource   Deadlock 발생 시, 하나의 차가 후진하는 방법으로 해결 가능 → res preempt와 roll back   Deadlock 발생 시, 여러 대의 차가 backed up 되어야할 수도 있음   starvation 발생할 수도 있음   - The Deadlock Problem      각각 res를 보유하고 있고, 다른 process가 소유하고 있는 res를 얻기 위해 기다리고 있는 block된 process 들의 set        ex 1)       System에 2개의 Disk 가 있고, P1, P2가 각각 하나의 disk 를 가지고 있으며 다른 disk 가 필요한 상황            ex 2)       1로 초기화 된 semaphores A와 B 가 있을 때                                  P0           P1                                           wait(A);           wait(B);                             wait(B);           wait(A);                           System Model      Resouce type : $R_1$, $R_2$, … $R_m$ (CPU cucle, memory space, I/O device, files…)   Each Resouce type $R_i$ 는 동일한 $W_i$ instace 를 가짐   Each process는 Request, Use, Releas 을 통해 resource utilizes            Request : resource 사용 요청 ! 요청이 바로 승인되지 않는 경우 process는 wait 해야함       Use : I/O device 사용 하는 것과 같이 resouce 사용       Release : Resouce를 다 사용하여 다른 process들이 사용할 수 있게 해제           Deadlock Characterization ***      다음 4가지 조건이 동시에 성립하는 경우 deadlock 이 발생 할 수 있음            Mutual exclusion           : 한 번에 하나의 process만 동일한 Resouce를 사용 가능! 다른 process 가 사용하고 있을 경우 기다려야 함               Hold and Wait       : process가 다른 process가 가지고 있는 추가 res를 얻기 위해 기다릴 때 하나 이상의 res를 가지고 있어야 함            No preemption       : process가 res를 가지고 있으면, process가 task 를 끝내고 자발적으로 해지하기 전까지 강제로 해당 res를 process 에게서 해지할 수 없음            Circular Wait       : 순환적으로 기다리는 process $R_1$, $R_2$, … $R_m$ 존재 ($P_i$ 는 $P_{i+1}$ 이 사용 중인 res를 기다리고, $P_n$은 $P_0$이 사용 중인 res를 기다리는 순환 구조)       - Resource-Allocation Graph      vertex set V, edge set E 가 있을 때   V Type            P = { $P_1$, $P_2$, … $P_n$ } : system 의 모든 process set → 책에선 $T$       R = { $R_1$, $R_2$, … $R_m$ } : system 의 모든 resouce set           E Type            Request edge : $P_i$  → $R_j$ 인 directed edge       Assignment edge : $R_j$ → $P_i$ 인 directed edge           Basic Facts      Cycle 이 ..            없다? → Deadlock 없음!!       있다? →  2가지 경우의 수                    Res type 당 하나의 instace 만 있다면 Deadlock                        Res type 당 여러개의 instace 있다면 Deadlock 가능성               (진짜 존재하는지는 ㅁㄹ 가능성이 있으니 확인해보아야하는거!)                                           Case 1. Resource-allocation graph.      The sets T, R, and E:            *T* = {*T*1, *T*2, *T*3}       *R* = {*R*1, *R*2, *R*3, *R*4}       *E* = {*T*1 → *R*1, *T*2 → *R*3, *R*1 → *T*2, *R*2 → *T*2, *R*2 → *T*1, *R*3 → *T*3}           Resourceinstances:            One instance of resource type *R*1       Two instances of resource type *R*2       One instance of resource type *R*3       Three instances of resource type *R*4           Threadstates:            Thread *T*1 is holding an instance of resource type *R*2 and is waiting for an instance of resource type *R*1.       Thread *T*2 is holding an instance of *R*1 and an instance of *R*2 and is waiting for an instance of *R*3.       Thread *T*3 is holding an instance of *R*3.               Case 2. Resource-allocation graph with a deadlock      *E* = {… , *T3* → *R2* } 추가 !   Cycle 존재            *T*1 → *R*1 → *T*2 → *R*3 → *T*3 → *R*2 → *T*1       *T*2 → *R*3 → *T*3 → *R*2 → *T*2           → deadlock 가능성           Case 3. Resource-allocation graph with a cycle but no deadlock      이 경우 T4가 R2 instace를 해지할 수 있기에 T4가 해지한 것을 T3가 가지면 되니까 cycle 깰 수 있음 ! → NO DEADLOCK       Methods for Handling Deadlocks      3가지 방법으로 Deadlock problem 을 다룰 수 잇음            Deadlock Precention &amp; Deadlock Avidance : system 이 deadlock state에 절대 빠지지 않도록 함       Deadlock Detection &amp; Deadlock Recovery : system이 deadlock state에 들어간 후 복구하도록 허용       문제를 무시하고 system 에서 deadlock 이 발생하지 않는다고 가정                 리눅스와 윈도우를 포함한 대부분의 system 에서 이 방식 사용 중       그런 다음 kenel 과 application developer 에게 1, 2 와 같은 방식 사용해 처리하도록 맡김           Deadlock Prevention      4가지 조건 중 적어도 하나가 만족되지 않음을 확인 !   1. Mutual Exclusion      Mutual Exclusion 은 유지 될 수 밖에 없음 ㅜㅜ 공유할 수 없는 res 에는 유지해야만 함 !!! 그래서 이걸 불만족 시킴으로 deadlock 을 방지할 순 없어여   Example of sharable resources: read-only files   Example of non-sharable resources: printer   2. Hold and Wait      이를 불만족 시키려면 process가 res를 요청 할 때 다른 res를 보유하지 않도록 보장해야 함 → 2가지 protocol 존재            각 process가 실행을 시작하기 전, 모든 res를 요청하고 할당받기를 요구 → res 요청의 동적 특성으로 인해 비실용적 . .       res가 없을 때만 res 를 요청 할 수 있도록 ! 즉 요청하려면 현재 가지고 있는 거 다 해제해야함           But, 두가지 모두 2개의 큰 단점 존재                     Low res utilization           : res가 할당되었으나 장기간 사용되지 않을 수 있기 때문에 res 활용도가 낮을 수 있다. 예를 들어, process 전체 실행에 대해 mutex 잠금을 할당받을 수 있지만 짧은 기간 동안만 필요합니다.                        starcation possible           : 여러 인기 있는 res가 필요한 process는 필요한 res 중 하나 이상이 항상 다른 process에 할당되기 때문에 무한정 기다려야 할 수 있습니다                   ex) DVD drive의 data를 disk의 file로 복사하고, file을 정렬 한 다음 printer로 결과를 인쇄하는 process      process는 처음에 DVD drive, Disk file, printer에 요청을 보내야함! → 마지막에 printer가 필요하더라도 전체 실행되는 동안 printer를 유지하고 있어야함   process는 처음에 DVD drive, Disk file 만 요청 보냄 → DVD drive에서 Disk file 로 복사 한 다음 이 둘 해지! 그리고 Disk file과 Printer 다시 요청보내기   3. No Premmption      2가지 protocol 존재            process가 일부 res를 가지고 있고 다른 process가 사용 중인 res를 추가적으로 요청해서 대기해야하는 경우           → 가지고 있던 res를 premmption 해 process가 대기 중인 res list에 추가시킴! 그리고 이전 res와 요청한 res 를 다시 가져올 수 있을 때 prcess 다시 시작       ex) 스레드 A가 자원 X와 Y를 가지고 있고, 자원 Z를 요청하는 상황이라고 가정해봅시다. 그러나 자원 Z가 현재 다른 스레드에게 할당되어 있어서 A는 기다려야 합니다. 이때, 데드락을 방지하기 위해서는 A가 X와 Y를 선점하여 다른 스레드가 이를 사용할 수 있도록 해야 합니다. 그리고 선점된 X와 Y는 A가 대기하는 자원 목록에 추가됩니다. 이후, 자원 Z가 A에게 할당되고, A는 X와 Y를 함께 사용하며 다시 시작됩니다. 이렇게 함으로써, 스레드 A가 자원을 대기하면서 데드락이 발생하는 상황을 방지할 수 있습니다.          process가 res를 요청하면, 요청한 res가 사용가능한지부터 먼저 확인하여 사용 가능하면 할당 ! 아니면 사용 중인 prcess 찾아 그 process로 부터 premmption 하여 요청한 process 에게 할당            CPU 레지스터나 데이터베이스 트랜잭션과 같이 상태를 쉽게 저장하고 복원할 수 있는 자원에 대해서 자주 적용       하지만 뮤텍스 잠금(mutex lock)과 세마포어(semaphore)와 같은 자원에 대해서는 일반적으로 적용할 수 없음 → 이러한 자원들이 데드락이 가장 일어나기 쉬운 자원들이기 때문           4. Circular Wait      circular wait를 불만족시키는 것이 위의 3가지보다 실용적인 방법!   모든 res type에 순서를 부여하고, process가 res의 순서가 증가하는 순서대로 res를 요청하는 방법        one-to-one function F : R → N (즉, res → number) 정의       ex) F(tape drive) = 1;  F(disk drive) = 5;  F(printer) = 12;            process가 가지고 있는 res를 $R_i$ 라 할 때, $F(R_i) &lt; F(R_j)$ 일 때만 res  $R_j$ 를 요청할 수 있음 !       ex) tape drive와 disk drive 가 둘 다 필요한 경우 tape drive 에 대해 먼저 요청을 하고 할당 받은 후에 disk drive를 요청 할 수 있음       그렇기에 application developer 는 순서대로 프로그램을 작성해야한담 !    💡 **→ 이러면 circular wait 없어진다는 거 증명?**  이 사실을 증명하기 위해 원형 대기 조건이 존재한다고 가정하고 모순에 의해 증명할 수 있습니다. 원형 대기에 관여하는 스레드 집합을 {T0, T1, ..., Tn}이라고 가정하고, 여기서 Ti는 스레드 Ti+1이 보유한 리소스 Ri를 기다리고 있습니다. (인덱스에 대해 모듈러 산술을 사용하여 Tn은 T0이 보유한 리소스 Rn을 기다리고 있다고 가정합니다.) 그러면 스레드 Ti+1은 리소스 Ri를 보유하면서 리소스 Ri+1을 요청하기 때문에 모든 i에 대해 F(Ri) &lt; F(Ri+1)이어야 합니다. 그러나 이 조건은 F(R0) &lt; F(R1) &lt; ... &lt; F(Rn) &lt; F(R0)을 의미합니다. 추이성에 의해 F(R0) &lt; F(R0)이 되어 모순이 발생합니다. 따라서 원형 대기는 발생할 수 없습니다.    Deadlock Avoidance   - Deadlock Avoidance      Deadlock Prevent 방법을 사용하면 uitilization 이 감소하는 등의 단점이 있음!   다른 방법으로는 res 요청 방법에 대한 추가 정보를 system이 알고 있어야함 → 누가 어떤 자원을 요청할 것이고 어떤 순서로 요청 할 것인지?            그러면 system 은 각 요청에 대해 deadlock 을 방지하기 위해 할당을 지정할 수 있음       가장 간단한 방법은 각 process가 필요로 하는 각 type의 최대 res 수를 선언할 것을 요구하는 것 !           Deadlock Avoidance 는 결국 res 할당 상태를 동적으로 검사하면서 circular wait 상태가 절대 발생하지 않도록 하는 것임   - Safe State      process가 available res를 요청 할 때 system은 system이 safe state에 유지하고 있는지 즉각적으로 확인해야함   모든 process에 대한 safe sequence가 존재하는 경우 system 이 safe state에 있다고 함                     seq &lt;P_1, P_2 , … , P_n&gt; 가 safe sequence (현재 할당 상태에 대해)           : 각 P_i에 대해 P_i 가 아직 요청할 수 있는 res 요청이 {현재 사용 가능한 res} + {P_j (j &lt; i) 가 가지고 있는 res} 로 모두 충족시킬 수 있는 경우               P_i 가 필요로 하는 res 가 즉시 사용 가능 한 것이 아니면 P_i 는 모든 P_j가 작업을 완료 할 때 까지 기다릴 수 있음       P_j 가 완료되면 P_i는 원하던 모든 res를 획득하고 작업 완료한 담에 res를 반환하고 종료할 수 있음       P_i 가 종료되면 P_{i+1} 은 원하던 res를 획득 할 수 있음 ! → 이런 식으로 반복           Basic Facts      system 이 safe state에 있다 → NO DEADLOCK   system 이 unsafe state에 있다 → DEADLOCK 가능성   Avoidance → system이 unsafe state로 절대 들어가지 않음       - Avoidance Algorithms      Deadlock-Avoidance Algorithms 은 Resource 할당 상태를 동적으로 검사하여 순환 대기 조건이 존재할 수 없도록 하는 것 !   2가지 type 에 따라 나뉘어욤            Resource Type 당 Single instance : Resource-Allocation Graph 사용 → simple case       Resource Type 당 Multiple instances :  Banker’s Algorithms  사용 → 이게 더 일반적이겠쥬           [ Resource-Allocation Graph Algorithms ]   기본 정의      Claim Edge (추가 !) : process 가 resource R_j를 요청할 수 있음을 나타내고 점선으로 표기 $P_i$ → $R_j$   process 가 resource 요청할 때, Claim edge → Request edge 로 변환   resource 가 할당 될 때, Request edge → Assignment edge 로 변환   process에 의해 resource 가 해제 될 때, Assignment edge → Claim edge 로 변환        resource는 무조건 system에서 사전(priori) 에 claime 되어야함       → 즉, P_i 가 실행되기 전 P_i 에 대한 claim edge 가 모두 graph 에 표기되어 있어야함       $P_i$ 가 $R_j$ 요청 할 때 cliam edge 를 request edge로 전환되더라고, cycle 이 없는 경우에만 request가 승인됨 !            Cycle 없음 : 즉각적인 resource 할당은 system 이 safe state 에 유지하도록 해줌       Cycle 있음 : 즉각적인 resource 할당은 systme 이 unsafe state 로 만들게 됨 .. → 그러므로 process는 기다려야한당           cycle-detection algorithm 으로 cycle 있는지 확인할 때 시간 복잡도는 $n^2$      Resource-allocation graph for deadlock avoidance        Unsafe state in a resource-allocation graph.    [ Banker’s Algorithms ]   Data Structure for      **n = {# of process}**, **m = {# of resource type}**   Available - m x 1 Vector            각 resoure type 에 대해 사용 가능한 resource 수를 나타냄       Available[j] == k 이면,  Reource type R_j에 대해 사용 가능한 k intance 존재           Max - n x m Matrix            각 process가 요청할 수 있는 최대 resource 수를 나타냄       Max[i][j] == k 이면, process P_i 는 reource type R_j 를 최대 k intances 만큼 요청할 수 있음           Allocation - n x m Matrix            현재 각 process에 할당 된 resource 수를 나타냄       Allocation[i][j] == k 이면, process P_i 는 reource type R_j 를 k intances 만큼 할당 받았음       Allocation_i 는 process P_i 에 할당된 resource           Need - n x m Matrix            각 process가 작업을 완료하기 위해 필요한 남은 resource 수       Need[i][j] == k 이면, process P_i 는 작업을 완료하기 위해 reource type R_j 를 k intances 만큼 더 필요함       Need[i][j] == Max[i][j] - Allocation[i][j]       Need_i 는 process P_i 가 작업을 완료하기 위해 요청해야할 추가 resource           Safety Algorithms      system이 safe state인지 아닌지 판단하는 알고리즘으로 시간 복잡도는 $O(mn^2)$            초기화           Work 와 Finish 가 각각 길이가 m, n 인 vetor 라고 정의하고 다음과 같이 초기화       Work = Available → 현재 시스템에서 사용 가능한 자원(resource)의 수를 나타내는 벡터       Finish[i] = fasle // for i = 0, 1, … , n-1  → 각 process에 대해 safe path 를 찾았는지 여부 (path 가 있어 실행되고 종료되었는지)               남은 need를 claim 할 수 있는 process 찾기       Finish[i] = false &amp;&amp; Need_i ≤ Work 인 index i 찾기! 만약에 만족하는 i가 없다면 4단계로 ㄱㄱ            실행 가능한 process P_i 실행 후 (resource 할당) 에 할당된 resource 들 모두 반환       Work = Work + Allocation_i; Finish[i] = ture; 로 한 다음에 2단계로 ㄱㄱ            모든 i 에 대해서 Finish[i] == ture 라면(모든 process가 실행 완료될 수 있는), system 은 safe state 임       Resource-Request Algorithm (for P_i)      요청을 안전하게 승인할 수 있는지 확인하여            안전하면 P_i에게 resource를 할당       아니면 P_i 의 요청을 보류하고 resource-allocation state 가 이전으로 복원           Request_i  : process P_i 에 대한 request vector (길이 m)            Request_i[j] == k 이면 P_i 는 resource type R_j 의 k instances 를 원하는 것                    Request_i ≤ Need_i 이면 유효한 요청 수 이니 2단계로! 아니라면 process가 최대 요청을 초과한 것이기에 error condition 이 발생함           Request_i ≤ Available 이면 할당 가능하니 3단계로! 아니라면 P_i 는 resource를 사용할 수 없기에 wait 해야함           system이 resource 를 P_i 에게 할당한 것 처럼 보이게 하기 위해 상태를 다음과 같이 변경                           Available = Available – Requesti;       Allocationi = Allocationi + Requesti;       Needi = Needi – Requesti;       - Example ** 이거 무조건 시험 나올 듯 무조건 완벽하게 이해하기      5 Processes : P_0 - P_4;  3 Resource types : A (10 instances), B (5 instances), C (7 instances)        T0 에서의 상태, Need = Max - Allocation 으로 하면 위와 같이 나옴    [Exmaple 1] Safety Algorithms          Seq &lt; P1, P3, P4,P2, P0&gt; 는 safe state 인지 확인하기!            초기화                    Work = Vailable = [3 3 2]           Finish = [false, false, false, false, false]                       남은 Need를 claim 할 수 있는 process 찾기                    P0 → Finish[0] == fasle 지만  [7 4 3] &gt; [3 3 2] 이기에 할당 못 함           P1 → Finish[1] == fasle 이고 [1 2 2] ≤ [3 3 2] 이기에 할당 가능           물론 다른 것도 가능 할 수 있음 (P2, P3, P4 다 가능 그래서 safe state 여러개 가능하다는 거) → 일단 i가 증가하는 순으로 구하는게 구현하기 쉬우니 . .                       실행 가능한 process P_i 실행 후 (resource 할당) 에 할당된 resource 들 모두 반환                    P1 실행 후 반환 → Work = Work + Allocation[1] = [5 3 2]           Finish[1] = True 로 변경                       반복 ! 해보면 safe state 임           &lt; P1, P3, P4, P0, P2&gt; 랑 &lt; P1, P3, P4, P2, P0&gt; 도 safe state   [Exmaple 2] Resource-Request Algorithm (for P_2)      P2 이 [1 0 2] 요청했을 경우 (Request_2 = [1 0 2]) 요청이 받아들여질 수 있는지 확인하여 할당하기            Request_2 = [1 0 2] ≤ Need_2 = [6 0 0] 이니 유효하지 않은 요청 !       Fail…           [Exmaple 3] Resource-Request Algorithm (for P_1)      P1 이 [1 0 2] 요청했을 경우 (Request_1 = [1 0 2]) 요청이 받아들여질 수 있는지 확인하여 할당하기            Request_1 = [1 0 2] ≤ Need_1 = [6 0 0] 이니 유효하지 않은 요청 !       Fail…       Request_1 = [1 0 2] ≤ Available = [3 3 2] 이기에 즉시 할당 가능 !                system이 resource 를 P1 에게 할당한 것 처럼 보이게 하기 위해 상태를 다음과 같이 변경           Available = Available – Request_1 = [2 3 0]           Allocation_1 = Allocation_1 + Request_1 = [3 0 2]           Need_1 = Need_1 – Request_1 = [0 2 0]                      요청 시 상태       완료 후 상태    [Exmaple 3] Resource-Request Algorithm (for P_0)      P0 이 [0 2 0] 요청했을 경우 (Request_0 = [0 2 0]) 요청이 받아들여질 수 있는지 확인하여 할당하기            Request_0 = [0 2 0] ≤ Need_0 = [7 2 3] 이니 유효한 요청 수       Request_0 = [0 2 0] ≤ Available = [2 3 0] 이기에 즉시 할당 가능 !                system이 resource 를 P0 에게 할당한 것 처럼 보이게 하기 위해 상태를 다음과 같이 변경           Available = Available – Request_0 = [2 3 0]           Allocation_0 = Allocation_0 + Request_0 = [3 0 2]           Need_0 = Need_0 – Request_0 = [0 2 0]                        근데 P0 의 요청을 허용 했을 경우  Need_i ≤ Available 인 P_i 를 찾을 수 없움 ㅠㅠㅠ       → Unsafe state          요청 시 상태       완료 후 상태    Deadlock Detection      System 이 Deadlock-precention 이나 Deadlock-avoidance 알고리즘을 사용하지 않는다면 Deadlock state 에 들어 갈 수 있음 → 들어가도록 허용하는   이런 경우 system 은 1) deadlock state가 발생했는지 확인하는 알고리즘 (Deadlock detection) 과 2) Deadlock state에서 복구할 수 있도록 하는 알고리즘(Recovery from Deadlock)을 제공   - Deadlock Detection      Detection Algorithms            각 Resource Type 이 single instace 를 가지는 경우 → Wait-for Graph 사용       Resource Type 이 multiple instaces 를 가지는 경우 → Detection Alogirithms           Recover scheme   - Detection-Algorithm Usage           expensive 한 algorithm 임 ㅜㅜ 그렇기에 너무 자주 사용하면 안되고 필요할 때만 사용해야함!       → 즉시 할당할 수 없는 모든 request 에 대해  사용한다면 overhead 가 굉장히 커질 것 ㅜㅜ       또한 임의로 사용한다면 graph 에서 많은 cycle 이 생길 수 있어서 어떤 deadlock process에 의해 deadlock state 가 발생했는지 파악할 수 없게 됨   그럼 언제 Detection-Algorithm 을 사용해야할까 ?! → 다음 두가지 요소에 따라 판단            Deadlock state 가 자주 발생할 가능성이 있는가?       Deadlock state 가 발생할 때 영향을 받는 스레드의 수는 얼마나 되는가?           - Signle Instace of Each Resource Type      Resource-allocation graph 를 변형한 Wait-for graph 사용!            Resource Node 와 Collapse Edge 를 제거       $P_i$ 가 $P_j$ 를 wait 하고 있는 경우 $P_i → P_j$ edge 로 표현           마찬가지로 cycle 이 존재하면 deadlock 이 존재한다는 것임   그렇기에 주기적으로 graph에 cycle 이 있는지 확인하는 algorithms 을 실행시키며 탐지함   n 개의 node를 가지고 있는 graph에 cycle 이 있는지 확인하는 algorithms의 시간복잡도는 O(n^2) → DFS 사용       왼) Resource - Allocation Graph           오) Wait - For Graph    - Several Instace of Resource Type      Wait-for 그래프는 serveral instance 상황에서는 사용할 수 없음 ㅜㅜ → baker’s 알고리즘과 비슷한 Detection 알고리즘 사용 할 것임   [ Detection Algorithms ]      banker’s 알고리즘과 비슷하지만, Max와 ?? 가 필요없음   Data Structure for      Available  - m x 1 Vector            각 resoure type 에 대해 사용 가능한 resource 수를 나타냄           Allocation  **- n x m Matrix            현재 각 process에 할당 된 resource 수를 나타냄           Request - n x m Matrix            현재 각 process의 요청을 나타냄       if Request[i][j] == k : 스레드 Ti는 자원 유형 Rj의 추가 k개 인스턴스를 요청           Algorithms      $O(mn^2)$            초기화                 Work 와 Finish 가 각각 길이가 m, n 인 vetor 라고 정의하고 다음과 같이 초기화       Work = Available → 현재 시스템에서 사용 가능한 자원(resource)의 수를 나타내는 벡터       Finish[i] = (Allocation_i == 0 ? ture : false) // for i = 0, 1, … , n-1 → 힐당 된게 없으면 확인 안 헤도 ㄱㅊ하니까 true 즉 detection 검사 완료 여부                    Index i 찾기!                       Finish[i] == false &amp;&amp; **Request_i** ≤ Work 인 index i 찾기! 만약에 만족하는 i가 없다면 4단계로 ㄱㄱ                                                       Finish[i] == false → O(n)               **Request_i** ≤ Work → O(m)       → O(mn)                                               Banker’s 와 달리 Need 가 아니라 Request 임                                           Work = Work + Allocation_i; Finish[i] = ture; 로 한 다음에 2단계로 ㄱㄱ       **Request_i** ≤ Work 이니까 P_i 가 Deadloack 에 관여하지 않고있음을 알고 있어 낙관적인 가정 (optimistically assume) 으로 P_i 가 task 를 완료하기 위해 더 필요한 res 가 없을 것이라 가정함 ! 즉 모든 resource 를 반환할 것이기에 반환한다 생각하고 저렇게 해도 됨                    Deadlock state 판단                       어떤 1 ≤ i ≤ n 에 대해 Finish[ i ] == false 이면 system 은 Deadlock state       Finish[ i ] == false 이라면 P_i 는 deadlocked           - Example ** 이거 무조건 시험 나올 듯22 무조건 완벽하게 이해하기      5 Processes : P_0 - P_4;  3 Resource types : A (7 instances), B (2 instances), C (6 instances)     [Example 1]          &lt;T0, T2, T3, T1, T4&gt; 의 경우 모든 i 에 대해 Finish[i] == true 이므로 deadlock state 가 아님!   [Example 2. P_2 가 Type C instance 를 하나 더 요청할 경우]          deadlock state 임 ㅜㅜ   P0 밀곤 디 false임   Recovery from Deadlock   - By Process and Thread Termination      Deadlock 상태(circular wait)를 제거하기 위해서 process나 thread 를 terminate 하는 2가지 방법            모든 Deadlocked process들 Abort → Cycle 확실히 제거할 수는 있으나 cost 가 많이 듬 ㅜㅜ                Deadlock cycle 이 사라질 때 까지 한번에 하나의 process 씩 Abort → overhead 많이 발생 ! process 종료하고 deadlock detection 해야하니까           → 이 방법 사용한다면 어떤 순서로 Abort 할 것인지를 정해야함                   Process Abort 하는 순서 → Terminate 하는데 드는 cost 가 최소가 되는 걸로 Abort 해야함 ! Mutex 가지고 있다던가 R/W 중이었다던가 그러면 에바            Priority of Process       Process가 지금까지 compute 한 시간이 얼마나 길고, 남은 시간이 얼마나 긴지       Process가 사용한 Resource (얼마나 많이 사용했고, 어떤 type 을 사용했는지) → ex) resource 선점하기 쉬운지 여부       Process가 완료하기 위해 필요한 Resource       Terminated 되어야하는 Process 수       Process 가 Interactive (대화형) 한지 Batch (한번에) 인지           - By Resource Preemption      Deadlock 상태(circular wait)를 제거하기 위해서 일부 Resource 를 procesess 로 부터 preempt 하여 다른 process 에 할당하는 방법   그러기 위해선 다음 3가지 문제를 다뤄야함            Selecting a victim(희생자) : 어떤 resource와 어떤 process를 선점할 것인가?                 termination 방식과 마찬가지로 cost 를 최소화하는 방향으로 선택해야함       cost 에는 deadlocked process가 가지고 있는 resource 수나 process 지금까지 사용한 시간 등과 같은 parameter 가 포함 될 수 있음                    Rollback : process에게서 자원을 preemption 하면 해당 process 는 어떻게 처리해야 하는가?                       Resource가 부족하므로 정상적으로 완료할 수 없음. 그러므로 어떤 safe state로 rollback 한 후에 다시 시작해야함       safe state 를 결정하는 것이 어려우므로 전체를 rollback 하는 것이 젤 효율적임 ← 사실 deadlock 발생시키는 거만 rollback 해도 되지만 그러면 추가 정보를 저장해야함                    Starvation : starvation이 발생하지 않도록 어떻게 보장할 수 있는가?                       항상 같은 process가 victim 으로 선택될 수 있음 → victim 으로 선정되는 횟수에 제한을 두어야함       일반적인 해결방법을 cost에 rollback 횟수도 포함하는 것 → 그러면 victim 으로 많이 선정될 수록 cost 가 올라가니까 선택될 확률이 낮아짐          ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch8",
        "teaser": null
      },{
        "title": "[OS] Ch9. Main Memory",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    Background   - 배경 지식      Program 을 실행하기 전 disk 에서 memory 로 가져온 다음에 ‘process’ 로 배치   Main Memory &amp; Register : CPU 가 직접 acces 할 수 있는 storage            Register : 접근하는데는 1 CPU clock (CPI) 이하로 걸림                Main Memory : 접근에는 많은 cycle 이 필요 → data 를 주고 받기 위해선 cpu 와 memory 간에 bus 를 통해야해서           → Processor 에 data가 없는 동안 기다려야하게 되기에 Cache 사용할거에요 ㅇㅇ                   Cache : Main Memory 와 CPU Register 사이에 존재   올바르게 operation 되기위해 Memory Protection 은 필요함            User process 로부터 OS 보호       User process 서로간의 보호       Hardware 에서 제공해줘야합니당           - Base and Limit Registers      User process 서로 간의 보호를 위하여 process 가 별도의 memory 공간을 가지게 함 → concurrent execution (동시에 실행)도 가능   Process 가 access 할 수 있는 legal address 범위를 정하고, 해당 legal address에만 access 할 수 있도록 보장해야함   Base, Limit 이라고 불리는 두 Register 의 한 쌍이 logical address space 를 정의            Base Register : 가장 작은 legal ‘physical’ address       Limit Register : 지정된 Range 크기           OS 만이 이 두 Register 값을 바꿀 수 있음 → 즉 OS 가 제공하는 보호 기능       [Base &amp; Limit Registers 로 Hardware address protection]      CPU Hardware가 User mode에서 생성된 모든 address를 Register (base &amp; limit) 과 비교하는 것으로 momory space 보호 → legal address 인지 확인   User mode에서 실행 중인 prgram OS 나 다른 User 의 momory 에 접근하려는 등 illegitimate memory 에 접근하려고 하면 trap 발생   address 가 [base, base + limit) 에 속해야함      Hardware address protection with base and limit registers    - Address Binding      Disk에 저장되어있는 Prgram(process) 들은 실행되기위해 Memory 로 가져와지기를 기다리고 있는데, 이때 input queue 에서 기다리고 있음            Input Queue 에서 한 process 선택       Disk 에서 Memory 로 Process Load       Process 실행되면 Memory 에서 Instruction 와  data에 접근하여 읽어옴       실행이 종료되면 Memory 는 다른 process 들이 사용할 수 있도록 Memory space 는 availavle 이라고 decleared           → 이 처럼 User prgram 은 실행되기 전에 여러 단계를 거침      user process 가 physical memory 의 어느 부분에 위치해도 상관 없음 꼭 시작부분부터 시작할 필요 없음   [Multistep processing of a user program]      Prgram 이 실행되기 위해 여러 단계를 거치는 것으로 이 과정에서 address 를 binding 함   User program (Source Program) 의 address 는 X 와 같이 symbol address 로 표시 됨   compiler 는 일반적으로 이런 symbol address를 “module의 시작으로 부터 14 byte (= 상대경로)” 와 같은 relocatable address 로 binding   Liker (Likage editor) 또는 Loader가 relocatble address 를 “74014” 과 같은 absolute address 로 binding   다음 3가지 stage 에서 Memory address에 대한 binding 이 일어날 수 있음            Compiler time : compile time 에서 Memory 가 어디에 위치할지를 먼저 알고 있다면, absolute code (compiler code) 를 생성할 수 있음                    process가 R 에서 시작한다는 것을 알고 있다면, code 는 R 에서 시작하여 그 위로 확장됨           시작 위치가 변경된다면 무조건 code를 recompile 해야함                       Load time :  compile time 에서 Memory 가 어디에 위치할지를 모른다면, 반드시 compiler 는 relocatable code 를 생성해야함                    최종 binding 은 load time 동안 지연됨           시작 위치가 변경된다면 user code 를 다시 load 하여 변경된 값 반영                       Execution time : process 가 실행 중에 memory segment 에서 다른 segment 로 이동할 수 있는 경우 binding 은 run time 동안 연기되어야함                    Address maps 에 대한 Hardware의 도움이 필요함 → Base &amp; Limit register                           → 효과적으로 구현하기 위한 방법을 알아볼거에여       - Logical vs Physical Address Space      별도의 Physical address space 로 binding 된 Logical address space   Logical address  : CPU 가 생성, virtual address 라고도 함 (execution-time 에선?)   Physical address : memory unit 에서 볼 수 있는 address   Compile-time &amp; Load-time address-binding scheme (compile-time 과 load-time 에서의 binding 에선) :            Logical address 와 Physical address 동일하게 생성됨 → 주소가 고정적으로       memory 에 load 될 때 마다 binding 해줘야함           Execution-time address-binding scheme (Execution-time 에선) :            Logical(virtual) address 와 Physical address 다르게 생성됩니다 → 주소가 동적으로 할당       MMU 가 매팡 해줘야함           Logical address space  : program 이 생성한 모든 logical address 의 집합 (logical address + mapping 되는 physical address ?? 정보?) → 각 process 마다 가지고 있음   Physical address spaece : physical memory address 의 집합 → process 간 공유 !   - Memory-Management Unit (MMU)      메모리 관리   Virtual address → Physical address 로 mapping 기능도 있는 Hardware device   Base Register 를 일반화한 MMU schme 으로 설명하고 여기선 Base Register를 이제 Relocatioin Register 라고 부름   Relocation register 값은 user program에 의해 생성된 모든 address 에 추가되어 memory 에 전송됨 → (base + addr)                     ex) 베이스가 14000에 위치한다면           사용자가 주소 0을 지정하려고 할 때 해당 주소는 동적으로 위치 14000으로 재배치           위치 346에 대한 접근은 위치 14346으로                   User program 은 logical address만을 다루고 실제 physicla address는 절대 안봄 (절대 다루지 않음)   2가지 type 의 address            0 to Max 인 logical address       R+0 to R+Max 인 Physical address (base == R 인 경우)           flowchart LR   CPU-Virtual_address --&gt; MMU --&gt; MEM-Physical_address       Dynamic relocation using a relocation register   - Excutable Files      OS 는 executable file 이 특정 format 을 가질 것이라고 expect            Header Info                    Code Locations           Data Locations                       Code &amp; Data       Symbol Table                    User program 에서 정의된 것들의 이름 list와 해당 위치들(정의된 곳)           User program 에서 사용하는 항목들 중 외부에서 정의된 항목들의 이름 list와 해당 위치들(정의된 곳)                           - Two-step operation (in most systems)      Linking : Library routine 을 포함한 program set을 결합하여 loadable Image 를 생성            Set 내에서 정의된 Symbole resolving       Loader 가 resolving 해야하는 symbol list화           Loading :  loadable Image 를 메모리로 복사하고, 이미 load된 다른 program 연결하여 주소를 필요에 따라 업데이트   - Linking      Static Linking :            Modules 과 사용하는 library들을 포함하여 program copy       여기선 모두가 standard 라이브러리 (libc.a, 등) 를 link 함       그렇다보니 모든 executabe image 와 모든 runtime 에 있는 process 의 memory 공간을 사용하게 됨 ㅜㅜ       standard 라이브러리처럼 공통 라이브러리는 공유할 수 있지 않을까?           Dynamic Linking :            Execution time 까지 linking 연기       각 library routin 을 reference 하기 위해 이미지를 포함하는 작은 코드 조각인 Stub 사용                    적절한 memory-resident (메모리 상주) 라이브러리 루틴을 찾거나 라이브러리가 not present (상주해 있지 않다면) 하다면 라이브러리 load 하는데 사용                       Stub 은 자기 자신을 해당 routine 의 주소로 바꾸어서 routine 실행시킬 수 있도록 (라이브러리 사용할 수 있게)       Dynamic Linking은 Library 에 특히 유용함!       이러한 System 은 Shared libaries 라고도 알려져 있음           - Loading      Static loading : Program memory 로 compiled &amp; linked image 가 이동   Dynamic loading :            호출되기 전까진 routine load 안됨 → 모든 routine 이 relocatable load format 으로 disk 에 유지       memory-space utilization 측면에서 더 좋음 ! → 사용하지 않은 routine 은 절대 load 되지 않으니까       자주 발생하지 않은 사례를 처리하기 위해 많은 양의 코드가 필요한 경우에 유용함!                    ex) error routines → error 는 자주 발생하지 않는데 발생해서 처리하려면 많은 양의 코드가 필요하니까                                   Swapping   - Swapping      원래 process 를 실행하려면 memory 에 실행할 process의 instruction 과 data 가 있어야하지만,  process를 일시적으로 memory 에서 backup storage 로 swap 한 다음(Swap out), 계속 실행하기 위해 다시 memory 로 가져 올 수도 있음 (Swap in)   모든 process의 total physical address space이 실제 시스템의 physical memory 를 초과할 수 있도록 허용하여 시스템에서 degree of multiprogramming 를 증가   Backup Storage : 모든 user 의 모든 memory copy 본을 수용할 수 있을만큼 충분히 크고 빠른 disk   ex) Multiprogramming with RR            Quantum 시간이 지나면 process 끝나자마자 swap out       다른 process 를 swap in 해서 memory space 에 넣음       이때 schduler 는 memory 에 있는 다른 process 에게 time slice 를 할당           → 이를 통해 프로세스 간 공유 메모리 자원을 효율적으로 관리하면서 실행을 지속 가능              Roll out, Roll in            swapping 변형으로 Priority-based scheduling 알고리즘에서 사용되는..?       priority 가 낮은 process 를 swap out 하여 priority 가 높은 process 를 load 하고 실행할 수 있도록!           System 은 memory image가 disk 나 memory 에 있는 모든 ready-to-run process 들의 ready queue 를 유지            만약 Ready Queue 내의 다음 process가 memory 에 없다면? → memory 에 있는 다른 어떤 process 를 swap out       이전에 점유했던 space 말고 다른 memory space로 swap back 할 수 있나요? → 넹 !           Swap time 의 대부분은 Trasfer time (data 가져오는 시간) 임 → swapping 은 expensive 해욤            total transfer time 은 swap 되는 memory 양과 직접적으로 비례함       ex) backout store 이 trasfer rate 가 50MB/s 인 disk 일 때, 100MB process 의 transfer time 은? → 2초! → 1Ghz CPI 인 경우 2*10^9 CPU cycle 이 됨           Contiguous Memory Allocation   - Memory Allocation      일반적으로 main memory 는 2개의 partition 으로 나뉨            Resident Operating System (상주하는 OS) → system 마다 다르긴 한데 일반적으로 interrupt vector 와 함께 low memory address 에 보관       User process → high memory address 에 보관           process 에 사용 가능한 moemory 를 할당하는 방법            일반적으로 여러 user program 을 main memory 에 상주시키고 싶음 → 그래야 multiprogramming 정도가 높아져 빠르니까       그래서 할당하는 방법을 고려해야함 !       contiguous allocation : 각 process는 단일 contiguous section (memory의) 에 포함됨           - Memory Protection      User process가 자신에게 할당되지 않은 memory 에 접근하지 않도록 해야함 ! ← process간 서로 보호하고 OS의 code 와 data 를 변경하지 못 하도록 보호해야하니까   Relocation Register 와 Limit Register 사용 !   Relocation Register : physical address 의 가장 작은 값 포함   Limit Register : logical addresses의 범위 포함 → 각 logical address는 limit register 보다 작아야함   MMU : Logical address 를 dynamically 하게 mapping → 위에서 말한 유닛 .. ! 여기서도 사용되어요       - Partition scheme      Partition : 하나의 Memory 를 logical 하게 나눔            나누어진 partition 은 각각 독립적으로 관리될 수 있으며 각 partition 에는 file system 이 할당 됨       각 partition 은 딱 하나의 process 만 포함할 수 있음           Fixed Partition scheme            Disk를 미리 정해진 크기의 Partition 들로 나누고, 각 partition 의 크기는 동일한 고정된 크기를 가지고 있음       Partition 수에 따라 Degree of Multiprogramming 이 제한 → partition 도, partotion 의 크기도 고정이니까       Internal fragmentation 발생 가능           Variable Partition scheme            Load 된 program 크기에 따라 partition 크기 결정       External fragmentation           - Memory Allocation (in Variable Partition scheme)      Hole : 사용가능한 memory block            처음엔 모든 memory 가 user process에 대해 사용가능하므로 큰 하나의 hole 임 !       나중에는 다양한 크기의 hole 들이 memory 전체에 흩어져 있고 이들은 hole set 에 있음           process가 도착하면            system 은 이 process 를 할당할 hole 찾기 위해 hole set 탐색       memory의 수용할만큼 큰 hole 에 할당       hole 이 너무 큰 경우 2개의 part 로 나뉘어 하나는 process에게 할당, 하나는 다시 hole set에 return       그리고 terminate 되면 memory 에서 해제되고 hole set으로           → spilt and merge       OS 는 다음 정보를 유지            allocated partitions       free partitione (hole) ( == free space == free address )           Dynamic Storage-Allocation 이라고도 함       1 → 2 : process 8 해제 ! relase 되고 hole 생김   2 → 3 : process 9 할당 p5 바로 아래 말고 hole 중간에 들어가서 hole 이 2개가 될 수도 있고 암때네 가능   3 → 4 : process 5 해제 ! realse 되고 hole 생김   - Dynamic Storage-Allocation Problem      Free hole set에서 size n 인 요청을 어떻게 충족시킬 것인가 에 대한 문제 → 사용가능한 Hole set 에서 free hole 고르는 방법            First-fit : 충분히 큰 크기를 갖는 첫번째 hole 할당 → 탐색하다 충분히 큰 hole 발견하면 중지하고 할당하고 끝       Best-fit : 충분히 큰 크기를 갖는 hole 중에 가장 작은 것 할당                 size에 대해 정렬되어 있지 않다면 전체 list를 다 봐야함       가장 작은 leftover hole (찾은 hole 할당 후 남은 부분) 생성 → 할당 후 남은 hole 을 최소화                    Worst-fit : 가장 큰 hole 할당                       전체 list 다 봐야함       가장 큰 leftover hole 생성           시뮬레이션 결과 속도 및 storage 활용 측면에서 First-fit 과 Best-fit이 Worst-fit 보다 우수하다고 보여줌   - Fragmentation      영역이 작은 조각으로 잘리는 단편화 문제   First-fit, Best-fit 모두 external fragmentation 문제를 겪음   memory 가 낭비되는 문제 ㅠㅠ   External Fragmentation :            process가 memory에 load 되고 remove 됨에 따라 free memory space 가 작은 조각들로 나뉘어지게 됨       이러한 과정에 의해 Total memory space 는 요청을 만족시킬 정도로 충분하지만, 연속적이지는 않을 때 External Fragmentation 발생       그니까 할당 할 수 있을만큼 memory 가 충분한데 그게 작게 나뉘어져 있어서 할당을 못 하게 되는,, → memory 낭비 문제           Internal Fracmentation            일반적으로 memory 를 고정된 크기의 block 으로 나누고, block 단위로 memory에 할당함       할당된 memory 가 요청한 memory 크기보다 클 수 있음 (고정된 크기로 나누다 보니까) → 남은 공간은 partition 내부의 memory 지만 사용하지는 않음!       이때  Internal Fragmentation 발생하고 이 차이가 Internal Fragmentation       ex) 고정 사이즈가 4KB 인데 요청 사이즈나 2KB 인 경우 2KB 만큼이 internal fragment           해결 방법            Compaction       Process의 Physical address space가 비연속적이게 할당할 수 있도록 허용 (Non-Contiguous memory allocation 방식 사용)                    Paging           Segmentation                           [compaction]      External fragmentation 줄일 수 있는 해결방법   memory 내 free space 들을 보아 하나의 큰 block 으로 만드는 것이 목표   Only Relocation 이 dynamic, 즉 execution time에 binding 이 될 때만 가능 !! → 즉, 항상 가능한 것은 아닙니다요            Relocation 이 dynamic : Relocation 은 program 이랑 data 가 옮겨지거나, base register 가 새로운 base address로 변경 될 때만 필요함           ex) Simplest Compaction Algorithm      모든 process 들을 memory의 한쪽 끝으로 옮기는 동안 모든 hole 들을 다른 방향으로 이동시킴 (process를 top 으로 올린담에 free 를 bottom 으로 모아버리는,,)   [Process의 Physical address space가 비연속적이게 할당]      Physical address space가 비연속적이게 할당할 수 있도록 허용함   그럼 작은 조작에도 할당 할 수 있게됨 !   이 방법에는 Paging, Segementation 두가지 방법이 있어요            paging : physical memory 를 page 로 나누고 이 page 들을 process 에게 할당       segmentation : program 을 segment로 나누고 각 segment 들을 memory 에 할당       자세한 차이점은 밑에 적어놨움           Paging   - Paging      Process의 physical address space가 비연속적이 되어도 괜찮다고 허용 → non-contiguous allocation   External fragmentation을 피할 수 있고 compaction 도 필요없게 됨   physical memory 를 고정된 사이즈의 block 인 frames (== pysical pages) 로 나눔   logical memory 를 frames과 동일한 크기의 block 인 pages (== virtual pages) 로 나눔   모든 free frames 추적   n page 크기의 program 을 실행하려면 n 개의 free page 를 찾아 load 하면 됨 !   Logical address 가진 page 를 physical address 가진 page (frame) 로 변환하는 page table 필요 !   Internal fragmentation 가 발생하긴 함,,, → 고정 크기다 보니까 . .   - Address Translation Scheme      CPU 에서 생성된 address 들(logical, physical)은 2개 영역으로 나뉨   Page numper (p) : physical memory 에서 각 page (physical page, frame) 의 base address 를 포함하는 page table 의 index 로 사용            virtual 인지 pyshical 인지 확인하는 용도로 사용되기에 이 둘을 나눠야한다??           Page offset (d) : base address 와 결합하여 memory unit 으로 전송되는 memory address              Page size 는 HW 에 의해 정의되며, 512 byte 에서 16MB 범위 내의 2의 거듭제곱 크기로 정의        ex) Logical address space 가 2^m 이고, page size 가 2^n 이라면 상위 (m-n) bits는 page number, 하위 n bits 는 page offset                   [example. n=2, m=4] ** 무조건 시험 !      Page size == frame size = 4 ( $2^n = 2^2$ ) bytes   Page number =  $2^{(m-n)}$ = 4 개   Logical Address space size = 16 ( $2^m = 2^4$ )            Logical memory size = 4 bytes * 4 pages = 16 bytes       page number : 2 bits       page offset : 2 bits           Physical Address space size = 32            Physical memory size = 32 bytes (8 frame * 4 bytes)       page (frame) number : 8 frames → 3 bits       page offset : 2 bits           Logical address 0 의 경우            0000 이므로 page number 은 00, page offset 은 00       page table index 0 번째 값은 5 임! (frame 5)       physical memory 5 * 4 bytes 로 이동 후 offset 이 0 이므로 physical address 20 으로 mapping           Logical address 7 의 경우            0111 이므로 page number 은 01, page offset 은 11       page table index 1 번째 값은 6 임! (frame 6)       physical memory 6 * 4 bytes 로 이동 후 offset 이 3 이므로 physical address 27 으로 mapping               - Fragmentation in paging      External fragmentation 없음 ! → 요청하는 process 에게 어떤 빈 frame 이든 할당해줄 수 있음   Internal fragmentation 은 있어요.. → 고정 크기의 frame 단위로 할당해주다보니 어쩔 수 없죠            frame 단위로 할당해주다보니 마지막으로 할당한 page 내부에서 다 채워지지 않은 경우 internal fragmentation 이 발생할 수 있음       최악의 경우 : process 가 (n pages + 1) byte 를 요청하는 경우 (n  + 1) frames 을 할당해주어야하고  마지막 frames 는 거의 전체가 internal fragmentation 이 됨           page size 가 작다면 internal fragmentation 을 줄일 수 있음! 하지만 그 만큼 각 page table 항목에 대한  overhead 는 증가 (frame 수가 증가하니까)            page table 에 대한 overhead 는 page size가 증가할 수록 줄어들어요           Efficition ?? = (ns+1)/(n+1)s   32 Bit page table entry 의 경우 page table 이 허용할 수 있는 page number (frame number) 는 ? → 2^32 개   만약 이때 page/frame size 가 4KB 라면 system 이 처리할 수 있는 physical memory 크기는? 2^32 * 4 KB = 2^44 bytes   - Free Frames      process 가 실행하기 위해 n 개의 page 가 필요하다면 최소 n 개의 free frame 이 memory 에서 available 해야함   OS 는 반드시 physical memory 의 세부정보를 알아야함            allocate 또는 available 한 frame 을 추적!       어떤 frame 이 할당되었고, 어떤 frame 이 사용가능한지, 총 frame 은 몇개인지 등           process 가 실행되기 위해 system에 도착하면 page 단위로 표현된 크기를 검사하고 각 page 는 하나의 frame 필요   즉, process가 n개의 page를 필요로 한다면, 최소 n개의 free frame 이 memory 에서 available 해야하고, 가능하다면 process 에게 할당   process의 첫 번째 page는 가능한 frame 중 하나에 load되고, 해당 process의 page table 에 frame 번호가 입력   다음 page는 다른 frame에 로드되고, 그 frame 번호가 page table 에 입력되는 식으로 진행   즉, process 의 page table 에 page 와 mapping된 frame number 가 들어있음      Free frames (a) before allocation and (b) after allocation.    - Implementation of Page Table with Hardware’s support      page table 의 pointer 는 다른 register values (ex instruction pointer) 과 같이 각 PCB 에 저장됨   Scheduler 가 process 선택할 때 page table 을 변경해야하므로 pagine 방법은 context switch 시간이 증가시킴   이러한 page table 을 위해 (context switch 시간을 줄인다던가) 도입된 HW 의 지원들            PTBR       TLB       ASID           [Page-table base register (PTBR)]      Page-table base register (PTBR) 은 page table 을 point 하는 reg   page table 변경하려면 PTBR 만 변경하면 되기에 context switch 시간을 줄일 수 있음   하지만 이 방식은 더 memory 접근 시간이 더 느려질 수 있음 → 모든 data / instruction 접근하기 위해 2번의 memory 접근이 필요            PTBR를 통해 page table 에 접근       page table 에서 number 에 따라 frame 으로의 data / instruction 접근           [translation look-aside buffers (TLBs)]              PTBR 의 memory 두번 접근하는 문제 해결   특수한 작고 빠른 조회용 hardware chach 로 associative 한 high-speed memory 임   각 항목은 key와 value 두 부분으로 구성   associative memory 에 값이 주어지만 주어진 key (page #)를 모든 key 들과 동시에 비교하면서 병렬적으로 content 를 검색함   TLB : Address translation(p, f)            p 가 TLB 에 있다면 frame number f 를 얻어 전달       없다면 page table 에서 frame number 찾아서 전달           [Address-space identifiers (ASIDs)]      TLB 기반   일부 TLB 는 TLB 항목에 address-space identifiers (ASIDs) 도 저장함   ASID : 어떤 process가 이 page 와 frame 을 쓰고 있는지 각 process 를 고유하게 식별해서 해당 process 에 대한 address space 보호를 제공하는데 사용   TLB 이 locigal page number 를 확인하려고(찾으려고?) 할 때 현재 실행중인 process 의 ASID 가 page 와 관련된 ASID 와 일치하는지 확인 → 일치하지 않다면 TLB miss   ASID 를 통해 TLB 는 서로 다른 process에 대한 항목을 동시에 포함할 수도 있게됨 ! → ASID 로 확인하면 되니까 ! → 더 효율적이죠   별도의 ASID 를 지원하지 않는다면 context switch 마다 TLB 를 flush (삭제) 해야해서 유효하지 않은 주소가 남아있지 않도록 해야함   [Effective Access Time]      Time for associative lookup: ε   Time for memory access: t   Hit ratio : α   Effective Access Time            page number 가 TLB에 있는 경우(HIT) :  mapping된 memory 접근 → t       TLB에 없다면(MISS) : page table 과 frame number를 위해 메모리에 접근(t), 그 이후 원하는 data 에 접근 (t) → 총 2t                    찾는데 ε 가 걸리므로 각 경우 걸리는 시간이 t + ε,  2t + ε 이고, α 에 따라 가중치를 주면                   → Effective Access Time :  EAT = (t + ε) α + (2t + ε)(1 – α) = 2t + ε – αt                   ex) t=100ns, ε=20ns, α=0.8   → EAT= (100+20)0.8 + (2100+20)*0.2=140   - Memory Protect      Protection bit : paging 환경에서 memory 보호하기 위해 page table 에 저장되는 각 frame 에 대한 protection bit            Read-Write / Read-Only 구별할 수 있는 하나의 bit       Read-Only page 에 write 하려고 하면 OS 로 HW trap           Valid-Invlalid bit : page table 의 각 항목에 저장되는 page 의 유효성을 알려주는 bit            Valid : associated page 가 process의 logical address space 에 있기에 legal page → 한마디로 지금 process 에서 해당 page 가 frame 과 연결되어 사용 중이라는       Invalid : page 가 process 의 logical address space 에 없음           Page-table length register (PTLR) : page table 의 크기를 나타냄            많은 process 들이 사용가능한 address space 의 일부만 사용함 그렇기에 모든 page 에 대해 page table 항목을 생성하는 것은 낭비임 → page table index &lt; avlid page number       PTLR을 모든 logical address 와 비교되어 해당 address가 process 의 유효한 범위에 있는지 확인하고, 유효하지 않은 범위면 OS 로 trap           [Ex. 14-bit address space (0 to 16383) with page size 2KB (= 2048 bytes)]   | page0 | 0 - 2047 | | — | — | | page1 | 2048 - 4095 | | page2 | 4096 - 6143 | | page3 | 6144 - 8191 | | page4 | 8192 - 10239 | | page5 | 10240 - 12287 |     process 는 실제 0 to 10468 만 사용 → page0-4 전부와 page 5 의 일부   page 0-5 는 valid 이기에 page table 을 통해 정상적으로 mapping   page 6-7 은 invalid 이기에 page 6, 7 로 address 변환하려는 시도가 있으면 유효하지 않은 page 참조로 OS 로 trap   이 방식의 문제점            process 는 10468까지만 사용하기로 되어있기에 그 이상 접근하면  illegal 임       하지만 page 5 의 참조는 valid 로 되어있기에 12287 까지 address 에 접근하는 건 유효하지만 10469 to 12287 까지의 address 는 유효하지 않음 ㅜㅜ       이건 process 가 실제 사용하는 공간보다 훨씬 큰 2KB page size 에 의해 page 내부에서 internal fragmentation 이 발생한 것           → 즉, 할당된 page 중 일부만 사용하기에 사용되지 않는 부분은 유효하지 않은데 valid 로 되어있음           - Shared Page           Paging 의 장점 중 하나는 여러 process가 있는 환경에서 common code 를 공유할 수 있다는 점       (reentrant인 code : 여러 user 들에게 사용되는 code 인 경우에서)            Read-only code의 한 copy 본은 여러 process에서 공유될 수 있음 ! ex) 표준 c 라이브러리, text editor, compiler, window system             read-only 이니까 (reentrant) 실행 중에 변경되지 않음으로 2개 이상의 process가 동일한 code 를 실행할 수 있음       이때 copy 본은 physical memroy에 하나만 유지되어도 각 user process 의 pafe table 은 동일한 physical memroy 와 mapping 할 수 있음       이 덕에 memory 공간 매우매우 아낄 수 있음               Structure of the Page Table   - Large page table problem      대부분 현대 컴퓨터 system 은 큰 logical address space (2^32 ~ 2^64) 를 지원하고 이 환경에선 page table 자체가 지나치게 큼   32bit logical address space 를 가진 system 에서 page size 가 4KB (2^12) 라면 page table 은 100만개 이상의 entry 로 구성될 수 있음 (2^20 = 2^32/2^12)   각 entry 가 4byte 로 구성되어 있다면 각 prcoess 는 page table 만으로도 최대 2^20 * 4 bytes = 4MB 크기의 physical address space가 필요 할 수 잇음   이를 main memory 연속적으로 할당하는 것은 비효율 적임 → 비효율적인 이유 개인적으로 찾아서 적어둠            mina memory 의 공간 낭비 : 연속적은 큰 공간을 찾아야하므로 낭비되는 memory 공간이 증가함       external fragmentation : address space 내에 page table 이 연속적으로 배치되므로 address space 내에서 external fragmentation       page table 크기 변경 어려워짐 : process 의 address space 가 동적으로 변할 수 있기에 page table 크기도 동적으로 조정되어야함. 하지만 연속적으로 할당한다면 새로운 공간을 찾아야하니 어려워짐           이를 해결하기 위해 page table 을 더 작은 조각 나누는 방법을 사용 !   Page table Strucutre type            Hieracrchical Paging : Page table 도 page 됨       Hashed Page Tables : Hash table 사용       Inverted Page Tables :           - Hirarchical Page Table      Logical Address Table 을 여러 page table 로 나눔 → 즉 page table 도 paging 됨   가장 심플한 건 2단게로 나누는 2 level page table       [Two-level Paging example]          32 bits system, 4KB (→ 2^12) page size   Logical address 은 20 bit 로 구성된 page number 와 12 bit 로 구성된 page offset 으로 나뉨   page table 도 page 되니까 page number 은 또 10 bit 의 page number 와 10 bit 의 page offset 으로 나뉨   p1 은 outer page table 의 index, p2 는 outer page table 에서의 위치 (displacement)          64bits system 에서는 outer page table 이 굉장히 커지게 되므로 two-level paing 이 적합하지 않음   - Haded Page Tables      32-bits 이상의 address space 를 처리하기 위한 일반적은 접근 방법 중 하나는 hased page table 을 사용하는 것   virtual page number은 page table 에 hash 됨   Hash table 의 각 entry 에는 충돌을 처리하기 위해 동일한 위치로 hash 하는 element들의 chain (linked list)가 포함 됨   각 elemet 는 다음 3가지로 구성            virtual page number       mapping 된 page frame 값       linked list 에서의 다음 element 를 가르키는 pointer           Virtual page number은 는 이 chain 에서 match 되는 것이 있는지 비교함! 일치되는 것을 찾은면 해당 physical frame 이 추출      virtual address의 virtual page number 가 hash table 에 hash 됨   virtual page number 는 lisked list 의 첫번째 elem 와 비교   일치하는 항목이 있으면 해당 elem 의 두번째 값 (page frame) 이 사용되어 physical addres 생성   일치하는 항목이 없다면 elem 의 세번째 값 사용해서 linked list 의 다음 elem 과 비교해 일치하는 것 찾기       - Inverted Page Table      ex) UltraSPARC, PowerPC   memory 의 실제 page 에 대한 하나의 entry 를 가짐   Entry &lt;pid, p&gt;            pid : 해당 page 를 가지고 있는 process로 address space 식별자 역할       p : 실제 memory 위치가 저장된 page 의 virtual address                    pid 를 통해 page table 에서 pid 와 일치하는 entry 찾기           찾았다면 entry 의 index 인 i 를 가진 frame와 매칭 ! 이때 p 를  virtual address로 사용                           각 page table 을 저장하는데 필요한 memory 는 줄어들지만, page 참조시 table 을 검색하는데 필요한 시간은 늘어남   shared memory 구현이 어려움 → pid 식별자가 있으니 공용에 대해서는?       Segmentation   - Segmentation      memory 에 대한 사용자 관점을 지원하는 memory management scheme   program을 서로 다른 크기의 logical unit 인 segment로 분할함!  → program 은 segments의 collection임   segment는 다음과 같은 logical unit            main program       procedure       function       method       object       local variables, global variables       common block       stack       symbol table       arrays       …              User’s view       Logical view    - Segmentation Architecture      logical address 는 tuple &lt;segment-numer, offset&gt;   Segment table : 2차원 주소를 1차원 physical address 로 mapping!            page table과 비슷하지만 크기가 고정이 아님           각 table entry 는            base : segment가 memery 에 상주하는 physical address 의 시작점을 포함       limit : 지정된 segment 의 길이 → page table 과 달리 크기가 고정이 아니고 process 의 unit 마다 다를 수 있음               - Segmentation 구현 위해 필요한 HW      Segment-table base register (STBR) : memory 에서 segement table 의 위치를 point 하는 reg   Segment-table length (limit) register (STLR) : program 이 사용하고 있는 segments 수 를 나타냄   segement number s &lt; STLR 일 때 s 는 legal   -  Protection in segmentation      segment table의 각 entry associate            validation bit가 0 이면 illegal segment       read / write / execute 권한           segment 관련된 Protection bit   code 는 segment level 에서 공유됨   segment 길이가 다양하기 때문에 moemory 할당은 storage-allocation problem   [example]          limit 인 400 보다 53 이 작기에 ㄱㅊ   limit 인 1000 보다 1222 가 크기에 trap   Paging vs Segmentation      Paging 은 고정 크기, Segmentation 은 가변크기   Pagine 은 internel Fragmentation 위험성, Segmentation 은 Externel Fragmentation 위험성   paging 은 고정된 크기의 page로 memory 를 분할하고 logical address를 page로 매핑 → 즉 메모리를 분할 !   segmentation 은 program을 segment로 분할하고 segment를 physical address에 매핑 → 즉 프로그램을 분할 !  ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch9",
        "teaser": null
      },{
        "title": "[OS] Ch10. Virtual Memory",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    Background   - Virtual-Address Space      결국 우리는 더 많은 multiprogramming 을 원하고 이를 위해선 memory 에 더 많은 것을 load 해야함   Virtual Memory : 개발자가 인식하는 logical memory 와 physical memory 를 분리하는 것                     오직 program 에서 필요한 부분만 memory 에 올려 실행되도록 함           → 각 program 은 더 작은 양의 physical mem 을 사용하므로 더 많은 program 을 동시에 실행 시킬 수 있게 됨                        그렇기에 Logical address space 는 Physical address space 보다 훨씬 클 수 있음 !                                  Virtual Memory 덕에 더 효율적인 process 생성 가능               → user program 을 memory 에 load 하거나 swap 하는 데 더 적은 I/O 가 필요하므로                                       Virtual-Address Space: process가 사용하는 address space   보통 0에서 시작하고 연속된 mem 에 존재하는 것으로 간주   program 전체가 필요한다고 하더라도 동시에 모든 부분이 필요한 것이 아니기에?   오른쪽 이미지에서 text 는 code 를 의미! 여기에는 주로 error handled code 같은거! 수행하는데 cost 가 많이 들지만 빈번하게 발생하므로     Virtual address space of a process in memory       위 사진 처럼 Virtual Memory 가 Physical Memory 보다 훨씬 큼 !   뭐 당연히 그래서 Physical Memory 가 모든 Page 를 동시에 laod 할 수 없는거     Diagram showing virtual memory that is larger than physical memory    Demand Paging   - Demand Paging      process 생성시 모든 page를 가져오지 않고 필요할 때만 Page 를 Memory 로 가져오는 것 → 즉 accese 하지 않은 page 는 memory 에 load 되지 않음            Less I/O needed : 필요한 page만 메모리로 가져오므로 I/O task가 줄어듬       Less Memory meeded : 필요한 age만 memory 에 load 되니까       Faster Respnse : 필요한 page 가 이미 mem 에 존재하는 경우 접근 및 실행 시간이 단축되어 Respnse time 이 빨라짐       More users           Page 가 필요하다면 page 를 reference하여 가져옴            Invalid reference ( ex. out of bound )→ Abort       Not-in-Memory → Disk 에서 Memory 로 가져옴           Lazy swapper : Page 가 필요하지 않은 이상 page 를 memory 로 swap 하지 않음            페이지와 관련된 스왑 작업은 페이지 매니저(pager)가 처리           - Valid-Invalid Bit      Page 가 memory 에 있는지 Disk 에 있는지 구별하기 위해 HW 의 도움이 필요함   각 Page table entry 에는 valid-inavlid bit 가 있어 이를 구별해줌!            v : in-memory, i : Not-in-Memory       모든 entry 는 처음에 i 로 초기화           Translation 중에 Page table entry 가 i 라면 PAGE FALUT           - Page Fault      Page 에 대한 reference 가 있을 때, page 에 대한 첫번째 reference 가 OS 로 trap 을 전달하는 현상        Invalid page 에 대한 접근이 발생할 때 Page Falut 발생       Page Falult 과정            OS 는 Internal Table (page table) 를 보고 refernce 가 valide 인지 invalide 인지 확인함       만약 Invalid reference 라면 process 종료 (참조 자체가 무효라), refer는 valid 지만 아직 Memory 에 가져오지 않은 경우(valid bit : i) 라면 Memory 에 가져와야함       i 라면 일단 trap 발생하고 Free Frame 을 찾기 (ex. free-frame list 에서 가져오기)       원하는 page를 새로 할당한 frame 으로 가져오기 (read) 하가 위해 secondary storge operation 를 스케줄링함 (wait quene 에 넣는다는 거) → swap device 에서 physical mem 으로 (swap)                Storage read 가 완료되면 Internal table 를 수정하여 page 가 이제 memory 에 있다고 알림           → Valid bit 를 v 로 설정                        Page Falult Trap 으로 중단되었던 Instructure 를 다시 시작함!           → process가 원래 memory 에 있었던 것 처럼 page 에 access 가능                       - Aspect of Demand Paging      Process 가 시작할 때는 memory에 page 가 없는 상태로 시작 !            OS 가 instrucrion pointer 를 process의 첫번째 instruction 으로 설정하지만, 이는 memory 에 없는 page 에 있는 instruction 이라서 page fault 가 발생함       process 가 필요한 page를 한번씩 다 가져올 때 까지는 page fault 가 계속 발생함       이렇게 처음 시작할 때 page 가 없는 상태로 시작해서 필요할 때만 page 를 가져오는 것을 Pure demand paging 이라고 함       cf.) prepaging : 지금 안 필요해도 미리 가져옴           Instruction 에 따라 multiple page 에 access 할 수도 있음 (두개의 page 에 걸쳐져서 있는 경우?) → 이런 경우 multiple page faults 발생 가능 !            하지만 locality of reference 에 이해 이런 경우는 실제 드물긴함           ex1 ) ld r1 r2 가 있을 때 최악의 경우 몇번의 page fault 발생? → ld 에서 2번!       ex2) ld r1 addr 가 있을 때 최악의 경우 몇번의 page fault 발생? → ld, addr 에서 각각 2번! 총 4번       Demand Paging 을 위해 HW 의 지원이 필요함            Vaild / Invalid bit 를 가진 Page table : memory 에 있는지 Disk 에 있는지 구별하기 위해 page 유효성 비트       Secondary memory : 보통 빠른 속도를 가진 disk 로 보조 기억 장치 &amp; 백업 저장 장치                    swap device 라고도 하며, swap device 에 의해 사용되는 저장 공간을 swap space 라고 함                       Instructoin restart : Page fault 처리 이후 동일한 곳에서 process 가 재시작되어야함       +) Dirty Bit : page replcement 할 때 disk 에 write 해야하는지 여부 확인           - Demand Paging 과정      OS 로 Trap   User의 Reg 과 Process state 저장   Interrupt 가 page fault 인지 결정   page references 가 유효한지 확인하고 disk 에서의 page location 결정   Disk 에서 free frame 로 read            Disk 에 대한  Read request 가 처리될 때 까지 Queue 에서 wait       Disk seek and/or latency time 동안 wait       Page 에서 free frame 으로 전송 시작           Waiting 하는 동안 CPU 는 다른 user 에게 할당   Disk I/O subsystem 으로부터 완료되었다고 interrupt 받음   6의 다른 user 의 Reg 와 Process state 저장   Interrupt 가 disk 에서 온 것인지 결정   원하는 Page 가 현재 memory 에 있는 것으로 Page table 와 other table 수정   CPU 가 다시 이 Process 에 할당되기를 기다리기   할당되었다면 1에서 저장해두었던 user Reg 와 process state, new page table 저장하고, 중단된 instruction 재시작      크게 보면            PF interrupt sevice       Page Read       Process Restart           - Performance of Demand Paging      Page Fault Rate : 0 ≤ p ≤ 1            p == 0 : no page fault       p == 1 : 모든 reference 는 fault                Effective Access Time (EAT, 유효 엑세스 시간)         EAT = = (Page Hit Rate) * (Memory Acess Time) + (Page Fault Rate) * (Page Fault Service Time)   \t\t\t= (1-p) * (Memory Access Time) + p * ((page fault overhead) + (swap page out) + (swap page in) + (restart overhead))           [Demand Paging Example]   - Memory access time = 200 nanoseconds = 200 * 10^-6 sec - Average page-fault service time = 8 milliseconds = 8 * 10^-3 sec  EAT = (1 – p) x 200 + p (8 milliseconds) \t\t= (1 – p)  x 200 + p x 8,000,000 \t\t= 200 + p x 7,999,800                       p = 0.001 이라면 EAT = 8.2 ms 가 되고 이는 40% 의 성능 저하를 발생   성능 저하(performance degradation) 가 10% 미만이길 원한다면            220 &gt; 220 + 7999800 * p → 20 &gt; 7999800 * p → p &lt; 0.0000025 이어야함       즉 400000 번에 한번 page fault 가 발생해야함           Page Replacement   - Page Replacement      Page fualt 인데 free frame 이 없다면 ?? → Page replacement 필요 !        Page Replacement : memory 에 있지만 실제로 사용하지 않는 page 를 찾아 swap out!       → swap out 할 page 를 찾는 여러 algorithms 존재 → page fault 횟수가 가장 적도록..              Page Replacement 를 Page-fault service routine 에 추가해서 memory over-allocation 을 예방   Page Replacement 중 Page transfer 과정에 의해 overhead 가 발생하는데 이는 Modify bit (dirty bit) 를 사용해서 줄일 수 있음            수정된 page 만 표시하여 disk에 written 해야하는 page 표시       page 가 수정된 경우 HW 에 의해 Modify bit 가 설정됨 → 즉, 설정된 경우 disk 에서 read 된 이후로 수정되었음을 의미           Page replacement 는 logical memory 와 physical memory 를 완벽하게 분리해서 작은 physical memory 로도 큰 virtual memory 를 제공해 줄 수 있음   - Basic Page Replacement      Disk 에서 원하는 page 의 location 찾기   Free frame 찾기            Free frame 이 있다면? → 사용하세욤 낼름       Free frame 이 없다면?                    Page replacement algorithms 을 이용하여 victim frame (희생자,,) 고르기           victime page 가 수정되었을(drity) 경우 disk 에 write 하고, 그에 따라 frame table 변경                           원하는 page 를 새로 생긴 free frame 에 사용하고 page 랑 frame table update   trap 에 의해 정지되었던 instrcution 재시작 하여 process 계속 이어가기       - Page Replacement Algorithms      어떤 frame이 replace 될지를 결정하는 알고리즘으로 page-fault rate 를 최소화하는 것이 목표            +) 일반적으로 frame 수가 증가할 수록 page fault 수는 감소하는 경향           알고리즘 평가하는 법            Page number 만 가지고 있는 reference string 을 실행시켜 page fault 수 측정       뒤에 나올 예시에서 우리는 [1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5] 을 reference string 으로 사용할거에욤 !!           알고리즘 종류            FIFO       Optimal (OPT)       LRU       LRU Approximation                    LRU Approximation           Second chance                       Counting                    LFU           MFU                           - First-In-First-Out (FIFO) Algorithm      각 Page에 memory 에 가져온 시간을 기록하거나, queue 를 사용해서 가져온 순서를 알 수 있도록   Page replacement 가 발생하면 oldest page 를 victim 으로 선택 !       [Example]           Reference string [1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5], 3 frmaes                   | Ref String | Mem | Page Fault? |   | — | — | — |   | 1 | [1] | init |   | 2 | [1 2] | init |   | 3 | [1 2 3] | init |   | 4 | [4 2 3] | 1 out |   | 1 | [4 1 3] | 2 out |   | 2 | [4 1 2] | 3 out |   | 5 | [5 1 2] | 4 out |   | 1 | [5 1 2] |  |   | 2 | [5 1 2] |  |   | 3 | [5 3 2] | 1 out → ref 순서가 아니라 mem에 들어온 순서 |   | 4 | [5 3 4] | 2 out |   | 5 | [5 3 4] |  |             Page fault rate = 9/12 = 75%           Reference string [1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5], 4frmaes        일반적으로 frame 이 많다면 page fault 수가 감소한다고 했으니, 증가시켜보쟈                          Page fault rate = 10/12 = 83..3% → 엥 더 안좋아졌네요 ㅋㅋ       이렇게 frame 이 늘어날 수록 page fault 가 증가 하는 현상을 Belady’s Anomaly (Balady 의 역설) 라고 함 (위에 그래프 확인)           - Optimal Algorithms      앞으로 가장 긴 시간 동안 사용되지 않을 page 를 victim 으로 고름   Pafe-fault rate 가 가장 작은 알고리즘으로 Belady’s anomaly 를 벗어나기에 Belady algorithms 이라고 부르기도함   하지만 SJF 와 비슷하게 어떤 것이 가장 오래 동안 사용되지 않을지를 모른다는 문제 . . . 그렇기에 성능측정하는 용도로 많이 사용합니다   [Example]           Reference string [1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5], 4 frmaes                          Page fault rate = 6/12 = 50%                          Ref String       Mem       Page Fault?                       1       [1]       init                 2       [1 2]       init                 3       [1 2 3]       init                 4       [1 2 3 4]       init                 1       [1 2 3 4]                         2       [1 2 3 4]                         5       [1 2 3 5]       4 out                 1       [1 2 3 5]                         2       [1 2 3 5]                         3       [1 2 3 5]                         4       [4 2 3 5]       1 out → 이땐 그냥 FIFO 야???                 5       [4 2 3 5]                   - Least Recently Used (LRU) Algorithm      가장 오래 동안 사용하지 않은 page 를 victim 으로 고름 → memory 의 temporal locality 속성을 사용한 방법   최근에 사용 여부를 결정하기 위해 HW 의 지원이 필요하고 2가지 방식이 존재 → Counter / Stack            Counter implementation                 Logical clock 또는 counter 사용       모든 page entry 는 time-of-use 필드를 가지고 있음       page 가 refer 될 때 마다 logical clock 을 time-of-use 필드 에 copy 함 → 이런 식으로 마지막에 refer 된 시간을 저장 ! 하지만 매번 참조될 때 마다 이뤄지는 copy 로 인한 overhead       Page replacement 가 발생하면 oldest time-of-use field를 serach해서 victim 으로 → 검색하는데 드는 시간으로 인한 overhead                    Stack implementation                                              Double Link 를 사용하는 stack 에 page number 를 저장해 순서 기록       page 가 refer 될 때 마다 top 으로 옮김 → 6 개의 pointer 가 변경되어야함 (bottom, bottom -1, origin top의 각 두 link를 변경해야하니)       serach 는 필요하지 않아요       buttom page 가 victim 으로 설정           [Example]           Reference string [1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5], 4 frmaes                          Page fault rate = 8/12 = 66.6..6%                          Ref String       Mem       Page Fault?                       1       [1]       init                 2       [1 2]       init                 3       [1 2 3]       init                 4       [1 2 3 4]       init                 1       [1 2 3 4]                         2       [1 2 3 4]                         5       [1 2 5 4]       3 out                 1       [1 2 5 4]                         2       [1 2 5 4]                         3       [1 2 5 3]       4 out                 4       [1 2 4 3]       5 out                 5       [5 2 4 3]       1 out           - LRU Approximation Algorithms      HW 에서 지원해주지 않는 경우 사용할 수 있는 알고리즘   Counter 나 stack 대신 Reference bit 사용                     OS 에 의해 처음엔 0 으로 초기화, page 가 refer 되면 1 로 설정           → refer 된 것은 알 수 있지만 order는 모른다는 문제 ㅜㅜ                   Second Chance            Reference bit 를 마찬가지로 사용하며 기본적으로 FIFO 방식       FIFO 에 의해 page 가 victim 으로 선택되었는데                    reference bit 가 1 : bit 를 0으로 바꾸어서 2번째 기회를 주고 다음 FIFO 선택           reference bit 가 0 : replace                       **circular queue 를 사용해서 구현하며 시계 방향으로 선택되기에 clock algorithims 라고도 함           Enhanced Second-Chance Algorithm → 수업시간에 언급하지는 않음            reference bit, modify bit pair 사용                    (0, 0) 최근에 사용되지 않았고 수정되지 않음 - 대체하기에 가장 적합한 페이지           (0, 1) 최근에 사용되지 않았지만 수정됨 - 대체되기 전에 페이지를 기록해야 하므로 약간 덜 적합합니다.           (1, 0) 최근에 사용되었고 깨끗함 - 아마 곧 다시 사용될 것입니다.           (1, 1) 최근에 사용되었고 수정됨 - 아마 곧 다시 사용될 것이며, 페이지는 대체되기 전에 보조 저장소로 기록되어야 합니다.                           - Counting Algorithms      각 Page 가 생성 된 이후로 counter of the number of references 를 유지 → 즉 생성 이후로 참조된 횟수를 계속 셈   LFU (least frequently used) Algorithm :            smallest count 를 replace       자주 사용되는 page의 reference counter 는 클 것이라는 가정           MFU (most frequently used) Algorithm :            largest count 를 replace?       가장 적게 참조된 page 는 최근에 가져와서 아직 사용하지 않은 것이라는 가정           이 방법들은 구현이 비싸고 OPT 를 잘 근사시키지 못하기에 자주 사용되는 방식은 아님   Allocation of Frames   - Allocation of Frames      사용가능한 frame 수를 넘어서 할당 시킬 수 없고 (page sharing 을 제외하고 생각한다면) , process는 각 process 마다 최소한으로 필요로 하는 page 수가 있음                     각 single instrction 이 reference 하는 모든 page 를 수용할 수 있을 정도의 frame 은 있어야함           → PF 발생 시 instruction 중지하고 PF 처리한 다음 instruction 재시작하는데, 이때 PF 처리하더라도 inst가 실행 되기 위한 page 정도는 기본적으로 가지고 있어야 재시작이 가능함                   ex) IBM 370 - SS MOVE instruction 을 위해 6 page 유지해야함            Instruction : 6 bytes → 아마 2 page       ‘from’ handling 위한 2 page       ‘to’ handling 위한 2 page           2가지 allocation schemes            Fixed Allocation       Priority Allocation           - Fixed Allocatioin      고정된 수의 frame 을 할당하는데 이때 균등하게 할당하냐, 비례하게 할당하냐에 따라서 나뉨            Equal Allocation                 process 에게 동일한 수의 frame 할당       ex) 5개의 process가 있고 100 frame 이 있을 때 각 Process 마다 20 frame 씩 할당                    Proportional Allocation                       process 의 size 에 비례하게 frame 할당 → 즉 각 process가 얼마나 need 하는지를 기반으로 분배       s_i = size of process p_i       S = ∑ s_i       m = total number of frames       a_i = allocation for p_i = (s_i/S) * m                ex) m = 64, s_1 = 10, s_2 = 127           → a_1 = (10/137) * 64 = 5, a_2 = (127/137) * 64 = 59                   - Prioirty Allocation      size 대신 priority 에 따라 비례적으로 분배하는 Proportional Allocation   P_i 가 Page fault 를 발생시켰다면, frame 중에 replacement 할 것을 고르는데            P_i 의 frame 중에 가져오거나       lower priority number 를 가지고 있는 process 로 부터 frame 뺏어옴           - Global vs Local Allocation      Global replacement : process는 모든 frame set 에서 replacement 할 frame 선택할 수 있음 → 즉 한 process 가 다른 process 로 부터 frame 가져올 수 있음            다른 process 의 동작에 영향을 미칠 수 있음       ex) 높은 우선순위를 가진 procss 는 낮은 우선순위를 가진 process들로부터 frame 을 가져올 수 있음           Local replacement : 각 process는 각자의 frmae set 에서만 replacement 할 frame 선택할 수 있음   Memory-Mapped Files   - Memory - Mapped Files      Memory-mappled files I/O 는  disk block 을 memory 의 page 에 mapping 하여 file I/O 를 memory access 처럼 취급할 수 있게 함 → 즉 파일을 memory 에 매핑한다는 소리   File 은 demand paging 을 통해 처음 read  되고, file의 page-size적 일부는 file system 에서 physical page 로 read 됨            File 에 대한 Read/Write To/From subsequent 는 memory access로 취급됨                File access 는 read(), write() system call 대신 memory 를 통한 file I/O 로 처리가 됩니당 !!       → memory와 file 간에 read / write 하는 것 대신 file 을 직접 memroy 에 mapping 해서 memory 를 읽고 쓰는 것 처럼 처리한다는 말       이 방식은 process 들이 memory 의 page 를 공유하는 것과 같은 방식으로 동일한 file 에 mapping 해서 공유할 수 있도록 허용            어떤 process 에 의해 write 된 것은 file의 같은 section 을 mapping 한 다른 process 들도 볼 수 있음           그럼 memory 에 mapping 된 page 는 언제 disk 에 write 되어야할까??            주기적 / file close() 시 / dirty page 탐색           - Technique for all I/O      Process 는 mmap() system call 을 통해 file 을 memory 를 매핑하라고 요청할 수 있고, 이를 통해 file 은 process address space 에 mapping됨   standard I/O (open(), read(), write(), close()) 은 일단 mmap() 을 사용하기는 하지만 process address space 가 아니라 kernel addrass space 에 매핑됨            process 는 kernel 과 process 간 복사를 위해 여전히 read() 와 write() 를 수행함       그래도 kernel 에 mapping 되어있기에 subsystem  분리 없이 효율적인 메모리 관리를 통해 성능 향상을 제공           COW(Copy-On-Write) 를 사용하여 read/write 가 자주 발생하지 않는 non-shared page 에 대해 최적화할 수 있음   shared memory 에 사용될 수 있어 여러 process 가 동일한 file 에 접근 할 수 있고 이를 통해 process 간 data 공유가 편해짐 → IPC(Inter-Process Communication) 없이 데이터를 공유 가능     File sharing      Shared Memory (이를 통해 communication 가능)    - Copy-on-Write (COW)          page 를 수정 할 경우에만 page 의 copy 을 만들어 수정하고, 수정하지 않을 경우는 따로 copy 하지 않고 원본 공유해서 사용   COW 은 parent 와 child 가 처음 부터 memory 은 같은 page 를 공유할 수 있게끔 해줌            shared page 는 COW page 라고 표시해두고 부모랑 자식 중에 하나가 공유된 page 를 수정할 때만 page copy       수정할 경우만 copy 하니까 process 생성 할 때 모든 page 를 다 copy 하지 않아도 되어서 더 효율적임           Thrashing   - Thrashing           process가 실행될 수 있을 만큼 충분한 page 를 memory가 가지고 있지 않다면…       → Page fault rate 가 매우 상승 → CPU utilization 이 낮아짐 → OS 는 degree of multiprogamming 증가하려함 → 다른 process 추가 → PF 더 발생 !            이 처럼 process 가 busy swapping page in &amp; out 하는 상황 (PF 가 연속적으로 계속해서 발생해서 성능이 갑자기 확 떨어지는 현상) 을 Thrashing 이라고 함           - Demand Paging and Thrashing      Thrashing 을 방지 하기 위해서는 process 가 필요한 만큼의 frame 을 가지고 있어야함 → 이를 위해 locality model 을 사용할거에욤   Locality Model            Locality : 함께 활발하게 사용되는 page set       process 는 locality 사이를 migrate 할 수 있음       program은 여러 locality 으로 구성될 수도 있고, 이들은 서로 겹칠 수도 있음           그럼 Thrashing 이 발생하는 조건은 ? → ∑(size of locality) &gt; (total memory size) 일 때 process의 active page 를 memory 에 유지 하지 못해서 발생   - Working-Set Model      Locality 를 기반으로 한 Model   𝚫 ≡ working-set window ≡ fixed number of page reference   $WS_i$  = Working set of Process $P_i$ : 최근 𝚫 번의 access 로 reference 된 page들의 set            𝚫 가 너무 작다면 WS 는 locality 전체를 포함하지 못 할 수 있음       𝚫 가 너무 크다면 WS 는 여러 locality 들이 겹칠 수 있음       𝚫 → ∞ 라면 WS 는 program 실행 중에 참조하는 모든 page를 포함함           $WSS_i$ = Working set size of Process $P_i$ : 최근 𝚫 번의 access 로 reference 된 page들의 수   D = $\\sum WSS_i$ ≡ Total Demand frames, m = total number of available frame            D &gt; m : process 중 하나 일시 중지하고 swap out 하여 p_i 에게 frame 할당해주어야함                       Page 가 actively 하게 사용된다면 WS 에 포함되어있을거고, 더 이상 사용하지 않는다면 WS 에서 나갈 것임 !       → WS 는 Program 의 locality 의 근사라고 할 수 있게되고, 이를 이용해 process 마다 필요한 frame 수를 알 수 있게 될 것임       - Keeping Track of the Working Set      WS 는 움직이는 window 이므로 이를 어떤 식으로 움직일지 (변화시킬지)에 대해 알아봅시다        매번 refer 가 일어날 때 마다 기록하기엔 overhead 가 굉장히 굉장히 클 것이므로 근사할거에요       → Fixed Interver Timer 와 Reference Bit 필요 !       [Example 𝚫 = 10,000 ]      5000 refer 마다 timer interrupt 발생!   각 page 마다 2개의 bit 를 유지 (10,000/5,000 = 2)   timer interrupt 발생하면 reference bit 를 조사해서 어떤 page 에 refer 가 일어났는지 기록하기 위해 저장하고 모든 refer bit 를 0으로 설정함        2개의 bit 중 하나라도 1 이라면 page 는 Working Set (WS) 에 ! !       → 5,000 refer 중에 언제 refer 가 발생했는지 몰라서 정확하진 않아욤,,       page 마다 10 bit 를 유지하고 1000 refer 마다 timer interrupt 발생시켜서 더 향상 시킬 수 있음! → timer interrupt 가 자주 발생할 수록 정확도는 올라가지만 cost 도 올라간다링   - Page-Fault Frequency Schme      허용가능한 Page-Fault Rate 정도를 제어 → Upper Bound / Lower Bound 정하기   Actual Rate &lt; Lower Bound : process 에 frame 이 너무 많이 할당 된 것이기에 frame 수 감소   Actual Rate &gt; Upper Bound : process 에 frame 이 너무 적게 할당 된 것이기에 frame 수 증가 시켜 더 할당   이런식으로 feedback 형식으로 제어   Allocating Kernel Memory   - Allocating Kernel Memory      Kernenl Memory 는 User Meory 와 다르게 취급해주어야함   일반적으로 kernel은 free-memory pool라고 하는 곳에서 memory를 할당                     kernenl 은 다양한 크기의 structure를 위해 memory 를 요청           →  다양한 크기다 보니 메모리를 보존하고 (가능한 빨리 반환하고 재사용하여 누수 방지) fragment 로 인한 낭비를 최소화하려고 함                        일부 kernel  memeory 는 연속적인 memroy 를 필요로 할 때도 있음           ex) I/O Device.. virtual memory 없이 바로 physical memory 랑 상호작용하니까?                   page 말고 다른 방법을 사용하여 관리함            Buddy System       Slab Allocator           - Buddy System      Physical-contiguous pages 로 구성된 고정된 크기의 segment 에서 memory 를 할당   2의 제곱으로 크기로 (power-of-2 allocator) 를 지정하여 메모리를 할당            Request는 2의 제곱으로 크기가 조정하기 위해 요청보다 큰 2의 제곱갑으로 올림 처리함 ex) 4KB, 8KB, 16KB       Available 보다 작은 할당이 필요한 경우 현재 chuck를 2개의 buddy 로 분할하여 다음으로 낮은 2의 제곱값으로 분할됨 그리고 이 과정을 가장 근접한 chunk 값을 얻을 떄 까지 진행           장점            사용되지 않은 chunk 를 빠르게 다시 하나로 결합시켜 빈공간을 효율적으로 사용할 수 있음           단점            Fragment… 작은 크기의 request 에 대한 memory 낭비 → 33KB 짜리 요청은 64KB 크기의 segment 만 만족시킬 수 있으니 31KB 가 낭비임           [Example 256KB 크기의 Chunk가 available, Kernel 은 21KB 를 요청한 경우]      $A_L$ , $A_R$ 을 각각 128KB 로 분할   그 중 하나를 $B_L$ , $B_R$ 을 각각 64KB 로 분할   그 중 하나를 $C_L$ , $C_R$ 을 각각 32KB 로 분할   $C_L$ , $C_R$ 중 하나를 요청을 충족시키기 위해 사용됨       - Slab Allocator      ALternate Strategy (대체 전략)   Slab : 하나 이상의 Physical contiguous page   Cache : 하나 이상의 Slab   kernel 의 고유한 data structure 마다 cache가 존재                     각 cache 는 data structure를 인스턴스화한 object 로 채워져 있음           ex) File object, Semaphores 를 나타내는 data structure를 위해 별도의 cache 가 존재                        Chche 에 있는 object 수는 slab 의 크기에 따라 달라짐       ex) 4KB 짜리의 contiguous page 3개로 이루어진 12KB 의 slab은 2KB 짜리 object 를 6개 저장할 수 있음       Cahce 가 생성될 때 free 라고 표시된 Object 들로 채워짐   그리고 Cache 에 Structure 가 저장될 때 Object 들은 used 라고 표시됨   Slab 이 used Object 들로 가득 찼다면 다음 object는 empty slab 에서 할당 됨            Empty slab 이 없다면 contiguous physical page 에서 새로 slab 을 할당 !           장점            물리적으로 연속된 페이지로 slab 을 구성하기에 fragment 가 없음 !       memroy 할당과 해제와 같은 요청을 빠르게 처리할 수 있음 !               Other Issue   - I/O Interlock      page 는 때때로 memory 에 lock 됨            process 가 I/O 요청을 발생하면 해당 요청은 queue 로 들어가고 CPU 는 다른 process 에게 주어짐       대기 중인 process 를 위해 memory buffer 의 page 를 교체       나중에 지정된 addresss로 I/O 가 발생하는데 해당 address가 다른 process (CPU 넘겨준) 에서 사용중일 수 있음 → 막아야해!           Device에서 file 복사하는데 사용되는 page 들은 page replacment algorithms 에 의해 eviction 으로 선택되지 않도록 lock 되어서 막아야함            Lock bit 는 모든 frame 있어야함       Frame 이 lock 이라면 replacement 를 위해 선택되지 않음       I/O 가 끝나면 unlock           - Prepaging      Process가 시작될 때 많은 Page fault 가 발생하는 것을 막기 위해 사용   Process가 필요로 하는 모든 page, 또는 일부 Page 를 page가 refer 되기 전에 가져옴   I/O 랑 Memory 낭비라 prepage 은 잘 사용 안하긴함   만약 s pages가 prepage 되고, page 중 a (0≤a≤1) 만큼 사용된다면            sa 만큼의 page fault 를 아끼는 것과 s(1-a) 만큼의 page 를 낭비하는 것 의 cost 비교       a 가 0 에 가까우면 → prepaging loses       a 가 1 에 가까우면 → prepaging win          ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch10",
        "teaser": null
      },{
        "title": "[Github blog] DISQUS로 minimal mistakes 에 commnet 기능 추가하기",
        "excerpt":"DISQUS   내가 작성한 글에 대해 독자와 의사소통 하기 위해서는 댓글 기능은 필수 중에 필수 ! (댓글이 많이 달리진 않겠지만,,,)   댓글 기능을 사용하기 위해선 여러 방법이 있지만 오늘은 DISQUS 을 사용해서 한번 댓글 기능을 추가해보겠다   1. DISQUS 가입하기   자 먼저 DISQUS 사이트에 접속해서 회원가입을 진행하자      이때 반드시 오른쪽을 선택해서 해야한다! 우리는 자기 블로그에다가 댓글 기능을 추가하려는 거니깡   첨에 안 보고 그냥 왼쪽 눌렀다가 왜 없지 하면서 한참 찾음,, ^^          2. 설정 들어가기    이제 설정에 들어가서 자기 블로그랑 연결을 해줘야한다! setting 을 누른 다음        SITE → General 클릭     저기 보면 shortname 이랑 Website URL 이 나올건데 예상하는 대로 잘 넣으면 끝 !   아마 shortname은 가입 했을 때 입력했을 건데 아이디 처럼 생각하면 된당 그리고 나중에 minimal mistakes 에 연결 할 때 이거 쓰니까 잘 기억해두기 ~   3. minimal mistakes (Github Blog) 에 연결  _config.yml 를 수정해주자! 총 3 곳을 수정해야한다   // in _config.yml comments:   provider                : \"disqus\" # false (default), \"disqus\", \"discourse\", \"facebook\", \"staticman\", \"staticman_v2\", \"utterances\", \"custom\"   disqus:     shortname             : rutuna  ...  # Defaults defaults:   # _posts   - scope:       path: \"\"       type: posts     values:       layout: single       author_profile: true       read_time: #true       show_date: true       comments: true # 댓글기능 ...       comments의 provider 를 “disqus” 라고 입력   comments의 disqus - shortname 에 본인 shortname 입력   defaults 의 values - comments 를 true 로 설정해서 comment 기능 활성화   4. 끝 !    위의 사항을 저장하고 push 하면 요로코롬 아주 잘 들어가 있는 것을 확인 할 수 있다    local 에서는 확인 안되는거 맞으니까 걱정 말아요 !!  ","categories": ["Github Blog"],
        "tags": ["Github","Blog"],
        "url": "/categories/develop/Github_Blog/comment",
        "teaser": null
      }]
