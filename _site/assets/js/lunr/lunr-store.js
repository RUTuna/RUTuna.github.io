var store = [{
        "title": "[포스팅 예시] 이곳에 제목을 입력하세요",
        "excerpt":"🦥 본문   본문은 여기에 …  ","categories": ["Categories1"],
        "tags": ["tag1","tag2"],
        "url": "/categories1/post-name-here/",
        "teaser": null
      },{
        "title": "[포스팅 예시] 이곳에 제목을 입력하세요",
        "excerpt":"🦥 본문   본문은 여기에 …  ","categories": ["Categories2"],
        "tags": ["tag1","tag2"],
        "url": "/categories2/post-name-here-2/",
        "teaser": null
      },{
        "title": "[포스팅 예시] 이곳에 제목을 입력하세요",
        "excerpt":"🦥 본문   본문은 여기에 …  ","categories": ["Categories3"],
        "tags": ["tag1","tag2"],
        "url": "/categories3/post-name-here-3/",
        "teaser": null
      },{
        "title": "[포스팅 예시] 이곳에 제목을 입력하세요",
        "excerpt":"🦥 본문   본문은 여기에 …  ","categories": ["Categories4"],
        "tags": ["tag1","tag2"],
        "url": "/categories4/post-name-here-4/",
        "teaser": null
      },{
        "title": "[포스팅 예시] 이곳에 제목을 입력하세요",
        "excerpt":"🦥 본문   본문은 여기에 …  ","categories": ["Categories5"],
        "tags": ["tag1","tag2"],
        "url": "/categories5/post-name-here-5/",
        "teaser": null
      },{
        "title": "[포스팅 예시] 이곳에 제목을 입력하세요",
        "excerpt":"🦥 본문   본문은 여기에 …  ","categories": ["Categories6"],
        "tags": ["tag1","tag2"],
        "url": "/categories6/post-name-here-6/",
        "teaser": null
      },{
        "title": "[포스팅 예시] 이곳에 제목을 입력하세요",
        "excerpt":"🦥 본문   본문은 여기에 …  ","categories": ["Categories7"],
        "tags": ["tag1","tag2"],
        "url": "/categories7/post-name-here-7/",
        "teaser": null
      },{
        "title": "[OS] Ch1. Introduction",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    Operating System  - Computer System Sturcture의 component             HW : 기본 computing resource 제공   ex) CPU, Memory, I/O Device   Operating Systme : 여러 application과 user 간의 HW 사용을 제어하고 조정   Application Program : System resource 가 user computin probelm 을 해결하는데 사용되는 방식 정의    ex) word processes, web browser   User   ex) people, machines, other computer   - OS 란?      computer의 user와 computer 의 HW 간 intermediary (중개자) 역할을 함            HW control &amp; manage       basic application 제공           Goal of OS → 결국 성능을 어떻게 더 좋게 할 것인가 . .            user program 실행하고, user problem 을 쉽게 해결할 수 있도록 제어 서비스 향상       computer system 을 사용하기 쉽게 user 에게 편리한 환경 제공하지       computer HW 를 효율적으로 사용하게 system 성능 향상           - Definition of OS? OS 역할!      OS는 Resource allocator            모든 리소스 관리하고 할당하는 역할       효과적이고 공평한 리소스 사용을 위해 상충되는 요청들 (여러 application 이 동일 resouce 에 접근하는 경우) 사이에서 결정내려줌           OS 는 Program controler            application과 I/O device를 제어감       program 실행을 제어해서 computer 사용의 error 와 improper 방지              사실 보편적인 정의는 없음 . . → OS 명령 시 오는 모든 것 정도로 생각하면 ㅇㅇ   Kernel : computer 에서 항상 실행 중인 한 program 으로 OS 의 core part 임 → 그 외는 system program (OS 와 함께 제공) 이거나 application program 임   system program (system utllities)            OS 와 associated 이지만 kernel 의 일부는 아님       program 개발과 실행하는데 편한 환경 제공    ex) editer, compiler, debugger, shell …               Computer System Architecture   - Single Processor System      single general-purpose processor 사용   special-purpose processor 사용하는 경우도 있긴 함!            graphics controller 나 disk controller       여기선 user process 실행하지 않음           - Multi-Processor Systme      paraller system 이나 tightly-coupled system 이라고도 알려져 있음   장점            throughtput 증가       multi single processor system 보다 경제적임       신뢰성 증가 → 서로의 영역에 접근을 안해서, , ?           Type            Asymmetric Multiprocessor (AMP) : 각 process에는 특정 task 가 할당되어 그 task 만 수행함! 그리고 master / slave procesor 로 나뉘어 master 가 slave 들 scheduling 하거나 관리       Sysmmetric Multiprocessor (SMP) : 모든 process 는 동일하며 모든 task 수행 가능! → 일반적으로는 보통 이 type                   -&gt; CPU 간은 BUS 나 Switch 로 연결되어 있고, 각 CPU 는 identical                   - Multi-core Processor System      single chip 에 multi computing core 가 존재 → CPU 의 한 Chip 에 여러 core 가 존재   N-core 가 있는 multi-core processor 는 N standard processor 로 OS 가 인식함   Type            Uniform Memory Access (UMA) : 모든 core 는 모든 memory 모듈에 대해 동일한 access time 을 가짐       Non-uniform Memory Access (NUMA) : core 마다 각 memory 모듈의 access time 이 다를 수 있음                       UMA 는 물리적 거리가 같기에 접근 시간이 동일한데       NUMA 는 물리적 거리가 다르기에 접근 시간이 다름           - 용어 정리?      Processor : logical 실행 단위 or 물리적 chip을 설명하기 위해 사용 → CPU 자체를 의미하기도 함! 근데 multi-core 에서는 좀 애매해짐   Core : L1 cache 및 funtional unit 을 포함하는 logical 실행 단위 → Processor 에 포함된 작업 단위   Chip : computer 에 있는 물리적 intergrated circuit (IC)   Soket : computer matherboard (메인모드) 에 있는 물리적인 connector 로 signle phtsical ship 을 수용 → soket 여러개인 메인보드는 multi-core chip 을 수용할 수 있음   - Operating System Structure      효율성을 위해 Multiprogramming이 필요함!            why?     → single programe은 CPU 및 I/O 장치를 항상 사용할 수 없는데 (독점 못하니까 ㅜㅜ) user는 여러 program을 실행해야함       Multiporgramming은 작업(code &amp; data)를 organize하여 CPU가 항상 하나만 실행 할 수 있도록 해줌     → 여러 process 들이 CPU 사용할 수 있게       system의 전체 작업 중 일부는 memory에 보관됨       Job Scheduling을 통해 실행할 하나의 작업이 선택됨       대기해야 할 때 (I/O Burst) OS는 다른 작업으로 전환됨           Timesharing (Multitasking)은 CPU가 작업을 너무 자주 전환해서 사용자 작업이 실행되는 동안 해당 작업과 상호작용 할 수 있는 interactive Computing (대화형 컴퓨팅)을 만들어내는 logical extension            respones time (요청 보내고 응답 받는데 걸리는 시간) 이 1초보다 짧아야함       각 사용자는 momory에서 실행되는 적어도 하나의 프로그램을 가지고 있음 → process       여러 작업이 동시에 실행될 준비가 된 경우 → CPU Scheduling을 통해 나눠주는       만약 process가 memory에 맞지 않으면 swapping을 통해 momory 밖으로 옮겨 실행할 수 있도록 함       가상 momory는 완전히 memory 에 있지 않은 process의 실행을 허용함 → Ch9 에서 좀 더 자세히           +) 사실 명확하게는 multitasking이랑은 다름 ! Timesharing 은 CPU 시간을 작은 단위로 분할하여 여러 사용자가 동시에 접근 할 수 있게하는 것           Computer System Operation   - Computer System Operation      I/O device 와 CPU는 동시에 실행될 수 있음 → 그래서 I/O burst 와 CPU Burst 가 따로인겨 !   각 device controller는 특정 device type을 담당하고 local buffer를 가지고 있음   CPU는 Main Memory ↔ local buffe 양 방향으로 data를 이동시킴   Device controller는 Interrupt를 발생시켜 CPU에게 operation이 끝났다는 것을 알림   - Computer System Operation들           Interrupt : 중요 event를 알리기 위해 processor에게 전달되는 signal       ex) 마우스 클릭 이벤드              HW와 SW는 interrupt를 유발할 수 있음                intterupt는 interrupt vector를 통해 보통 interrupt service routine으로 control을 전달하며, 이 interrupt vector에는 모든 service rouine의 address가 포함되어 있음           → 어디부터 실행하면 되는지 알려줘서 control 전달                   +) interrupt service routine : Computer System에서 발생하는 interrupt를 처리하기 위해 미리 정의된 code block → 즉 발생했을 때 어떻게 처리할 것인지       HW-generated interrupt 는 OS   SW-generated interrupt 에는 Trap과 Exception가 있음                     Trap : OS service를 위한 software request → 개발자가 의도를 가지고 design한           ex) file open.. 과 같은 system call                        Exception : software error → trap과 달리 bug..           ex) division by zero                   [Interrupt 과정]      현재 실행 중인 instruction 완료 (중단)   user program의 state를 reg나 stack에 저장   고정된 위치 (서비스 루틴의 address) 곳으로 실행 이동   interrupt service routine 실행   저장된 user program의 state로 restore   1에서 중단된 user program 실행 재개      OS와 user는 computer system의 HW/SW resource를 공유함 → 여기서 OS의 user 신뢰 문제 발생…            user program이 다른 program 이나 system 을 kill 해서는 안됨       그래서 Dual-mode를 사용함 !!           - Dual-mode      OS가 자신과 다른 sysptem component들을 보호하도록 하기 위해 사용하는   User mode / kernel mode 로 나뉨   User mode : 제한된 operation만 수행 가능 → application은 기본이 이 mode   Kernel mode (supervisor, system, privileged) : 모든 operation 수행 가능 → kernel은 이 mode   Mode bit (HW 에서 제공)            system이 User(mode bit = 1) / Kernel code(mode bit = 0) 중 뭐를 실행하고 있는지 구별 할 수 있도록       특권으로 설정된 어떤 instruction (다른 user나 system에게 영향을 줄 수 있는)은 kenel에서만 실행 가능함 (only kernel mode)       system call은 mode를 kernel mode로 변경하고 실행한 다음 return 되면 user mode로 다시 변경함 → kenel 에서 실행되는 동작이라서                 system call이 될 경우 trap을 발생시키고, mode bit를 0으로 바꿈   그리고 system call 처리후에 bit를 다시 1로 돌린 다음에  return       Management   - Timer      무한 루프나 process가 과하게 resource를 차지하는 것을 막기 위한 방법 → OS 는 효율적이게 동작하기 위해 관리하는 manager니까   특정 주기 이후에 interrupt 설정되게끔 → 주기마다 작업이 실행            OS는 counter를 설정하고 매 clock tick 마다 counter를 감소 시킴       counter 가 0이 되면 interrupt 설정                control을 되찾거나 할당된 시간을 초과한 program을 종료시키기 위하여 process scheduling 전에 설정       → scheduling 전에 timer 확인! 그래야 지난 애 있으면 대기나 다른 상태로 바꿔야 schduling 때 처리되니까       - GHz      CPU 에서 GHz는 clock frequency이며, clock rate, clock speed라고 하기도 함   일반적으로 clock speed가 빠를수록 CPU가 빠름        clock speed는 CPU 가 초당 실행하는 cycle 수로 측정하며 그 단위가 GHz       ex) A CPU with a clock speed of 3.2 GHz executes 3.2 billion cycles per second.       - Process Management      process는 실행 중인 program이며, system내 작업 단위임   Program은 Passive(패시브 ㅇㅇ) entity이고, Process는 Active(실행 중인) entity → 즉 program 중 실행 중인 것이 process   Process는 작업을 수행하기 위해 resources 가 필요함            CPU, Memory, I/O, File       Initializaion data → Input 받거나 . .           process 종료시 재사용 가능한 resources 를 되돌려 받아야함 → 다시 반납하쇼   Single-threaded process는 하나의 program counter (PC)를 가지고 있다            program counter (PC) : 실행할 다음 instruction 의 위치 지정       process는 완료 될 때 까지 한번에 하나씩 순차적으로 inst을 실행함           Multi-thredaded process는 thread당 하나의 program counter를 가지고 있다   일반적으로 system은 하나 또는 그 이상의 CPU들에서 동시에 실행 중인 많은 process들(some user, some OS)을 가지고 있다.            process / thred 간 CPU multiplexing를 통한 concurrency (동시성)           Process Management Activities            CPU에서 process 및 thread scheduling       user &amp; system processes 생성 및 삭제       process 일시 정지 및 재개       process synchronization 를 위한 매커니즘 제공                    process synchronization : 여러 process가 공유 중인 resouce에 접근하려고 할 때 실행 순서를 제어하여 서로의 작업에 영향을 주지 않도록 하는 기술                       process communication 을 위한 매커니즘 제공                    process communication : 서로 다른 process 간 data나 masseage를 주고 받는 기술                           - Memory Management      processing 전 후의 모든 Data은 main memory 에 있음!   실행을 위해 memory 에 있는 모든 instruction   Momory management는 memory 에 저장될 내용과, 그 시기를 결정함            user를 위해 CPU utilization 와 computer response 최적화           Main Memory Management Acticities            현재 실행 중인 memory part와 누구에 의해 사용 중인지 추적       memory 안팎으로 이동할 process (또는 그 일부) 및 data 결정       필요에 따라 memory 공간 할당 및 할당 해제           보조 기억장치도 관리해요 !   - Storage Management      OS는 information storage 에 대해 균일하고 논리적인 view를 제공            물리적 속성을 논리적 storage 단위인 file로 abstract → file 의 기본 컨셉       각 media 은 device (disk srive, tape drive)에 의해 control 됨                    access speed, capacity, data-transfer rate, access method (sequential or random) 이 속성에 포함되어 있음                           File-System Management            일반적으로 file은 directory들로 organiz됨       누가, 무엇에 access할 수 있는지 셜정하기 위해 대부분의 system에 대한 acces control       OS Activities                    file &amp; directory 생성 및 삭제           file &amp; directory 조작을 위한 primiotives           보조 storage에 file mapping           안정적인 (non-volatile) storage media에 file backup                   +) 어떻게 power 없이 안정적으로 file을 storage할 것인지가 OS에서는 중요한 도전과제                  ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch1",
        "teaser": null
      },{
        "title": "[OS] Ch2. Operating-System Structure",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    OS Services              OS Services    - Operating System Service      OS 별로 차이가 있긴 하나 보통 다음 4가지의 service로 구성            Booting Service : Couputer HW를 관리하고 Program을 실행 할 수 있도록 부팅함       User Service : 프로그래머가 programming 작업을 쉽게 할 수 있도록 함       System Service : System 이 효율적으로 동작하도록 보장       System Call : Program과 OS 간의 interface 를 제공하여 System 기능을 사용 할 수 있도록           -  User Service           User Interface :  대부분의 OS는 user unterface (UI)를 가지고 있음       ex) Comman-Line(CLI), Graphics User Interface(GUI) 등..            Program Execution : system은 program을 memory에 로드, 해당 program을 실행하고 정상 또는 비정싱 시 실행을 종료 할 수 있어야 함       ex) 메모리 할당, 해제, 프로세서 스케줄링       I/O Operation : 실행 중인 program에는 I/O가 필요할 수 있음! OS 는 I/O 동작 방법을 제공   File-System Manipulation : program은  file과 directory를 읽고 쓰고, 생성하고, 삭제하고, 검색하고 나열하고 권한을 관리해야함   Communications(통신) : proces는 같은 computer 내  process들이나, 네트워크로 연결된 다른 computer의  process들과 information을 교환할 수 있음            공유 memory 나 message 전달을 통해 통신이 이루어질 수 있음           Error Detection : OS 는  가능한 모든 HW/SW 수준에서의  error을 탐지하고 system을 모니터링하여 조정함으로 HW 문제를 예방해야함            user program, CPU, memory hardware, I/O device 등에서의 error 탐지       각 error에 대해 OS는 적절한 조치를  취해야함!       Debugging facilites가 도움이 될 수 있음           - System Service      Resource Allocation : 다수의 user나 job이 동시에 실행 될 경우 각각에 res를 할당해주어야함            다른 scheduling 방식을 가진 여러 종류의 resource 존재           Accounmtin / Logging : 어떤 user가 어떤 종류의 resource를 얼마나 많이 사용하고 있는지 정보를 저장하고 추천            user service를 개선하고 system을 재구성하는 연구, 통계 자료로도 사용           Protection and Security : computer system에 저장된 정보의 소유자의 사용을 제한할 수 있음. 그리고 서로 관련이 없는 여러 perocess이 동시에 실행 될 때는 다른 process나 OS를 방해하지 못하도록 보호해야함            Protection : resource에 대한 모든 액세스를 제어       Security : 외부 I/O를 방어하고 외부 user에 대해 인증을 요구               System Calls   - System Calls      OS에서 제공하는 service에 대한 programming interface → 실행 중인 prgram과 OS 간의 interface   일반적으로 high-level language인 C/C++ 로 작성됨   직접적인  system call 사용이라 아니라 주로 high-level  Application Program Interface (API)을 통해 system call 에 엑세스            potrability (이식)이 편함 system call은 더 자세하고 작업하기 어렵기 때문에!           일반적인 3가지 API            Window를 위한 Windows API       POSIX-based system(모든 버전의 UNIX, Linux, Mac OS X 포함)을 위한 POSIX API                    휴대용 OS Interface (POSIX) : OS 간의 호환성을 위해 IEEE가 정한 표준 제품군                       Java Virtual Machine (JVM)을 위한 JAVA API                ex)                 한 file의 내용을 다른 file로 복사하는 system call                           standard api         - System Call Implementation      System call interface는 API에서 function call을 가로채 OS Kernel에서 의도한 system call을 호출하고, system call의 state, 및 returen value를 반환함   일반적으로 각 system call에는 번호가 할당됨            system call interface는 이러한 번호에 따라 indexing된 table 을 유지, 관리함           caller는 system call이 어떻게 구현되어있는지 알 필요가 없음.            그냥 API를 따르고 호출 결과로 OS 가 수행할 작업만 이해하면 됨 → 걍 쓸거니까,,       API에 의해 OS Interface의 자세한 부분은 programer에게 숨겨짐              API - System Call - OS 관계도           User Application이 open()이라는 system call을 호출한 경우            Application이 open()이라는 system call 호출       system call interface는 open()의 system call number를 확인하고, 이를 실행하기 위해 kernel mode로 변경       kernel mode 에서 open()에 필요한 parameter들을 검사       file system 에서 file의 meta data를 읽어와 File Descriptor에게 할당하고, file table에 등록       File Descriptor는  open() 의 반환 값으로 user application에게 반환됨       반환된 File Descriptor를 이용하여 user application은 file을 읽거나 쓸 수 있음           - Standard C Library Example          Standard C Library 는 Linux와 UNIX 에게 일부 system call interface를 제공함   C program에서 printf()를 호출하면, system call인 write()를 호출함       OS Design and Implementation (OSDI)   - OS Design and Implementation      OS 의 Design과 Implementaion은 해결하지 못 하는 문제이지만, 일부 approache들은 성공적으로 증명되었다 → 나중에 나와요   다양한 OS 내부 구조들은 크게 달라질 수 있음   Goal과 Specification을 먼저 정의해서 OS 설계를 시작해야함!   System design은 HW 선택과 system type에 의해 영향을 받음            Batch, time shared, single user, multiuser, …           User goals &amp; System goal            User goal : OS는 사용하기 편하고, 배우기 쉬우며, 신뢰성이 있고, 안정하고 빠르게 동작해야함       System goal : OS 는 설계, 구현, 유지 보수가 용이해야하고, 유연하,며 신뢰성이 있으며, 오류가 없고, 효율적이어야함           OS의 requirement를 정의가 (정의하는 솔루션이) 유일한 것은 아님!!            다양하기에 OS 가 다양한 것           -  Seperate Mechanism &amp; Policy      Mechanism와 Policy를 분리하는 것이 OS 설계 및 구현에서의 중요한 principle            Mechanism : 어떻게 할 건가?       Policy : 무엇을 할 건가?           ex) CPU 보호를 보장해야함!!       →  Mechanism : Timer 구조를 사용하자, Policy :  특정 user에 대해서 timer를 얼마나 길게 설정하지?            Mechanism와 Policy를 분리는 policy 결정이 나중에 변경되는 경우에 대처할 수 있는 유연성을 제공함       ex) CPU-intensive 한 program보다 I/O-intensive한 program에 우선순위를 부여하는 policy           OS Structure   - Simple Structure (Monolithic, 단일구조)      OS 기능을 kernel 과 동일한 memory 공간에 두고 system call 만으로 사용함   Not Well-definde인 구조   작고 단순하며 제한된 system으로 시작하여 성장!   module로 나누지 않음   [MS-DOS]         초기에는 memory 공간이 제한적이었기에, 최대한 적은 공간을 차지하면서 최대한 많은 기능을 제공하기 위해 초기에 작성됨   처음에는 간단한 OS 였지만, 시간에 따라 컴퓨터 기술이 발전하면서 새로운 기능이 계속해서 추가됨 → 초기에 계획된 제한적 범위를 넘어섬   초기에는 I/O Interface와 level이 분리되어 있지 않아 application이 직접 I/O Device에 접근할 수 있음            오작동과 악성 프로그램의 위험성이 높았음 ㅠㅠ           그 당시 HW 도 제한적이었기에 Dual Mode를 지원하지 않았음            그렇기에 이러한 HW에서도 잘 동작되도록 개발           [Traditional UNIX (Monolithic)]         매우 광범위한 기능이 Kernel에 집약되어있음                     Kernel 아래 System call interface 이하의 모든 기능이 kernel에 통합됨 (단일층 . .)           → kenel은 OS 에서 거의 모든 일을 처리함                   매우 적은 Layering (계층구조)을 가지고 있으며, 두꺼운 monolthic layer로 구성되어 있다.            적은 만큼 각 계층간 interface가 충분하지 않기에, 구현과 유지보수가 어려움           즉. Tranditional UNIX는 기능이 통합된 kernel과 layering이 얇은 구조로 인해 확장성이 제한적이며, 구현과 유지 보수가 어려움   [Monolithic Structure]                 OS는 system Call Interface 아래 하나의 장소에 모두 포함   Application은 system call interface를 사용하여 kernel과 상호작용   ex) Unix, Window XP, Linux과 같은 상용 system에서 일반적으로 사용   장점            성능 우수 → 직접 통신이라       kernel 개발자가 쉽게 개발 할 수 있음           단점            kernel component 간 보호 없음 → 다 통합된 공간에 있으니..       쉽게 확장되지 않음 → 다 kernel 에 넣어야해서       전체 구조가 복잡해짐       하나에 문제가 발생하는 순간 어디에 문제가 발생한 것인지 몰라 복구 어려움           - Layerd Approach                  OS 는 하위 layer위에 구축된 여러 layer (level)로 나뉨            The bottom layer (level 0) : HW       The highest Layer (level N) : User Interface           Moularity를 통해 각 layer는 하위 level layer의 functions(operations) 및 service만을 사용하도록 선택            자신보다 하위인 layer에서 제공하는 functions(operations) 및 service를 이용해 본인 layer를 구축함           장점            각 layer가 서로 분리되어있기에 보안이 강화       각 layer의 문제가 전체 system에 영향을 미치는 것을 방지할 수 있고 독립적으로 디버깅 및 교체 가능                    low-level routines의 구현 세부사항을 숨김                       유연하고 확장성이 높은 OS를 만드는데 유용함           단점            여러 layer를 적절하게 정의하는 것에 어려움이 있을 수 있음       효율성 → layer가 많을 수록 function간 더 많은 Indirection (간접 참조)가 필요하고 이로 인해 function overhead가 커짐           - Microkernels System Structure      Microkernel은 필수적인 OS 기능만을 포함시킨 축소된 OS core   기존 OS에서 kernel에 있던 기능을 user space로 옮겨, kernel에는 기본적인 기능만 남겨둠 → 필수만 남긴다!   Kernel에 남긴 기능            기본적인 Memory 관리       I/O와 iterrup 관리       Process간 통신       기본 Scheduling           전통 OS에 포함되는 많은 service들이 User Process로 동작            Device driver       File system       Virual Memory 관리       Security sercvice       etc..           example: QNIX, Tru64, UNIS, Mach        User modules간 통신은 message passing을 통해 이루어짐       ex) 디스플레이를 필요로 하는 클라이언트 프로그램은 마이크로커널과 메시지 교환을 통해 간접적으로 디스플레이 서비스와 통신                   장점            확장성 : 새로운 서비스를 Kernel이 아닌 user space에 추가하므로, microkenel 기반 OS를 확장하는 것이 더 쉬움       호환성 : Microkernel만 변경하고 그 외의 service는 변경하지 않아도 되기에 다른 CPU로 port하는 것이 쉬움.       신뢰성 &amp; 보안성 : 많은 코드가 kenel mode에서 실행되지 않기에 User space service의 error가 kernel space에 영향을 주지 않아 안전함           단점            Performance overhead : User space와 kernel space 사이에 통신이 많기에 이에 따라 overhead가 발생 할 수 있음       Communication from User space to Kernel space : 사용자 공간의 서비스가 커널 공간과 통신할 때 보안 문제가 발생 가능성                Layer VS Mocrokernel                   - Modules      많은 최신 OS는 kernel module을 구현함   Object-oriented approach와 유사함            각 core component는 분리되어 있음       각 component은 알려진 interface를 통해 다른 component와 통신함       필요한 경우 kernel 내에서 load 가능함           전반적으로 layer 구조와 비슷하지만 더 flexibility함            어떤 module도 다른 module을 호출 가능함!           Modules은 microkernel 방식과도 유사하지만, Modules은 kernel 내부에 있으며 통신을 위한 message passing이 필요하지 않음   [ex. Solaris Modular Approach]          Core Kernel 을 중심으로 7가지 type의 module로 구성한 소프트웨어 모듈화 접급 방식            scheduling classes       file systems       loadable system calls       executable formats       STREAMS modules       miscellaneous       device and bus drivers          ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch2",
        "teaser": null
      },{
        "title": "[OS] Ch3. Processes",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    Process Concept   - Process Concept                    Process : 실행 중인 progeam → 실행되었으니 memory 에 적제되었고, 자신만의 memory 영역이 있는 것 !   Process 실행은 무조건 순차적으로 실행되어야 함   Process에 포함 된 것            Text Section (loaded Progeam)       Program Counter       Stack (Temporay data) : 함수 parameter나, reture address, local variable을 저장하는 일시적인 memory 영역       Head : 동적으로 할당된 memory → Stack 이랑 비슷하지만 동적으로 할당된다는 점이 다름! 더 static하고 global함       Data Section (Global Variables) : Global variable등 초기화된 data를 저장           - Process State      Process가 실행되는 동안 process의 state는 계속해서 변경됨            new : Process가 생성되는 중       running :  Instriction이 실행되고 있는 상태       waiting : Process가 어떤 event가 발생하기를 기다리는 중       ready : Process가 processor에 할당되기를 기다리는 중       terminated : process가 실행을 완료함               - Process Lift Cycle          New → Ready : 새로 생성되는 New에서 실행 가능한 상태인 Ready 로 전환   Ready → Running : Kernel이 scheduling 할 때 process는 ready 상태에서 running으로 전환   Running → Waiting : 만약, Process가 blocked되어 event가 발생하기를 기다린다면 waiting으로 전환 ex) I/O   Waiting → Ready : Event가 완료되면 다시 Ready 상대로 전환   Running → Ready : Interrupt가 발생하면 실행 되다가 다시 실행 가능 상태인 ready로 전환   Running → Terminated : exit()가 호출되면 실행 완료한 것이므로 종료하기 위해 terminated로 전환   - Process Control Block (PCB)         Particular process를 관리하기 위해 필요한 정보가 포함된 OS의 데이터 구조   각 Process와 관련된 정보들 → OS에서 process를 표현하는 .. !            Process State       Program Counter       CPU registers       CPU Scheduling information       Memory-management information       Accountin information       I/O status information           Process Scheduling   - Context Switch          P1가 CPU 사용중인 상황인데, P2가 CPU를 사용해야하는 일이 발생   Kernel의 Interttupt Handler가 P1을 중지하고 PCB0에 P1에 대한 정보(reg 정보, process state 등)를 저장함   다음에 실행할 P2에 대한 정보를 PCB1에서 가져옴   Interrupt Handler는 다시 CPU를 P2에 할당하고, P2에서 PCB1에서 받아온 reg 정보, process state를 읽어와 CPU가 실행하도록 함   P2 실행            CPU Switch from Process to Procee       CPU가 다른 process로 전환된다면 system은 무조건 이전 process의 state를 save하고, 새로운 process의 state를 load 해야함       Process의 Context는 PCB로 표현됨       Context Switch 과정은 사실 유용한 작업을 수행하는 것은 아니고 단지 전환이기에 순전한 overhead 임 ㅜㅜ       switch되는 속도는 memory 속도나, 복사해야하는 reg 수 등등에 따라 달라짐                 보통은 마이크로 초 단위           - Process Scheduling Queues           Job Queue : System의 모든 실행 가능한 process들의 set   Ready Queue : Main memory에 상주하며, 실행될 준비가 되었거나(ready) 기다리는 (waiting) 상태의 process들의 set   Device Queue (I/O wait Queue) : I/O Device를 기다리는 procee들의 set            process는 다양한 Queue들 사이에서 이동함       Queue는 보통 linked list로 구현       Process schduling하는 과정 Queueing-Diagram으로 표현                            Process는 I/O request를 발생 시킨 후 I/O Wait Queue에 추가될 수 있음       process는 새로운 child process를 생성한 다음, child의 종료를 기다리는 동안 ready Queue에 추가될 수 있음       Process가 interrupt 또는 time slice expired에 의해 강제로 core 에서 제거 되었다면 Ready Queue에 추가될 수 있음           - Schedulers      Long-term Scheduler (Job Scheduler) : Ready Queue로 추가할 process 선택하는 것이 목적            매우 드물게 호출 : (second, miniutes) → 느려도 괜찮앙       Degree of multiprogramming를 제어           Short-term Scheduler (CPU Scheduler) : 다음에 실행되고 CPU에 할당할 process 선택하는 것이 목적            매우 자주 호출 : (milliseceons) → 빨라야함!!           Process는 둘 중 하나로 설명 가능            CPU-bound-process : 계산에 더 많은 시간을 소비하고, 적고 긴 CPU Burssts → Long-term                    그래서 Long-term Scheduler는 결정을 신중해야해야함..                       I/O-bound-process : 계산보다 I/O 를 수행하는데 더 많은 시간을 소비하고. 많고 짧은 CPU Bursts →Short-term       CPU Bursts : Process가 CPU를 사용하는 시간               +) Medium-term Scheduler :   Time-sharing system 에서 Degree of multiprogramming (동시에 실행 중인 program 수?)를 줄이기 위해 process를 memory에서 temporarily(일시적)으로 제거함  → 나중에 process 재시작함!!   → Swapping       Operation on Processes   - Process Creation (프로세스 생성)          Creating precess를 Parent Process라고 하고 이때 생성되는 새 process를 Child Process라고 함 → Parent가 Child Process 생성   생성된 Child Process가 또 다른 Process를 생성하면서 Process tree를 만듦   일반적으로 Process는 식별자(PID) 를 통해 식별되고 관리됨   Resource Sharing            부모와 자식은 모든 리소스를 공유 → 둘 다 동일한 리소스에 접근 가능       자식은 부모의 일부 리소스를 공유 → 자식은 부모의 일부 리소스에만 접근할 수 있음       부모와 자식은 리소스를 공유하지 않음 →  서로 독립적           Execution            부모와 자식이 동시에 실행       부모는 자식이 terminate될 떄 까지 wait           Address Space            자식은 부모의 duplicate       자식은 새로운 program을 load           - Process Creation in UNIX      UNIX에서 process를 생성하는 system call들           fork() : 새로운 process를 생성함! → 부모 process의 모든 것을 그대로 복제시켜 자식 process 생성   exec() : Process의 memory space를 fork로 생성된 새 process로 대체하기 위해 fork 다음으로 실행되는 system call            fork할 때 부모를 그대로 복제하면서 메모리 공간도 그대로 복제시켜버림..       복제된 process가 같은 program이 아니라 다른 program을 실행시켜야 하므로 새 memory space로 덮어씌움           → 즉 그대로 복제 한 다음에 실행할 program 으로 덮어씌우는 형태로 보통 fork-exec  같이 사용함       wait() : 부모에 의해 호출됨! 자식 process가 종료 될 떄 까지 부모 process를 일시적으로 중단하고 대기시킴   exit() : 호출한 prcoess를 종료   - Process Termination      process는 마지막 statement를 실행하고 OS에게 삭제를 요청하여 종료함 (exit)            Process는 부모에게 state value를 return할 수도 있음 → wait를 통해!       Process의 리소스는 OS에 의해 해제됨           부모는 자식 process의 실행을 종료 시킬 수도 있음 (abort)            자식이 할당된 리소스를 초과하는 경우       자식에게 할당된 작업이 더 이상 필요하지 않은 경우       부모가 종료된 경우                    일부 OS는 부모가 종료되면 자식의 계속 실행을 허용하지 않는 것도 있음 → 그럼 이제 모든 자식이 연쇄적으로 다 종료되는..                           Interprocess Communication   - Cooperating Processes (협력 프로세스)      Cooperating Process는 독립적인 proces와 달리 다른 process의 실행에 영향을 줄 수도, 받을 수도 있음!!            +) 독립적인 Process는 다른 process의 실행에 영향을 줄 수도, 받을 수도 없음       서로 상호작용하면서 특정 기능을 수행           장점 (Process Cooperation 환경을 제공하는 이유)            정보 공유 : 같은 데이터에 여러 user가 관심을 가질 수 있음 (ex. shared files) 그러면 제한된 리소스 사용 효율성 증가       연산 속도 향상 : task를 subtask로 나눠서 병렬로 실행할 수 있음       모듈성 : 모듈 방식으로 system을 디자인하면서 system function을 separeate process로 나눌 수 있음       편리성 : 동시에 개별 사용자가 많은 task를 를 수행 할 수도 있게 됨           단점            병행 process간의 synchronization 되어야한다는 문제와 이때의 reace condition           - Interprocess Communication (IPC)      Process간 통신하고 synchronize하는 매커니즘!        IPC에는 2가지 모델(방법)이 있고 둘다 OS에서 일반적으로 사용             왼) Message Passing         오) Shard Memory                        Shard Memory : 동일한 주소 공간과 공유 변수 사용 → 즉 공유되는 memory 공간이 있다는 뜻                    어디에 메모 남기고 가면 다른 사람이 보고 확인하는 방식이랑 비슷 ㅋㅋ           system call은 공유 memory 영역을 설정하는데만 필요함           모든 access는 routine memory access로 처리됨                       Message Passing : 공유 변수에 의존하지 않고 process가 각각 통신함                    카톡 보내는거랑 비슷합니다요           작은 양의 data(simple data)를 교환하는데 유용함           충돌 없이 구현하기게 쉬움                           - Shard Memory      통신하는 Process간 공유되는 memory 공간이 있음   통신은 OS가 아닌 User process의 제어 아래에 있음 → User process에 따라서 통신   User process가 공유 메모리에 접근 할 때 동기화 하는 방법을 제공하는 것이 가장 큰 문제! → Producer - Consumer 문제   동기화에 대해서는 나중에 . . .   - Producer - Consumer Problem (in shard memory)           Cooperatin process의 패러다임, 생산자 프로세스는 소비자 프로세스가 소비하는 정보를 생산함       → 정보가 없는데 소비자가 소비하려하거나, 정보가 가득 찼는데 정보를 생성하려는 문제가 발생하지 않도록       공유 memory는  Buffer를 사용하여 Buffer의 item이 Producer에 의해 채워지고, Consumer에 의해 비워지는 방식 사용            동시에 접근하는 문제를 해결하기 위한 방법임!           Unbounded-Buffer            Buffer의 크기에 실질적인 제한을 두지 않아 producer는 항상 생산하도록       Consumer는 buffer가 empty라면 기다려야함           Bounded-Buffer → Circular Buffer            Buffer의 크기가 고정되어있다고 가정하여 Producer는 buffer가 가득 찼다면 기다려야함       Consumer는 마찬가지로 buffer가 empty라면 기다려야함           [Bounded-Buffer]   #define BUFFER_SIZE 10  typedef struct { \t... } item;  item buffer[BUFFER_SIZE];  int in = 0;          // point to next free position (Producer가 생성해서 넣을 위치) int out = 0;         // point to first full position (Consumer가 받을 위치)*          If in == out : Buffer is Empty → 넣을 곳과 가져올 곳이 동일하니   If ((in+1) % BUFFER_SIZE) == out : Buffer is Full → 넣을 곳 다음이 바로 가져올 곳이니 한바퀴 돌았다는 뜻            왜? in+1 == out  이면 가득찼다는 것인데 overflow 방지를 위해 순환식으로 사용하다보니까 모듈값이 out이 되어야함                이 해결 방법이 제대로 작동하긴 하지만 BUFFER_SIZE-1 개의 element만 사용할 수 있다는 단점이 있음       → Full 일 때 in과 out 이 차이가 나야 Full 과 Empty 구별가능하니까 하나 비워두기       // Producer while (true) { \t/* Produce an item */ \twhile ((**(in + 1) % BUFFER_SIZE)**  == out);    /* free buffer가 없는 동안에는 (full 상태) 아무것도 안함 */   \t/* full 이 아니면 */ \tbuffer[in] = item; \tin = **(in + 1) % BUFFER SIZE**;                 /* overflow 방지하기 위해 순환방식을 사용하고자 modular */ }  // Consumer while (true) { \twhile (in == out);                           /*  buffer 안에 아무것도 없는 동안 (empty 상태) 아무것도 안함 */  \t// remove an item from the buffer \titem = buffer[out];  \tout = **(out + 1) % BUFFER SIZE**;               /* overflow 방지하기 위해 순환방식을 사용하고자 modular */ }*   - Message Passing      Process간 서로 통신하고 행동을 동기화하는 매커니즘 → 동기화한다는 점에서 공유 메모리랑 다르죠            shard memory 는 mem 을 동기화, 얘는 행동을 동기화           동일한 주소 공간을 쓰지 않고, Process간 직접 통신하고 동기화할 수 있도록 허용   Direct / Indirect 2가지 통신이 있음            Direct는 누구한테 보내고 받는 지를 명시 → 직배송       Indirect는 mail box같은 것을 통해서 전달함 → 배대지 사용하는 느낌?           2가지 Operation (직접 통신 버전) 제공            Send(receiverID, message) → message size는 구현에 따라 고정일 수도 있고, 변수일 수도 있음                Receive(senderID, message)           *  Indirect였다면 ID 가 아니라 mailbox 위치가 파라미터로 사용                   두 Process간 통신 할 때 다음 과정이 필요            그들간 communication link 설정 → 통신망 느낌       send/receive 를 통해 message 교환                    Soket programming처럼 soket만들고 연결 link 만들고 soket 보내는 방식과 유사                           구현 문제..            link 어케 설정해?       모든 통신 process 쌍 간에 몇개의 link가 있을 수 있을까?       link의 capacity는?       message 크기는 고정이야 가변이야?       link는 단방향이야 양방향이야?           - Synchronization (in message passing)      message passing 에는 block / non-block 방식이 있음   Blocking → rendezvous (랑데뷰) 방식            Synchronize로 간주됨 (응답 올 때 까지 대기! 암거도 못해!)       Block-send : Sender가 msg 보낸 후, Reciver가 받을 때 까지 Send를 block (sender 아님!!! send method를 블락한다는거)       Block-receive : Msg를 사용할 수 있을 때 까지 Receive를 block (reveiver 아님!!! receive method를 블락한다는거)           Non-blocking            Asynchonize로 간주됨 (응답 오던 말던 다 함 ㅋ)       Nonblock-send  **:** Sender가 msg보낸 후에도 계속 send 할 수 있도록 허용       Nonblock-receive : vaild message나 null을 retrieve할 수 있도록 허용 (받는 담에 vaild일 떄만 ㄹㅇ 받아융)           non-block 방식이 더 유용함!   message next_produced;   while (true) { \t/* produce an item in next produced */ \tsend(next_produced);  // 계속 보냄 }  message next_consumed;   while (true) { \treceive(next_consumed); // -&gt; 일단 받고 ㅋㅋ \t/* consume the item in next consumed */  }*   - Buffering      Indirect 방식에서 사용 . . ? Message 수용하는..   Link에 message Queue를 연결하는 방식으로 다음 3가지 중 보통 하나는 사용            Zero capacity : 0 message 가능                 Queue의 수용 공간이 0이라 msg 보관이 안됨       그렇기에 sender는 receiver가 받을 때까지 기다려야함 (block) → rendezvous (랑데뷰) 방식                    Bounded capacity : 유한한 N 개의 message 가능                       N 길이의 Queue를 가짐       Link가 Full이라면 sender는 기다려야함 (block)                    Unbounded capacity : 무한한 message . . 가능                       Sender가 기다릴 일이 없어용 ~  !          ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch3",
        "teaser": null
      },{
        "title": "[OS] Ch4. Thread",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    Overview   - Threads      Instructions Sequence를 실행하는 CPU utilization의 기본 단위 → 실행 단위 !            OS scheduler가 독립적으로 관리하는 가장 작은 sequence       자체 Thread ID, Program Counter(PC), Register set, Stack 를 가지고 있음           Process는 하나 이상의 Thread를 가질 수 있고, 하나 이상의 task를 동시에 실행할 수 있음            process의 다른 thread과 reaource (code, data section, heap…) 를 공유하기에 lightweight       프로세스와 비슷한 lifecycle을 가짐 → ready, waiting, running           Single processor에서 multithreading은 일반적으로 multiplexing에 의함            single processor 라서 multiplexing 하려면 한 processor 내에서 thread간 전환이 굉장히 빠르고 자주 발생 해야함.. → context switch 로 인한 overhead           Multiprocess (including multi-cores)에서 thread는 실제로 동시로 실행 될 수 있으며, 각 core는 특정 thread를 실행         - 왜 Threads 방식을 사용했을까?      경우에 따라서 하나의 application이 동시에 여러 task를 실행해야하는 경우가 있음. 근데 이때 모든 task마다 새로운 process를 생성하기에는 시간이랑 리소스가 너무 많이 소모됨 ㅜㅜ   그래서 하나의 process에 task를 실행할 수 있는 thread를 여러개 두는 방식을 사용!   장점            빠름!       생성, 전환에 드는 ovehead가 적음       동일한 주소 공간을 공유할 수 있음           - Multithreaded server           하나의 process에서 여러 비슷한 task를 수행하는 경우의 예시 ex) 웹서버                   웹 서버는 클라이언트 요청을 받는데, 이 클라이언트가 동시에 굉장히 많을 수 있음        기존의 단일 threas process로 실행된다면, 한번에 하나의 클라이언트에게만 받은 요청에 대한 서비스를 제공 할 수 있어서 다른 클라리언트들은 굉장히 기다려야했음 ㅜㅜ       → 이걸 요청을 처리하는 별도의 thread를 만들어 해결! 즉, 요청 처리하는 thread 따로 있도 다른 사용자 상호작용이나 그런 작업하는 thread 따로 있는       client가 server에 요청을 보내면, 새로운 thread를 만들어 요청에 대한 서비스를 하도록하고, server는 계속 클라이언트들에게 요청을 받음   장점            Responsiveness :                    일부 part가 block되거나 긴 작업을 수행하는 동안에도 application은 계속 실행될 수 있음 → 사용자에 대한 응답성 향상           그니까 버튼을 눌렀는데 시간이 겁나 오래 걸리는 동작일 경우.. 이 시간에도 다른 요청을 받을 수 있게 됨                       Resource Sharing :                    Process는 원래 공유 메모리나 메세지 전달과 같은 기술을 통해서만 리소스를 공유할 수 있음           근데 Thread는 기본적으로 자신이 속한 process의 memory와 resource를 공유함           그렇기에 application이 동일한 주소 공간 내에서 여러 실행 중인 thread를 가질 수 있음                       Economy :                    process 생성을 위해 매 process 마다 memory와 resource 할당하는 데는 비용이 많이 듬.. ㅜㅜ           근데 thread는 그냥 자기가 속한 process의 memory와  resourc를 공유하므로 따로 할당안해줘두 됨 ! 그래서 차라리 thread만들고 전환하는게 더 경제적                       Scalability :                    다중 CPU system에서 multithreading사용하면 병렬 처리가 더 증가됨           즉, multithreading의 장점은 서로 다른 processing core에서 병렬적으로 thread가 실행 중인 multiprocess 구조에서 더 커짐           단일 thread process는 짜피 한 process니까?                           - Multicore Programming      Multicore or Multiprocessro system은 다음과 같은 이유로 프로그래머에게 압박감을 줌 ㅠㅠ            Dividing activities, Balance, Data splitting, Data dependency, Testing and debugging           Concurrency(동시성)는 하나 이상의 작업 진행을 할 수 있음을 의미   Parallelism(병렬성)은 System이 하나 이상의 작업을 동시에 수행 할 수 있음을 의미        즉, Concurrency는 동시에 실행되는 것 처럼 보이게 하는 것으로 single-core, multi-core 둘 다 가능하며, Parallelism은 실제로 동시에 수행되는 것으로 multi-core에서만 가능한 개념                          Concurrency은 동시에 실행되는 것 처럼 Thread를 왔다갔다 거리며 실행하지만, Parallelism은 여러 core로 실제로 동시에 실행시킴. (1,2) (3,4) 이렇게           Type of Parallelism            Data prarallelism - 동일한 데이터의 subset을 여러 core에 분산, 각 thread는 동일한 operation 을  각각 수행       Task parallelism - core 에 thread를 분산, 각 thread는 고유한 operation 수행               Multithreading Models   - Multithreading models      Kernel Threads : Kernel에서 지원 받음            ex) Windows, Solaris, Linux, Mac OS X 등을 포함한 거의 모든 일반적인 OS           User Threads : user-level therad library에 의해 수행되는 management            3가지 중요한 thread library                    POSIX Pthreads           Win32 threads           Java threads                           - Kernel Threads      Kernel (OS) 가 직접 관리하는 thread로, Kernel은 System call에 의한 생성되고 파괴되는 thread를 모두 알고 있음   그렇기에 thread가 차단되면, 전체 thread 를 차단하지 않고 다른 thread를 예약할 수 있음   Thread 기반으로 Fine-grain 수행            Fine-grain : 하나의 작업을 작은 단위로 나눈 뒤, 다수의 호출을 통해 작업 결과를 생성하는 방식       Kernel은 thread를 관리하기 위해 process scheduling algorithms을 사용함           kernel mode 권한 관련에 의해 thread 전환이 무거움   - User Threads      Kernel은 user-level thread의 존재를 알지 못하고(인식하지 못함), thread가 포함된 process만 알고 있음 → 즉 process 단위로 인식   Thread management는 user-level therad library에 의해 수행됨            개발자는 thread 라이브러리를 사용해서 thread를 관리 (생성, 삭제, 예약 전환 등..) 함           Thread가 차단되면, processd의 다른 모든 thread를 포함한 전체 process가 종료됨            Thread block → process block → process 내 다른 thread도 block           Kernel은 thread가 아니라 process를 scheduling 함 → thread는 user-level에서 관리하니까   kernel mode 권한이 필요하지 않아서 thread 전환이 가벼움   - 다양한 Multi-threading Models      궁극적으로 user thread와 kernel thread 사이에 관계가 무조건 존재해야함   그 관계의 종류            Many-to-One       One-to-One       Many-to-Many           → user가 하나고, 여러개의 kernel 가 있을 순 없으니 . .       - Many-to-One Model (user-level thread)      여러개의 user-thread가 단일 kernel-thread에 매핑됨 → kernel 이 process 단위로 관리   지금 이 모델 사용하는 경우는 거의 없음!   장점            Thread management가 user space에서 이루어짐 →즉, scheduling 이 user-threas library 에서 이뤄져서 효율적임!           단점            Thread가 block되면, 전체 process도 block 된다는 문제점 ㅜㅜ → kernel 이 process 단위로 인식하다 보니까       process단위로 kernel 이 관리하다보디 process 단위로 할당해서 Thread의 병렬 실행이 없음 ㅜㅜ 그래서 multiple CPU를 이용 할 수 없다 !           ex) Solaris Green Threads, GNU Portable Threads       - One-to-One Model (kernel-level thread)      각 user-threaed가 kernel-thread에 매핑됨 → kernel 이 process 내 thread 단위로 관리   장점            Thread를 block해도 다른 thread가 block 되지 않음       parallelism이 증가해 multiprocessor 성능이 향상됨           단점            User-thread를 생성하려면, kernel-thread도 생성해야함 → 그렇기에 overhead가 증가하고 thread 수에 제한이 생김           ex) Windows NT/XP/2000, Linux, Solaris 9랑 그 이후 모델들       - Many-to-Many Model      여러 user-thread가 여러 kernel-thread에 매핑 할 수 있도록 허용   OS가 충분한 수의 kernel-thread를 생성할 수 있도록 허용   장점            parallelism이 증가해 multiprocessor 성능이 향상됨           단점            일반적으로 구현하기에 복잡함 ㅜㅜ           ex) Solaris prior to version 9, Windows NT/2000 with the Thread Fiver package       - Two-level Model      Many-to-Many랑 비슷하지만, 얘는 user-thread와 kernel-thread간의 bound를 허용한다는 점이 다름            Bounded threads : User thread 가 지정된 단일 kernel thread (전용.. 인 느낌)에 영구적으로 매핑       Unbounded threads : User thread 가 set내의 kernel thread 간 움직일 수 있음           ex) IRIX, HP-UX, Tru63 UNIX, Solaris 8와 그 earlier       - User-Level Thread vs Kernel-level Threads  정리   User-Level      Application(User) 에 의해 관리   Kernel은 Thread를 모름! 인식하지 못함   Context switching이 쌈 → kernel mode 권한이 필요 없으니   원하는 만큼 많이 생성할 수 있음   주의 깊게 사용해야함 . . → 서로 보호되어 있지 않아서   Kernel-Level      Kernel에 의해 관리   Kernel resources를 사용함   Context switching이 비쌈   생성하는데 한계가 있음 → Kernel Resource를 사용하다보니   사용하기 비교적 간편함 ㅎㅅㅎ       Thread Libraries   - Thread Libraries      Thread library는 thread를 생성하과 관리하기 위한 API를 개발자에게 제공함   구현의 2가지 기본 방법            Kernel의 도움 없이 User space에 완전히 있는 Library                    Library에 있는 함수를 호출하면, system call이 아니라 User space에 있는 local function이 호출                       Kernel (OS)의 도움을 받는 Kernel-level library                    Library에 있는 함수를 호출하면, kernel로의 system call                           3가지 main library            Pthreads       Win32       Java           - Pthreads (POSIX Thread)      User-level 또는 Kernel-level 로 제공될 수 있음   Thread 생성 및 syncronization에 필요한 POSIX 표준 (IEEE 1003. 1c) API   API는 thread library의 동작을 지정하고, 구현은 library 개발에 달려있음 → 이게 무슨 말이고 . .   UNIX OS(Solaris, Linux, Mac OS X)에서 공통적임   기본 Pthread APU            pthread_create() : 새로운 thread 생성                    thread 변수, thread 속성, start routinc 함수와 선택적 argument 허용                       pthread_join() : thread의 termination을 기다림                    메인 thread가 종료되기 전에 thread가 작업을 수행할 수 있는지 확인하는 데 사용                       pthread_exit() : 호출한 thread를 termination           #include &lt;pthread.h&gt; #include &lt;stdio.h&gt;  #include &lt;stdlib.h&gt;  int sum;                                /* this data is shared by the thread(s) */ void *runner(void *param);              /* threads call this function */  int main(int argc, char *argv[]) { \t\tpthread t tid;                      /* the thread identifier */ \t\tpthread attr t attr;                /* set of thread attributes */  \t\t/* set the default attributes of the thread */  \t\tpthread attr init(&amp;attr); \t \t\t/* create the thread */ \t\tpthread create(&amp;tid, &amp;attr, runner, argv[1]); /* runner에 의해 child thread 생성하고 실행됨 */ \t \t\t/* wait for the thread to exit */  \t\tpthread join(tid,NULL); \t \t\tprintf(\"sum = %d∖n\",sum); /* child에서 수행한 값이 나옴! 만약 param이 2였다면 sum은 1+2 = 3 */ }  /* The thread will execute in this function */  void *runner(void *param) { \t\tint i, upper = atoi(param);         /* thread 내에서 정의한 local var이기에 각 thread의 local stack에 저장됨 */ \t\tsum = 0;                            /* gloval var이기에 data section에 저장죔 */  \t\tfor (i = 1; i &lt;= upper; i++) \t\t\tsum += i; \t\t \t\tpthread exit(0);  }       Threading Issues   - fork() &amp; exec() system call      multithreaded program에선 fork()와 exec() system call의 의미가 달라질 수 있음 → 원래  fork() 는 process 생성하는 놈   multithreaded program에서 한 program의 thread가 fork()를 호출한 경우            새로운 process는 부모의 모든 thread를 복제해야하는가       새로운 process는 fork()를 호출한 thread만 복제해야하는가                    일부 UNIX system은 위의 두가지 버전의 fork()를 모두 구현하기도 함                           exec()를 호출한 경우            모든 thread를 포함한 전체 process가 대체됨           fork()를 부르자마자 다시 exec()을 부른다면 exec()에서 지정한 프로그램이 곧 모든 것을 다시 대체할 것이기 때문에 모든 스레드를 복제해서 만들어주는 것은 불필요!   fork() 후 exec()를 하지 않는다면 새 프로세스는 모든 스레드들을 복제 해야 함   - Signal Handling      signal은 UNIX system에서 특정 event가 발생했다고 process에게 알리기 위해 사용함            ex) CTRL+C에 의해 process가 종료된 경우           signal를 process하기 위해 signal handeler 사용            특정 event에 의해 signal 생성       process로 signal 전달       signal handled (처리)                  multithread program에서 signal 전달하기 위한 option (signal 생성 종류에 따라 결정됨)            signal이 적용되는 thread에 전달       process의 모든 thread에 전달       process의 특정 thread에 전달       process에 대한 모든 signal을 받을 특정 thread 지정           - Thread Cancellation      Thread가 완료되기 전에 terminating            ex) 웹 페이지가 렌더링 되는 동안 중지 버튼 누르는 경우           2가지 일반적인 approaches            Asynchronous cancellation : 타겟 thread를 즉시 종료                Deferred cancellation : 타겟 thread가 자신이 취소되는지 취소 여부를 주기적으로 확인하면서 순서대로 종료할 수 있는 기회 제공           → 더 통제되고 안전함! 자신이 취소되어도 안전하다고 판단하고 취소 여부 확인하면 되니까                   - Thread Pool      요청마다 새로운 thread를 생성하는 거는 새로운 process를 생성하는 방식보다는 overhead가 적긴하지만 그래도 thread에도 약간의 overhead가 존재            thread생성하는데 걸리는 시간이라던가 . .           무제한 thread는 system resource (CPU, Memory) 를 고갈할 수 있음 ㅜㅜ   이러한 문제를 해결하기 위해 thread pool 사용 !            process를 시작할 떄 미리 일정한 수의 thread를 만들어 task를 기다리는 곳인 pool에 넣어둠       대기하고 있다가 server가 요청을 받으면 새 thread를 생성하는 것 대신 pool에서 깨워서 할당           장점            일반적으로 기존 thread로 요청을 처리하는 방식보다 빠름!       일정한 한 순간에 존재하는 thread 수를 제한하여 리소스 고갈 방지           Pool의 thread 수는 CPU 수, Memory, 예상하는 동시 요청 수 등을 기준으로 설정할 수 있음  ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch4",
        "teaser": null
      },{
        "title": "[OS] Ch5. CPU Scheduling",
        "excerpt":"   노션으로 작성된 글을 백업 용으로 옮긴 것입니다. 개인적으로 공부하며 작성된 글이기에 틀린 정보가 있을 수 있습니다    Basic Concepts  - Basic Concept      Multiprogramming : 일부 process가 항상 실행되도록 하여 CPU utilization (사용율)을 최대화 함 → 즉 최대한 CPU가 놀지 않도록 하는 것            한 번에 여러 process들이 메모리에 유지시킴       block 될 때 까지 process 실행 시키고, 만약 block 된다면 다른 process를 실행           Process scheduling이랑 Thread Scheduling은 종종 같은 의미로 사용되기도 함 ~~   - CPU Burst와 I/O Burst의 Alternating Sequence          CPU-I/O Burst Cycle : CPU 실행 cycle과 I/O Wait로 구성된 Process            이때 CPU 실행이 연속되는 기간을 CPU Burst라고 하고       I/O를 연속해서 기다리는 기간을 I/O Burst라고 함                  CPU-bound Process : CPU-Burst가 길고, I/O-Burst가 드물게 있는 Process                     왼쪽 그래프에서 왼쪽 동그라미           ex) 데이터 마이닝, 이미지 프로세싱..                   I/O-bound Process : CPU-Burst가 짧고, I/O-Burst가 자주 있는 Process                     왼쪽 그래프에서 오른쪽 동그라미           ex) 유저의 입력이 계속있는 게임                   - CPU Scheduler      Short-term Scheduler → 빠르게 자주 바뀌는 .. !            memory에서 실행할 준비가 되어있는 process를 고르고, 그들 중 하나에게 CPU를 할당!                Process가 다음과 같은 경우 CPU Scheduling가 실행 될 수 있음                                   Admitted 된 상태                        Running state → Waiting state 로 전환된 경우                          ex) I/O Request                  Running state → Ready state 로 전환된 경우                  ex) Interrupt 발생                  Waiting state → Ready state 로 전환된 경우                  ex) I/O 작업 완료                  Terminates           1,4 는 non-preemtive, 나머지는 preemitive   1와 4번의 경우, 실행 중이던 것이 멈추거나, 종료된 상황이므로 선택의 여지가 없이 Ready Queue에서 새로운 Process를 골라야함   다른 경우, 어떻게 스케줄링을 할지 선택권이 있을 수 있다   - Preemtive (선점형) vs Non-preempitve (비선점형)      Preemitive            CPU가 Process에 할당되어도, 다른 Process가 CPU를 강제로 빼았을 수 있음 → 우선순위에 따라 CPU가 할당 되는 경우       ex) Time-slicing           Non-preempitve            CPU가 Process에 할당 되면, Block 되거나 terminate될 때 까지 실행됨 → 중간에 빼았을 수 없음       위에서 1번과 4번의 경우           - Dispatcher      Dispatcher module은 Short-term Scheduler (이하 STS)가 선택한 Process에 CPU 제어권을 넘겨줌! → CPU 할당 !   CPU Scheduler 내부에 포함되어 있는 것으로 STS가 선택한 Process에 실질적으로 CPU 를 할당하는 역할   Dispatch Latency : Dispatcher가 한 process를 stop하고 다른 하나를 running 시키는데 걸리는 시작   CPU 제어권 넘기는 과정에는 다음 것들 포함            Switching context (Process의 Reg 전환)       Switching to User mode       Program을 재시작하기 위해 User program이 적절한 location을 찾을 수 있도록하고, jump함           → 즉 다시 Running 하기 위해 할당해주는 과정                              Scheduling Criteria   - Scheduling Criteria (스케줄링 기준)      최대화 할수록 최적화됨            CPU utilization : 가능한 CPU를 바쁘게 일 시켜야함       Throughput : 시간 단위당 실행 완료하는 process 수           최소화 할수록 최적화됨            Turnaround time : 특정 작업을 실행 시키는데 걸리는 시간                    Completion time - Submission Time                       Waiting time : Ready Queue에서 실행되기를 기다리는 시간                    Fairness : 각 Process에 대해 동일한 시간을 배정하거나, 우선순위에 따라 적절한 시간을 배정해주어야함                       Response time : output이 아닌 request가 요청된 순간부터 첫번째 response가 생성될 때 까지 걸린 시간                    특히 interactice system environment에서 유용 ex) 폰,,                           Scheduling Algorithms   - Scheduling Algorithms      Ready Queue에 있는 Process 중 어떤 Process에게 CPU를 할당할 것인지 결정   최대한 Performance criteria를 최적화하는 방향으로 결정함   종종 일부보다는 평균값을 최적화하는 방향을 선택하기도 함   Interactive System에서는 Response Time을 최소화는 것이 가장 중요한 기준인 경우도 있음   - First-Come, First-Served (FCFS, 선착순) Scheduling      말 그대로 먼저 도착한 Process 순서대로 CPU를 배정함        ex) 다음과 같은  P1, P2, P3가 있을 때                                  Process           Burst Time (ms)                                           P1           24                             P2           3                             P3           3                                  P1, P2, P3 순서대로 도착했을 때, FCFS Scheduling에 의해 정해진 Gantt Chart는           | P1 | P2 | P3 |   | — | — | — |   | 0 ———————————————24 | 24 —————— 27 | 27—————— 30 |             Waiting Time : P1 = 0;  P2 = 24;  P3 = 27;       Average Waiting Time : (0 + 24 + 27) / 3 = 17                  P2, P3, P1 순서대로 도착했을 때, FCFS Scheduling에 의해 정해진 Gantt Chart는           | P2 | P3 | P1 |   | — | — | — |   | 0 —————— 3 | 3—————— 6 | 5 ———————————————30 |             Waiting Time : P1 = 6;  P2 = 0;  P3 = 3;       Average Waiting Time : (6 + 0 + 3) / 3 = 3           → 1의 경우에 비해 굉장히 최적화됨!!!       Ready Queue로 FIFO 사용   Average Waiting Time은 일반적으로 최소가 아니며, variance가 큼 → 순서에 따라 많은 영향을 받아서   단점            Convoy effect : CPU bound process (CPU 사용 시간이 굉장히 긴 Process) 로 인해 다른 모든 사람이 Ready 상태임에도 불구하고 한참 기다려야함 ㅜㅜ       Non-preemptive Schediling algorithms.. 이면 timesharing system에서 큰 골칫거리,,           - Shortest-Jop-First (SJF) Scheduling      다음 CPU Burst의 길이와 각 Process를 연결하여 이 길이가 가장 짧은 Process 순서대로 CPU를 할당하여 scheduling            길이가 동일하다면 FCFS (선착순)           Average Waiting Time이 최소화 되기에 SJF 방식이 최적이긴하나, 다음 CPU Request 시간을 알기 어렵다는 큰 문제점이 있음 ㅜㅜ            Why 어려움? → I/O Request 가 나와야 I/O Burst로 전환되어 CPU Burst 길이를 측정 할 수 있어서 ㅜㅜ                ex) 다음과 같은  P1, P2, P3가 있을 때                                  Process           Burst Time (ms)           Shortest Order                                           P1           6           2                             P2           8           4                             P3           7           3                             P4           3           1                           SJF Scheduling에 의해 정해진 Gantt Chart는       | — | — | — | — |              Waiting Time : P1 = 3;  P2 = 16;  P3 = 9; P4  = 0       Average Waiting Time : (3 + 16 + 9 + 0) / 4 = 7       FCFS 사용 했을 경우 Average Waiting Time : (0 + 6 + 14 + 21) / 4 = 10.25           SJF Scheduling의 2가지 방식   | Process | Arrival Time (ms) | Burst Time (ms) | | — | — | — | | P1 | 0 | 8 | | P2 | 1 | 4 | | P3 | 2 | 9 | | P4 | 3 | 5 |          Nonpreemptive SJF : 일단 CPU가 Process에게 주어지면, CPU burst가 끝날 때까지 CPU를 선점하고 있음       | P1 | P2 | P4 | P3 |  | — | — | — | — |  | 0———————— 8 | 8 ———— 12 | 12 ————— 17 | 17 —————————26 |             Average Waiting Time : (0 + (8-1) + (17-1) + (12-3) / 4 = 7.75                Preemiptive SJF : 새로 도착한 Process의 CPU burst길이가 지금 실행 중인 procee의 남은 CPU burst시간보다 짧다면 선점 (뻇음)       → Shortest-remaining-time-first scheduling이라고도 알려져 있음       | P1 | P2 | P4 | P1 | P3 |  | — | — | — | — | — |  | 0 —1 | 1 ———— 5 | 5 ————— 10 | 10 ———————18 | 18 ————————- 27 |             Average Waiting Time : ((10-1)+(1-1)+(17-2)+(5-3)) / 4 = 6.5           - Next CPU Burst 길이 결정      실제 길이를 알 수 없기에 추측만 가능함 ㅜㅜ   이전 CPU Burst 길이들의 exponential average를 이용하여 추측            $t_n$  = Actual Lenght of $n^{th}$ CPU Burst       $\\tau _{n+1}$  = Predicted Value for the next CPU Burst       $\\alpha, 0 \\leq \\alpha \\leq1$       Define :  $\\tau _{n+1} = at_n\\space + \\space (1-\\alpha )\\tau_n$           - Priority Scheduling      각 process에게 정수 priority number가 주어짐   CPU는 우선순위가 가장 높은 process에게 할당되고, 만약 우선순위가 동일한 경우에는 FCFS 순서를 사용함   SJF는 다음 CPU Burst 시간을 기반으로 한 우선순위 스케줄링이라면, 이거는 일반적으로 지정된 고정된 값을 우선순위로 이용   우선순위는 internally(내부적), externally(외부적) 으로 정의될 수 있음            Internally : 측정가능한 quantity나 qulity를 사용! ex) 시간 제한이나 시간 사용량, 리소스 사용량, CPU burst에 대한 I       external : 컴퓨터 시스켐 외의 기준에 의해 설정 ex) 컴퓨터 사용에 지불하는 금액           2가지 방식            현재 실행 중인 프로레스보다 우선위가 높은 새로운 프로레스가 ready queue에 도착한 경우                    Preemptive : CPU를 선점하고 새로운 프로세스 실행           Non-preempitve : 그런거 없음 지금 CPU 사용하고 있는 process 그대로 유지                           문제점 : Stavation → 우선 순위가 낮은 process의 경우 계속 밀리니 결국 절대 실행 못 할 수도 있음 ㅜㅜ        해결법 : Aging → 시간이 지날수록 점진적으로 기존의 process의 우선수위를 높여서 오래된 process가 실행되도록       ex) 우선순위 범위를 0-127로 두고 15분 마다 대기 중인 프로세스의 우선순위를 1씩 높임!       → 그렇게 되면 우선순위 127이었던 애는 32분 이상 지나면 0이 되어서 처리하게 됨       Round Robin (RR)      Time-sharing system 을 위해 특별히 설계된 방식으로 Preemptive 방식 임   각 process는 10-100 밀리초인 작은 CPU 단위 시간 (Time Quantum)의 일정 시간을 얻음   그리고 이 Time Quantum이 지나면 다음 process가 선점되어서 ready Queue의 마지막에 추가됨            FCFS랑 비슷하지만 Process 간 switch를 위한 선점을 추가함           Ready Queue는 circular queue이고 FIFO를 사용해서 구현함   고려해야할 2개의 경우            Process가 1 Time Quantum보다 작거나 같은 CPU Burst를 가지는 경우 → 남는 time quantum 동안 어떻게? 그냥 바로 scheduling       Process가 1 Time Quantum보다 큰 CPU Burst를 가지는 경우 → time quantum 끝날 때 마다 계속 처리를 어떻게?           ex) example, Time Quantum = 4                  Process       Burst Time (ms)                       P1       24                 P2       3                 P3       3                          P1       P2       P3       P1       P1       P1       P1       P1                       0—— 4       4 —- 7       7— 10       10 ——14       14——18       18——22       22——26       26——30              Average waiting time : ((10-4)+4+7)/3 = 5.66   RR의 경우 굉장히 긴 시간을 기다려야하는 경우도 있음        일반적으로 평균 turnarund 시간이 SJF보다 길지만 응답속도은 더 좋음 → interactive 한       Ready Queue 에 n개의 process가 있고 time quantum이 q인 경우, 각 process는 한번에 최대 q 시간 단위의 chunk로 CPU시간의 1/n 을 얻음   (n-1)q 이상 다음 quantum을 기다리는 process는 없음 → 각자가 최대로 q 만큼 기다려야 (n-1)q 만큼 기다린거니까   성능은 time quantum 사이즈 q에 따라 달려있음            q 가 매우 큰 경우 → FCFS 랑 동일해짐.. 사실 q 보다 burst 시간이 긴게 없을테니까       q 가 매우 큰 경우 → 각 n 개의 process는 실제보다 1/n 속도의 실행되는 process가 될거임. . 그리고 context switch가 굉장히 자주 일어나서 overhead가 커짐 ㅜㅜ                    평균 Turnaround 시간은 q가 증가한다고 해서 무조건 나아지는게 아님      Multilevel Queue      Ready Queue를 2개로 분할한 다음에 어떤 process냐에 따라 어떤 queue에 넣을지 결정 → 즉 프로세스간 여러 레벨로 분류하는            foreground (interactive) queue → 상호작용이 많고 burst 시간이 빠른       background (batch) queue → batch 처럼 긴 시간동안 동작하고 상대적으로 덜 중요한           각 process는 하나의 ready queue에 영구적으로 할당됨   각 queue는 각자의 scheduling 알고리즘을 가짐            foreground (interactive) : RR → 아무래도 빠르게 동작되어야하니까 …       background (batch) : FCFS           ready queue 사이에도 scheduling이 이루어져해야함            Fixed priority scheduling                    즉 무조건 foreground에서 모두 사용한 다음에 background로 넘어감 → Stavation 문제 발생할 수도                       Time slice : 각 queue는 프로세스 사이에서 schedule을 잡을 수 있는 일정량의 CPU 시간을 얻음! 이 시간 지나면 얻어야해                    foreground queue는 processRR 에서 80%, background in FCFS 에서 20%                                각 ready queue는 우선순위가 낮은 queue보다 절대적인 우선 순위를 가짐                          interactive 프로세스를 실행하려면 system process queue이 비어있어야함       system process가 도착하면 interactive process가 선점됨       즉 앞에 있는 queue가 다 실행되어야 다음 queue에 들어있는 프로세스들이 실행된다는 것           Multilevel Feedback Queue      process가 ready queue간에 이동할 수 있는 경우 !   다른 policy와 quantum size를 가진 Multiple Queue 간에서 process는 migrate 할 수 있음   CPU burst times에 따라 process를 분리할 수 있음            process가 CPU 시간을 너무 많이 사용하는 경우 → 낮은 우선순위를 가진 queue로 이동                만약 process가 너무 오래 wait 하고 있는 경우 → 높은 우선순위를 가진 queue로 이동           : starvation 을 방지하기 위한 aging 방법               I/O 중심인 process랑 foreground(interactive)한 process 은 높은 우선순위에 배치함       processeor 중심의 process는 낮은 우선순위에 배치함           Example in Multilevel Feedback Queue      3 개의 Queue            Q0 : Time Quantum 이 8 ms 인 RR       Q1 : Time Quantum 이 16 ms 인 RR       Q2 : FCFS           Scheduling            새로운 job이 Q0 에 들어가고, CPU를 얻으면 8 ms 동안 가지고 있음       8 ms 동안 완료되지 않으면 jop은 Q1 으로 이동함       Q1 에서 job 은 16 ms 동안 추가적으로 CPU 가짐 ! 그리고 이 시간동안 완료되지 않으면 다시 Q2로 이동       Q2 에서 job 은 FCFS 방식으로 작동! 대신 Q1, Q2 가 이때 비어있을 때만                  Multilvel-feedback-Queue Sceduler은 다음 parameter에 대해 정의됨                     of Queues               각 Queue에 대한 scheduling algorithms       process 를 더 높은 우선순위의 queue로 upgrade 하는 것을 결정하는 method       process 를 더 낮은 우선순위의 queue로 demote 하는 것을 결정하는 method       process가 service를 원할 때 process 가 들어갈 ready queue를 결정하는 method       process가 service를 받는 시기를 결정하는 method → PPT 에는 없음!           Multiple-Processor Scheduling   - Multiple-Processor Schduling      multiple CPUs (Multiple-Processor) 가 가능한 경우 CPU Scheduling은 더 복잡해짐 ㅜㅜ → Processor 마다 독자적인 Queue랑 독자적인 Scheduling 방식을 가지고 있으니까 !            Asymmetric Multiprocessing (AMP)                 단 하나의 process (master)만 system data structure에 접근함 그리고 얘가 다른 모든 processor들의 scheduling을 지정함       다른 process (slave)들은 user code만 실행                    Symmetric Multiprocessing (SMP)                       각 processor는 자체적으로, 즉 스스로 scheduling함       각 Processor는 공통의 ready Queue에 있는 process 들 중에 실행할 process를 선택함! 아니면 Procesor가 각자의 private queue를 가지는 경우도?           - Symmetric Multiprocessing (SMP)      Common Ready Queue (Global)            Process가 idle이 되면 (유휴 상태가 되면), CPU schduler는 즉시 common queue에서 해당 process를 추출함           A private Queue for Each Processor            모든 process 간의 load balancing이 필요함       process간 migration으로 종료되면                    push migratioin           pull migration (work stealing)           Linux: Push-load-balancing every 200 ms, pull-load-balancing whenever local task queue is empty                           - Processor Affinity (프로세서 선호도)      Cache Affinity            cache에는 최근에 CPU에 의해 접근한 data의 copy본이 포함되어 있음 그래서 이를 선호       process가 최근에 할당된 CPU말고 다른 CPU에 할당된 경우                    새로운 접근에 의해 이전 캐시들은 무효화됨 → 관련 없는 캐시니까           새 CPU에서 시작하니까 cache miss가 엄청나게 많이 발생           많은 bus traffic과 굉장히 느린 main memory 접근..                       그러니까! 최대한 다른 CPU로의 migration은 피해야함!! 되도록이면 무조건 기존의 CPU에 할당되도록!!! → 그래서 processor에 대한 선호도를           Process는 현재 있는 Processor에 대한 선호도가 있음            Hard Affinity : 다른 CPU로의 migration 금지 (forbidden)       Soft Affinity : Mitgration 가능하긴 한데 undesirable (바람직하지 않다)                NUMA (Non-Uniform Memory Accesss) Affinity : CPU Scheduler와 memory 배치 알고리즘이 함께 작동해서 프로세스에 대한 메모리 페이지가 상주하는 특정 processor(soket)에 process를 할당 할 수 있음                   Work-Conserving or Not      Work-conserving            누군가 CPU 를 원할 때 리소스를 idel 상태로 두지 마라!       실행 가능한 process가 없을 때만 CPU가 idel 상태가 되도록           Non work-conserving            실행 가능한 process가 있어도 CPU가 idel 상태 일 수 있음       안정성은 높을지도?          ","categories": ["[2023]Operating System"],
        "tags": ["OS","강의필기"],
        "url": "/categories/study/2023_OS/ch5",
        "teaser": null
      }]
